{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duan/magma/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import transformers\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = clip.load(\"ViT-B/32\")[0].visual\n",
    "count_parameters(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+------------+\n",
      "|                      Modules                       | Parameters |\n",
      "+----------------------------------------------------+------------+\n",
      "|                     cls_token                      |    768     |\n",
      "|                     pos_embed                      |   151296   |\n",
      "|         embeddings.word_embeddings.weight          |  38603520  |\n",
      "|      embeddings.token_type_embeddings.weight       |    768     |\n",
      "|            embeddings.LayerNorm.weight             |    768     |\n",
      "|             embeddings.LayerNorm.bias              |    768     |\n",
      "|       embeddings.position_embeddings.weight        |   394752   |\n",
      "|      embeddings.x_position_embeddings.weight       |   131072   |\n",
      "|      embeddings.y_position_embeddings.weight       |   131072   |\n",
      "|      embeddings.h_position_embeddings.weight       |   131072   |\n",
      "|      embeddings.w_position_embeddings.weight       |   131072   |\n",
      "|              patch_embed.proj.weight               |   589824   |\n",
      "|               patch_embed.proj.bias                |    768     |\n",
      "|                  LayerNorm.weight                  |    768     |\n",
      "|                   LayerNorm.bias                   |    768     |\n",
      "|                    norm.weight                     |    768     |\n",
      "|                     norm.bias                      |    768     |\n",
      "|    encoder.layer.0.attention.self.query.weight     |   589824   |\n",
      "|     encoder.layer.0.attention.self.query.bias      |    768     |\n",
      "|     encoder.layer.0.attention.self.key.weight      |   589824   |\n",
      "|      encoder.layer.0.attention.self.key.bias       |    768     |\n",
      "|    encoder.layer.0.attention.self.value.weight     |   589824   |\n",
      "|     encoder.layer.0.attention.self.value.bias      |    768     |\n",
      "|   encoder.layer.0.attention.output.dense.weight    |   589824   |\n",
      "|    encoder.layer.0.attention.output.dense.bias     |    768     |\n",
      "| encoder.layer.0.attention.output.LayerNorm.weight  |    768     |\n",
      "|  encoder.layer.0.attention.output.LayerNorm.bias   |    768     |\n",
      "|     encoder.layer.0.intermediate.dense.weight      |  2359296   |\n",
      "|      encoder.layer.0.intermediate.dense.bias       |    3072    |\n",
      "|        encoder.layer.0.output.dense.weight         |  2359296   |\n",
      "|         encoder.layer.0.output.dense.bias          |    768     |\n",
      "|      encoder.layer.0.output.LayerNorm.weight       |    768     |\n",
      "|       encoder.layer.0.output.LayerNorm.bias        |    768     |\n",
      "|    encoder.layer.1.attention.self.query.weight     |   589824   |\n",
      "|     encoder.layer.1.attention.self.query.bias      |    768     |\n",
      "|     encoder.layer.1.attention.self.key.weight      |   589824   |\n",
      "|      encoder.layer.1.attention.self.key.bias       |    768     |\n",
      "|    encoder.layer.1.attention.self.value.weight     |   589824   |\n",
      "|     encoder.layer.1.attention.self.value.bias      |    768     |\n",
      "|   encoder.layer.1.attention.output.dense.weight    |   589824   |\n",
      "|    encoder.layer.1.attention.output.dense.bias     |    768     |\n",
      "| encoder.layer.1.attention.output.LayerNorm.weight  |    768     |\n",
      "|  encoder.layer.1.attention.output.LayerNorm.bias   |    768     |\n",
      "|     encoder.layer.1.intermediate.dense.weight      |  2359296   |\n",
      "|      encoder.layer.1.intermediate.dense.bias       |    3072    |\n",
      "|        encoder.layer.1.output.dense.weight         |  2359296   |\n",
      "|         encoder.layer.1.output.dense.bias          |    768     |\n",
      "|      encoder.layer.1.output.LayerNorm.weight       |    768     |\n",
      "|       encoder.layer.1.output.LayerNorm.bias        |    768     |\n",
      "|    encoder.layer.2.attention.self.query.weight     |   589824   |\n",
      "|     encoder.layer.2.attention.self.query.bias      |    768     |\n",
      "|     encoder.layer.2.attention.self.key.weight      |   589824   |\n",
      "|      encoder.layer.2.attention.self.key.bias       |    768     |\n",
      "|    encoder.layer.2.attention.self.value.weight     |   589824   |\n",
      "|     encoder.layer.2.attention.self.value.bias      |    768     |\n",
      "|   encoder.layer.2.attention.output.dense.weight    |   589824   |\n",
      "|    encoder.layer.2.attention.output.dense.bias     |    768     |\n",
      "| encoder.layer.2.attention.output.LayerNorm.weight  |    768     |\n",
      "|  encoder.layer.2.attention.output.LayerNorm.bias   |    768     |\n",
      "|     encoder.layer.2.intermediate.dense.weight      |  2359296   |\n",
      "|      encoder.layer.2.intermediate.dense.bias       |    3072    |\n",
      "|        encoder.layer.2.output.dense.weight         |  2359296   |\n",
      "|         encoder.layer.2.output.dense.bias          |    768     |\n",
      "|      encoder.layer.2.output.LayerNorm.weight       |    768     |\n",
      "|       encoder.layer.2.output.LayerNorm.bias        |    768     |\n",
      "|    encoder.layer.3.attention.self.query.weight     |   589824   |\n",
      "|     encoder.layer.3.attention.self.query.bias      |    768     |\n",
      "|     encoder.layer.3.attention.self.key.weight      |   589824   |\n",
      "|      encoder.layer.3.attention.self.key.bias       |    768     |\n",
      "|    encoder.layer.3.attention.self.value.weight     |   589824   |\n",
      "|     encoder.layer.3.attention.self.value.bias      |    768     |\n",
      "|   encoder.layer.3.attention.output.dense.weight    |   589824   |\n",
      "|    encoder.layer.3.attention.output.dense.bias     |    768     |\n",
      "| encoder.layer.3.attention.output.LayerNorm.weight  |    768     |\n",
      "|  encoder.layer.3.attention.output.LayerNorm.bias   |    768     |\n",
      "|     encoder.layer.3.intermediate.dense.weight      |  2359296   |\n",
      "|      encoder.layer.3.intermediate.dense.bias       |    3072    |\n",
      "|        encoder.layer.3.output.dense.weight         |  2359296   |\n",
      "|         encoder.layer.3.output.dense.bias          |    768     |\n",
      "|      encoder.layer.3.output.LayerNorm.weight       |    768     |\n",
      "|       encoder.layer.3.output.LayerNorm.bias        |    768     |\n",
      "|    encoder.layer.4.attention.self.query.weight     |   589824   |\n",
      "|     encoder.layer.4.attention.self.query.bias      |    768     |\n",
      "|     encoder.layer.4.attention.self.key.weight      |   589824   |\n",
      "|      encoder.layer.4.attention.self.key.bias       |    768     |\n",
      "|    encoder.layer.4.attention.self.value.weight     |   589824   |\n",
      "|     encoder.layer.4.attention.self.value.bias      |    768     |\n",
      "|   encoder.layer.4.attention.output.dense.weight    |   589824   |\n",
      "|    encoder.layer.4.attention.output.dense.bias     |    768     |\n",
      "| encoder.layer.4.attention.output.LayerNorm.weight  |    768     |\n",
      "|  encoder.layer.4.attention.output.LayerNorm.bias   |    768     |\n",
      "|     encoder.layer.4.intermediate.dense.weight      |  2359296   |\n",
      "|      encoder.layer.4.intermediate.dense.bias       |    3072    |\n",
      "|        encoder.layer.4.output.dense.weight         |  2359296   |\n",
      "|         encoder.layer.4.output.dense.bias          |    768     |\n",
      "|      encoder.layer.4.output.LayerNorm.weight       |    768     |\n",
      "|       encoder.layer.4.output.LayerNorm.bias        |    768     |\n",
      "|    encoder.layer.5.attention.self.query.weight     |   589824   |\n",
      "|     encoder.layer.5.attention.self.query.bias      |    768     |\n",
      "|     encoder.layer.5.attention.self.key.weight      |   589824   |\n",
      "|      encoder.layer.5.attention.self.key.bias       |    768     |\n",
      "|    encoder.layer.5.attention.self.value.weight     |   589824   |\n",
      "|     encoder.layer.5.attention.self.value.bias      |    768     |\n",
      "|   encoder.layer.5.attention.output.dense.weight    |   589824   |\n",
      "|    encoder.layer.5.attention.output.dense.bias     |    768     |\n",
      "| encoder.layer.5.attention.output.LayerNorm.weight  |    768     |\n",
      "|  encoder.layer.5.attention.output.LayerNorm.bias   |    768     |\n",
      "|     encoder.layer.5.intermediate.dense.weight      |  2359296   |\n",
      "|      encoder.layer.5.intermediate.dense.bias       |    3072    |\n",
      "|        encoder.layer.5.output.dense.weight         |  2359296   |\n",
      "|         encoder.layer.5.output.dense.bias          |    768     |\n",
      "|      encoder.layer.5.output.LayerNorm.weight       |    768     |\n",
      "|       encoder.layer.5.output.LayerNorm.bias        |    768     |\n",
      "|    encoder.layer.6.attention.self.query.weight     |   589824   |\n",
      "|     encoder.layer.6.attention.self.query.bias      |    768     |\n",
      "|     encoder.layer.6.attention.self.key.weight      |   589824   |\n",
      "|      encoder.layer.6.attention.self.key.bias       |    768     |\n",
      "|    encoder.layer.6.attention.self.value.weight     |   589824   |\n",
      "|     encoder.layer.6.attention.self.value.bias      |    768     |\n",
      "|   encoder.layer.6.attention.output.dense.weight    |   589824   |\n",
      "|    encoder.layer.6.attention.output.dense.bias     |    768     |\n",
      "| encoder.layer.6.attention.output.LayerNorm.weight  |    768     |\n",
      "|  encoder.layer.6.attention.output.LayerNorm.bias   |    768     |\n",
      "|     encoder.layer.6.intermediate.dense.weight      |  2359296   |\n",
      "|      encoder.layer.6.intermediate.dense.bias       |    3072    |\n",
      "|        encoder.layer.6.output.dense.weight         |  2359296   |\n",
      "|         encoder.layer.6.output.dense.bias          |    768     |\n",
      "|      encoder.layer.6.output.LayerNorm.weight       |    768     |\n",
      "|       encoder.layer.6.output.LayerNorm.bias        |    768     |\n",
      "|    encoder.layer.7.attention.self.query.weight     |   589824   |\n",
      "|     encoder.layer.7.attention.self.query.bias      |    768     |\n",
      "|     encoder.layer.7.attention.self.key.weight      |   589824   |\n",
      "|      encoder.layer.7.attention.self.key.bias       |    768     |\n",
      "|    encoder.layer.7.attention.self.value.weight     |   589824   |\n",
      "|     encoder.layer.7.attention.self.value.bias      |    768     |\n",
      "|   encoder.layer.7.attention.output.dense.weight    |   589824   |\n",
      "|    encoder.layer.7.attention.output.dense.bias     |    768     |\n",
      "| encoder.layer.7.attention.output.LayerNorm.weight  |    768     |\n",
      "|  encoder.layer.7.attention.output.LayerNorm.bias   |    768     |\n",
      "|     encoder.layer.7.intermediate.dense.weight      |  2359296   |\n",
      "|      encoder.layer.7.intermediate.dense.bias       |    3072    |\n",
      "|        encoder.layer.7.output.dense.weight         |  2359296   |\n",
      "|         encoder.layer.7.output.dense.bias          |    768     |\n",
      "|      encoder.layer.7.output.LayerNorm.weight       |    768     |\n",
      "|       encoder.layer.7.output.LayerNorm.bias        |    768     |\n",
      "|    encoder.layer.8.attention.self.query.weight     |   589824   |\n",
      "|     encoder.layer.8.attention.self.query.bias      |    768     |\n",
      "|     encoder.layer.8.attention.self.key.weight      |   589824   |\n",
      "|      encoder.layer.8.attention.self.key.bias       |    768     |\n",
      "|    encoder.layer.8.attention.self.value.weight     |   589824   |\n",
      "|     encoder.layer.8.attention.self.value.bias      |    768     |\n",
      "|   encoder.layer.8.attention.output.dense.weight    |   589824   |\n",
      "|    encoder.layer.8.attention.output.dense.bias     |    768     |\n",
      "| encoder.layer.8.attention.output.LayerNorm.weight  |    768     |\n",
      "|  encoder.layer.8.attention.output.LayerNorm.bias   |    768     |\n",
      "|     encoder.layer.8.intermediate.dense.weight      |  2359296   |\n",
      "|      encoder.layer.8.intermediate.dense.bias       |    3072    |\n",
      "|        encoder.layer.8.output.dense.weight         |  2359296   |\n",
      "|         encoder.layer.8.output.dense.bias          |    768     |\n",
      "|      encoder.layer.8.output.LayerNorm.weight       |    768     |\n",
      "|       encoder.layer.8.output.LayerNorm.bias        |    768     |\n",
      "|    encoder.layer.9.attention.self.query.weight     |   589824   |\n",
      "|     encoder.layer.9.attention.self.query.bias      |    768     |\n",
      "|     encoder.layer.9.attention.self.key.weight      |   589824   |\n",
      "|      encoder.layer.9.attention.self.key.bias       |    768     |\n",
      "|    encoder.layer.9.attention.self.value.weight     |   589824   |\n",
      "|     encoder.layer.9.attention.self.value.bias      |    768     |\n",
      "|   encoder.layer.9.attention.output.dense.weight    |   589824   |\n",
      "|    encoder.layer.9.attention.output.dense.bias     |    768     |\n",
      "| encoder.layer.9.attention.output.LayerNorm.weight  |    768     |\n",
      "|  encoder.layer.9.attention.output.LayerNorm.bias   |    768     |\n",
      "|     encoder.layer.9.intermediate.dense.weight      |  2359296   |\n",
      "|      encoder.layer.9.intermediate.dense.bias       |    3072    |\n",
      "|        encoder.layer.9.output.dense.weight         |  2359296   |\n",
      "|         encoder.layer.9.output.dense.bias          |    768     |\n",
      "|      encoder.layer.9.output.LayerNorm.weight       |    768     |\n",
      "|       encoder.layer.9.output.LayerNorm.bias        |    768     |\n",
      "|    encoder.layer.10.attention.self.query.weight    |   589824   |\n",
      "|     encoder.layer.10.attention.self.query.bias     |    768     |\n",
      "|     encoder.layer.10.attention.self.key.weight     |   589824   |\n",
      "|      encoder.layer.10.attention.self.key.bias      |    768     |\n",
      "|    encoder.layer.10.attention.self.value.weight    |   589824   |\n",
      "|     encoder.layer.10.attention.self.value.bias     |    768     |\n",
      "|   encoder.layer.10.attention.output.dense.weight   |   589824   |\n",
      "|    encoder.layer.10.attention.output.dense.bias    |    768     |\n",
      "| encoder.layer.10.attention.output.LayerNorm.weight |    768     |\n",
      "|  encoder.layer.10.attention.output.LayerNorm.bias  |    768     |\n",
      "|     encoder.layer.10.intermediate.dense.weight     |  2359296   |\n",
      "|      encoder.layer.10.intermediate.dense.bias      |    3072    |\n",
      "|        encoder.layer.10.output.dense.weight        |  2359296   |\n",
      "|         encoder.layer.10.output.dense.bias         |    768     |\n",
      "|      encoder.layer.10.output.LayerNorm.weight      |    768     |\n",
      "|       encoder.layer.10.output.LayerNorm.bias       |    768     |\n",
      "|    encoder.layer.11.attention.self.query.weight    |   589824   |\n",
      "|     encoder.layer.11.attention.self.query.bias     |    768     |\n",
      "|     encoder.layer.11.attention.self.key.weight     |   589824   |\n",
      "|      encoder.layer.11.attention.self.key.bias      |    768     |\n",
      "|    encoder.layer.11.attention.self.value.weight    |   589824   |\n",
      "|     encoder.layer.11.attention.self.value.bias     |    768     |\n",
      "|   encoder.layer.11.attention.output.dense.weight   |   589824   |\n",
      "|    encoder.layer.11.attention.output.dense.bias    |    768     |\n",
      "| encoder.layer.11.attention.output.LayerNorm.weight |    768     |\n",
      "|  encoder.layer.11.attention.output.LayerNorm.bias  |    768     |\n",
      "|     encoder.layer.11.intermediate.dense.weight     |  2359296   |\n",
      "|      encoder.layer.11.intermediate.dense.bias      |    3072    |\n",
      "|        encoder.layer.11.output.dense.weight        |  2359296   |\n",
      "|         encoder.layer.11.output.dense.bias         |    768     |\n",
      "|      encoder.layer.11.output.LayerNorm.weight      |    768     |\n",
      "|       encoder.layer.11.output.LayerNorm.bias       |    768     |\n",
      "|            encoder.rel_pos_bias.weight             |    384     |\n",
      "|           encoder.rel_pos_x_bias.weight            |    768     |\n",
      "|           encoder.rel_pos_y_bias.weight            |    768     |\n",
      "+----------------------------------------------------+------------+\n",
      "Total Trainable Params: 125326976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125326976"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = transformers.LayoutLMv3Model.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "count_parameters(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 402M/402M [00:08<00:00, 51.3MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------------+\n",
      "|            Modules            | Parameters |\n",
      "+-------------------------------+------------+\n",
      "|          conv1.weight         |    1080    |\n",
      "|           bn1.weight          |     40     |\n",
      "|            bn1.bias           |     40     |\n",
      "|          conv2.weight         |   14400    |\n",
      "|           bn2.weight          |     40     |\n",
      "|            bn2.bias           |     40     |\n",
      "|          conv3.weight         |   28800    |\n",
      "|           bn3.weight          |     80     |\n",
      "|            bn3.bias           |     80     |\n",
      "|     layer1.0.conv1.weight     |    6400    |\n",
      "|      layer1.0.bn1.weight      |     80     |\n",
      "|       layer1.0.bn1.bias       |     80     |\n",
      "|     layer1.0.conv2.weight     |   57600    |\n",
      "|      layer1.0.bn2.weight      |     80     |\n",
      "|       layer1.0.bn2.bias       |     80     |\n",
      "|     layer1.0.conv3.weight     |   25600    |\n",
      "|      layer1.0.bn3.weight      |    320     |\n",
      "|       layer1.0.bn3.bias       |    320     |\n",
      "|  layer1.0.downsample.0.weight |   25600    |\n",
      "|  layer1.0.downsample.1.weight |    320     |\n",
      "|   layer1.0.downsample.1.bias  |    320     |\n",
      "|     layer1.1.conv1.weight     |   25600    |\n",
      "|      layer1.1.bn1.weight      |     80     |\n",
      "|       layer1.1.bn1.bias       |     80     |\n",
      "|     layer1.1.conv2.weight     |   57600    |\n",
      "|      layer1.1.bn2.weight      |     80     |\n",
      "|       layer1.1.bn2.bias       |     80     |\n",
      "|     layer1.1.conv3.weight     |   25600    |\n",
      "|      layer1.1.bn3.weight      |    320     |\n",
      "|       layer1.1.bn3.bias       |    320     |\n",
      "|     layer1.2.conv1.weight     |   25600    |\n",
      "|      layer1.2.bn1.weight      |     80     |\n",
      "|       layer1.2.bn1.bias       |     80     |\n",
      "|     layer1.2.conv2.weight     |   57600    |\n",
      "|      layer1.2.bn2.weight      |     80     |\n",
      "|       layer1.2.bn2.bias       |     80     |\n",
      "|     layer1.2.conv3.weight     |   25600    |\n",
      "|      layer1.2.bn3.weight      |    320     |\n",
      "|       layer1.2.bn3.bias       |    320     |\n",
      "|     layer1.3.conv1.weight     |   25600    |\n",
      "|      layer1.3.bn1.weight      |     80     |\n",
      "|       layer1.3.bn1.bias       |     80     |\n",
      "|     layer1.3.conv2.weight     |   57600    |\n",
      "|      layer1.3.bn2.weight      |     80     |\n",
      "|       layer1.3.bn2.bias       |     80     |\n",
      "|     layer1.3.conv3.weight     |   25600    |\n",
      "|      layer1.3.bn3.weight      |    320     |\n",
      "|       layer1.3.bn3.bias       |    320     |\n",
      "|     layer2.0.conv1.weight     |   51200    |\n",
      "|      layer2.0.bn1.weight      |    160     |\n",
      "|       layer2.0.bn1.bias       |    160     |\n",
      "|     layer2.0.conv2.weight     |   230400   |\n",
      "|      layer2.0.bn2.weight      |    160     |\n",
      "|       layer2.0.bn2.bias       |    160     |\n",
      "|     layer2.0.conv3.weight     |   102400   |\n",
      "|      layer2.0.bn3.weight      |    640     |\n",
      "|       layer2.0.bn3.bias       |    640     |\n",
      "|  layer2.0.downsample.0.weight |   204800   |\n",
      "|  layer2.0.downsample.1.weight |    640     |\n",
      "|   layer2.0.downsample.1.bias  |    640     |\n",
      "|     layer2.1.conv1.weight     |   102400   |\n",
      "|      layer2.1.bn1.weight      |    160     |\n",
      "|       layer2.1.bn1.bias       |    160     |\n",
      "|     layer2.1.conv2.weight     |   230400   |\n",
      "|      layer2.1.bn2.weight      |    160     |\n",
      "|       layer2.1.bn2.bias       |    160     |\n",
      "|     layer2.1.conv3.weight     |   102400   |\n",
      "|      layer2.1.bn3.weight      |    640     |\n",
      "|       layer2.1.bn3.bias       |    640     |\n",
      "|     layer2.2.conv1.weight     |   102400   |\n",
      "|      layer2.2.bn1.weight      |    160     |\n",
      "|       layer2.2.bn1.bias       |    160     |\n",
      "|     layer2.2.conv2.weight     |   230400   |\n",
      "|      layer2.2.bn2.weight      |    160     |\n",
      "|       layer2.2.bn2.bias       |    160     |\n",
      "|     layer2.2.conv3.weight     |   102400   |\n",
      "|      layer2.2.bn3.weight      |    640     |\n",
      "|       layer2.2.bn3.bias       |    640     |\n",
      "|     layer2.3.conv1.weight     |   102400   |\n",
      "|      layer2.3.bn1.weight      |    160     |\n",
      "|       layer2.3.bn1.bias       |    160     |\n",
      "|     layer2.3.conv2.weight     |   230400   |\n",
      "|      layer2.3.bn2.weight      |    160     |\n",
      "|       layer2.3.bn2.bias       |    160     |\n",
      "|     layer2.3.conv3.weight     |   102400   |\n",
      "|      layer2.3.bn3.weight      |    640     |\n",
      "|       layer2.3.bn3.bias       |    640     |\n",
      "|     layer2.4.conv1.weight     |   102400   |\n",
      "|      layer2.4.bn1.weight      |    160     |\n",
      "|       layer2.4.bn1.bias       |    160     |\n",
      "|     layer2.4.conv2.weight     |   230400   |\n",
      "|      layer2.4.bn2.weight      |    160     |\n",
      "|       layer2.4.bn2.bias       |    160     |\n",
      "|     layer2.4.conv3.weight     |   102400   |\n",
      "|      layer2.4.bn3.weight      |    640     |\n",
      "|       layer2.4.bn3.bias       |    640     |\n",
      "|     layer2.5.conv1.weight     |   102400   |\n",
      "|      layer2.5.bn1.weight      |    160     |\n",
      "|       layer2.5.bn1.bias       |    160     |\n",
      "|     layer2.5.conv2.weight     |   230400   |\n",
      "|      layer2.5.bn2.weight      |    160     |\n",
      "|       layer2.5.bn2.bias       |    160     |\n",
      "|     layer2.5.conv3.weight     |   102400   |\n",
      "|      layer2.5.bn3.weight      |    640     |\n",
      "|       layer2.5.bn3.bias       |    640     |\n",
      "|     layer3.0.conv1.weight     |   204800   |\n",
      "|      layer3.0.bn1.weight      |    320     |\n",
      "|       layer3.0.bn1.bias       |    320     |\n",
      "|     layer3.0.conv2.weight     |   921600   |\n",
      "|      layer3.0.bn2.weight      |    320     |\n",
      "|       layer3.0.bn2.bias       |    320     |\n",
      "|     layer3.0.conv3.weight     |   409600   |\n",
      "|      layer3.0.bn3.weight      |    1280    |\n",
      "|       layer3.0.bn3.bias       |    1280    |\n",
      "|  layer3.0.downsample.0.weight |   819200   |\n",
      "|  layer3.0.downsample.1.weight |    1280    |\n",
      "|   layer3.0.downsample.1.bias  |    1280    |\n",
      "|     layer3.1.conv1.weight     |   409600   |\n",
      "|      layer3.1.bn1.weight      |    320     |\n",
      "|       layer3.1.bn1.bias       |    320     |\n",
      "|     layer3.1.conv2.weight     |   921600   |\n",
      "|      layer3.1.bn2.weight      |    320     |\n",
      "|       layer3.1.bn2.bias       |    320     |\n",
      "|     layer3.1.conv3.weight     |   409600   |\n",
      "|      layer3.1.bn3.weight      |    1280    |\n",
      "|       layer3.1.bn3.bias       |    1280    |\n",
      "|     layer3.2.conv1.weight     |   409600   |\n",
      "|      layer3.2.bn1.weight      |    320     |\n",
      "|       layer3.2.bn1.bias       |    320     |\n",
      "|     layer3.2.conv2.weight     |   921600   |\n",
      "|      layer3.2.bn2.weight      |    320     |\n",
      "|       layer3.2.bn2.bias       |    320     |\n",
      "|     layer3.2.conv3.weight     |   409600   |\n",
      "|      layer3.2.bn3.weight      |    1280    |\n",
      "|       layer3.2.bn3.bias       |    1280    |\n",
      "|     layer3.3.conv1.weight     |   409600   |\n",
      "|      layer3.3.bn1.weight      |    320     |\n",
      "|       layer3.3.bn1.bias       |    320     |\n",
      "|     layer3.3.conv2.weight     |   921600   |\n",
      "|      layer3.3.bn2.weight      |    320     |\n",
      "|       layer3.3.bn2.bias       |    320     |\n",
      "|     layer3.3.conv3.weight     |   409600   |\n",
      "|      layer3.3.bn3.weight      |    1280    |\n",
      "|       layer3.3.bn3.bias       |    1280    |\n",
      "|     layer3.4.conv1.weight     |   409600   |\n",
      "|      layer3.4.bn1.weight      |    320     |\n",
      "|       layer3.4.bn1.bias       |    320     |\n",
      "|     layer3.4.conv2.weight     |   921600   |\n",
      "|      layer3.4.bn2.weight      |    320     |\n",
      "|       layer3.4.bn2.bias       |    320     |\n",
      "|     layer3.4.conv3.weight     |   409600   |\n",
      "|      layer3.4.bn3.weight      |    1280    |\n",
      "|       layer3.4.bn3.bias       |    1280    |\n",
      "|     layer3.5.conv1.weight     |   409600   |\n",
      "|      layer3.5.bn1.weight      |    320     |\n",
      "|       layer3.5.bn1.bias       |    320     |\n",
      "|     layer3.5.conv2.weight     |   921600   |\n",
      "|      layer3.5.bn2.weight      |    320     |\n",
      "|       layer3.5.bn2.bias       |    320     |\n",
      "|     layer3.5.conv3.weight     |   409600   |\n",
      "|      layer3.5.bn3.weight      |    1280    |\n",
      "|       layer3.5.bn3.bias       |    1280    |\n",
      "|     layer3.6.conv1.weight     |   409600   |\n",
      "|      layer3.6.bn1.weight      |    320     |\n",
      "|       layer3.6.bn1.bias       |    320     |\n",
      "|     layer3.6.conv2.weight     |   921600   |\n",
      "|      layer3.6.bn2.weight      |    320     |\n",
      "|       layer3.6.bn2.bias       |    320     |\n",
      "|     layer3.6.conv3.weight     |   409600   |\n",
      "|      layer3.6.bn3.weight      |    1280    |\n",
      "|       layer3.6.bn3.bias       |    1280    |\n",
      "|     layer3.7.conv1.weight     |   409600   |\n",
      "|      layer3.7.bn1.weight      |    320     |\n",
      "|       layer3.7.bn1.bias       |    320     |\n",
      "|     layer3.7.conv2.weight     |   921600   |\n",
      "|      layer3.7.bn2.weight      |    320     |\n",
      "|       layer3.7.bn2.bias       |    320     |\n",
      "|     layer3.7.conv3.weight     |   409600   |\n",
      "|      layer3.7.bn3.weight      |    1280    |\n",
      "|       layer3.7.bn3.bias       |    1280    |\n",
      "|     layer3.8.conv1.weight     |   409600   |\n",
      "|      layer3.8.bn1.weight      |    320     |\n",
      "|       layer3.8.bn1.bias       |    320     |\n",
      "|     layer3.8.conv2.weight     |   921600   |\n",
      "|      layer3.8.bn2.weight      |    320     |\n",
      "|       layer3.8.bn2.bias       |    320     |\n",
      "|     layer3.8.conv3.weight     |   409600   |\n",
      "|      layer3.8.bn3.weight      |    1280    |\n",
      "|       layer3.8.bn3.bias       |    1280    |\n",
      "|     layer3.9.conv1.weight     |   409600   |\n",
      "|      layer3.9.bn1.weight      |    320     |\n",
      "|       layer3.9.bn1.bias       |    320     |\n",
      "|     layer3.9.conv2.weight     |   921600   |\n",
      "|      layer3.9.bn2.weight      |    320     |\n",
      "|       layer3.9.bn2.bias       |    320     |\n",
      "|     layer3.9.conv3.weight     |   409600   |\n",
      "|      layer3.9.bn3.weight      |    1280    |\n",
      "|       layer3.9.bn3.bias       |    1280    |\n",
      "|     layer4.0.conv1.weight     |   819200   |\n",
      "|      layer4.0.bn1.weight      |    640     |\n",
      "|       layer4.0.bn1.bias       |    640     |\n",
      "|     layer4.0.conv2.weight     |  3686400   |\n",
      "|      layer4.0.bn2.weight      |    640     |\n",
      "|       layer4.0.bn2.bias       |    640     |\n",
      "|     layer4.0.conv3.weight     |  1638400   |\n",
      "|      layer4.0.bn3.weight      |    2560    |\n",
      "|       layer4.0.bn3.bias       |    2560    |\n",
      "|  layer4.0.downsample.0.weight |  3276800   |\n",
      "|  layer4.0.downsample.1.weight |    2560    |\n",
      "|   layer4.0.downsample.1.bias  |    2560    |\n",
      "|     layer4.1.conv1.weight     |  1638400   |\n",
      "|      layer4.1.bn1.weight      |    640     |\n",
      "|       layer4.1.bn1.bias       |    640     |\n",
      "|     layer4.1.conv2.weight     |  3686400   |\n",
      "|      layer4.1.bn2.weight      |    640     |\n",
      "|       layer4.1.bn2.bias       |    640     |\n",
      "|     layer4.1.conv3.weight     |  1638400   |\n",
      "|      layer4.1.bn3.weight      |    2560    |\n",
      "|       layer4.1.bn3.bias       |    2560    |\n",
      "|     layer4.2.conv1.weight     |  1638400   |\n",
      "|      layer4.2.bn1.weight      |    640     |\n",
      "|       layer4.2.bn1.bias       |    640     |\n",
      "|     layer4.2.conv2.weight     |  3686400   |\n",
      "|      layer4.2.bn2.weight      |    640     |\n",
      "|       layer4.2.bn2.bias       |    640     |\n",
      "|     layer4.2.conv3.weight     |  1638400   |\n",
      "|      layer4.2.bn3.weight      |    2560    |\n",
      "|       layer4.2.bn3.bias       |    2560    |\n",
      "|     layer4.3.conv1.weight     |  1638400   |\n",
      "|      layer4.3.bn1.weight      |    640     |\n",
      "|       layer4.3.bn1.bias       |    640     |\n",
      "|     layer4.3.conv2.weight     |  3686400   |\n",
      "|      layer4.3.bn2.weight      |    640     |\n",
      "|       layer4.3.bn2.bias       |    640     |\n",
      "|     layer4.3.conv3.weight     |  1638400   |\n",
      "|      layer4.3.bn3.weight      |    2560    |\n",
      "|       layer4.3.bn3.bias       |    2560    |\n",
      "|     layer4.4.conv1.weight     |  1638400   |\n",
      "|      layer4.4.bn1.weight      |    640     |\n",
      "|       layer4.4.bn1.bias       |    640     |\n",
      "|     layer4.4.conv2.weight     |  3686400   |\n",
      "|      layer4.4.bn2.weight      |    640     |\n",
      "|       layer4.4.bn2.bias       |    640     |\n",
      "|     layer4.4.conv3.weight     |  1638400   |\n",
      "|      layer4.4.bn3.weight      |    2560    |\n",
      "|       layer4.4.bn3.bias       |    2560    |\n",
      "|     layer4.5.conv1.weight     |  1638400   |\n",
      "|      layer4.5.bn1.weight      |    640     |\n",
      "|       layer4.5.bn1.bias       |    640     |\n",
      "|     layer4.5.conv2.weight     |  3686400   |\n",
      "|      layer4.5.bn2.weight      |    640     |\n",
      "|       layer4.5.bn2.bias       |    640     |\n",
      "|     layer4.5.conv3.weight     |  1638400   |\n",
      "|      layer4.5.bn3.weight      |    2560    |\n",
      "|       layer4.5.bn3.bias       |    2560    |\n",
      "| attnpool.positional_embedding |   209920   |\n",
      "|     attnpool.k_proj.weight    |  6553600   |\n",
      "|      attnpool.k_proj.bias     |    2560    |\n",
      "|     attnpool.q_proj.weight    |  6553600   |\n",
      "|      attnpool.q_proj.bias     |    2560    |\n",
      "|     attnpool.v_proj.weight    |  6553600   |\n",
      "|      attnpool.v_proj.bias     |    2560    |\n",
      "|     attnpool.c_proj.weight    |  1638400   |\n",
      "|      attnpool.c_proj.bias     |    640     |\n",
      "+-------------------------------+------------+\n",
      "Total Trainable Params: 87137080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87137080"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model3 = clip.load(\"RN50x4\")[0].visual\n",
    "count_parameters(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "weights_20 = torch.load('checkpoints/multimodal_transformer_layoulmv3/global_step20/mp_rank_00_model_states.pt', map_location='cpu')\n",
    "weights_30 = torch.load('checkpoints/multimodal_transformer_layoulmv3/global_step30/mp_rank_00_model_states.pt', map_location='cpu')\n",
    "weights_40 = torch.load('checkpoints/multimodal_transformer_layoulmv3/global_step40/mp_rank_00_model_states.pt', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['module', 'buffer_names', 'optimizer', 'param_shapes', 'lr_scheduler', 'sparse_tensor_module_names', 'skipped_steps', 'global_steps', 'global_samples', 'dp_world_size', 'mp_world_size', 'ds_config', 'ds_version', 'global_step', 'config'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_20.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "it20 = iter(weights_20['module'].items())\n",
    "it30 = iter(weights_30['module'].items())\n",
    "it40 = iter(weights_40['module'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mnext\u001b[39;49m(it20), \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m,\u001b[39mnext\u001b[39m(it30), \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m,\u001b[39mnext\u001b[39m(it40))\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(next(it20), '\\n',next(it30), '\\n',next(it40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OPT language model...\n",
      "From facebook/galactica-6.7b\n"
     ]
    }
   ],
   "source": [
    "from magma import Magma\n",
    "import torch\n",
    "\n",
    "model = Magma('configs/MAGMA_v1_layoutlmv3.yml', device=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm.model.decoder.layers.0.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.0.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.0.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.0.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.0.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.0.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.0.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.0.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.1.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.1.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.1.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.1.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.1.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.1.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.1.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.1.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.2.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.2.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.2.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.2.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.2.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.2.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.2.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.2.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.3.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.3.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.3.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.3.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.3.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.3.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.3.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.3.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.4.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.4.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.4.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.4.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.4.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.4.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.4.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.4.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.5.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.5.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.5.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.5.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.5.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.5.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.5.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.5.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.6.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.6.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.6.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.6.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.6.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.6.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.6.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.6.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.7.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.7.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.7.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.7.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.7.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.7.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.7.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.7.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.8.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.8.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.8.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.8.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.8.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.8.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.8.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.8.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.9.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.9.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.9.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.9.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.9.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.9.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.9.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.9.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.10.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.10.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.10.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.10.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.10.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.10.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.10.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.10.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.11.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.11.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.11.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.11.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.11.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.11.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.11.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.11.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.12.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.12.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.12.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.12.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.12.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.12.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.12.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.12.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.13.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.13.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.13.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.13.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.13.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.13.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.13.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.13.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.14.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.14.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.14.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.14.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.14.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.14.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.14.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.14.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.15.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.15.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.15.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.15.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.15.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.15.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.15.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.15.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.16.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.16.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.16.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.16.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.16.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.16.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.16.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.16.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.17.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.17.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.17.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.17.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.17.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.17.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.17.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.17.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.18.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.18.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.18.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.18.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.18.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.18.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.18.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.18.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.19.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.19.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.19.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.19.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.19.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.19.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.19.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.19.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.20.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.20.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.20.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.20.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.20.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.20.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.20.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.20.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.21.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.21.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.21.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.21.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.21.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.21.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.21.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.21.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.22.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.22.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.22.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.22.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.22.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.22.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.22.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.22.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.23.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.23.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.23.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.23.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.23.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.23.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.23.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.23.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.24.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.24.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.24.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.24.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.24.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.24.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.24.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.24.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.25.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.25.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.25.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.25.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.25.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.25.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.25.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.25.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.26.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.26.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.26.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.26.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.26.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.26.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.26.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.26.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.27.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.27.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.27.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.27.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.27.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.27.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.27.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.27.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.28.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.28.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.28.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.28.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.28.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.28.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.28.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.28.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.29.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.29.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.29.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.29.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.29.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.29.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.29.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.29.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.30.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.30.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.30.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.30.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.30.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.30.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.30.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.30.fc2.1.adapter.2.bias\n",
      "lm.model.decoder.layers.31.self_attn.adapter.0.weight\n",
      "lm.model.decoder.layers.31.self_attn.adapter.0.bias\n",
      "lm.model.decoder.layers.31.self_attn.adapter.2.weight\n",
      "lm.model.decoder.layers.31.self_attn.adapter.2.bias\n",
      "lm.model.decoder.layers.31.fc2.1.adapter.0.weight\n",
      "lm.model.decoder.layers.31.fc2.1.adapter.0.bias\n",
      "lm.model.decoder.layers.31.fc2.1.adapter.2.weight\n",
      "lm.model.decoder.layers.31.fc2.1.adapter.2.bias\n",
      "image_prefix.enc.cls_token\n",
      "image_prefix.enc.pos_embed\n",
      "image_prefix.enc.embeddings.word_embeddings.weight\n",
      "image_prefix.enc.embeddings.token_type_embeddings.weight\n",
      "image_prefix.enc.embeddings.LayerNorm.weight\n",
      "image_prefix.enc.embeddings.LayerNorm.bias\n",
      "image_prefix.enc.embeddings.position_embeddings.weight\n",
      "image_prefix.enc.embeddings.x_position_embeddings.weight\n",
      "image_prefix.enc.embeddings.y_position_embeddings.weight\n",
      "image_prefix.enc.embeddings.h_position_embeddings.weight\n",
      "image_prefix.enc.embeddings.w_position_embeddings.weight\n",
      "image_prefix.enc.patch_embed.proj.weight\n",
      "image_prefix.enc.patch_embed.proj.bias\n",
      "image_prefix.enc.LayerNorm.weight\n",
      "image_prefix.enc.LayerNorm.bias\n",
      "image_prefix.enc.norm.weight\n",
      "image_prefix.enc.norm.bias\n",
      "image_prefix.enc.encoder.layer.0.attention.self.query.weight\n",
      "image_prefix.enc.encoder.layer.0.attention.self.query.bias\n",
      "image_prefix.enc.encoder.layer.0.attention.self.key.weight\n",
      "image_prefix.enc.encoder.layer.0.attention.self.key.bias\n",
      "image_prefix.enc.encoder.layer.0.attention.self.value.weight\n",
      "image_prefix.enc.encoder.layer.0.attention.self.value.bias\n",
      "image_prefix.enc.encoder.layer.0.attention.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.0.attention.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.0.intermediate.dense.weight\n",
      "image_prefix.enc.encoder.layer.0.intermediate.dense.bias\n",
      "image_prefix.enc.encoder.layer.0.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.0.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.0.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.0.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.1.attention.self.query.weight\n",
      "image_prefix.enc.encoder.layer.1.attention.self.query.bias\n",
      "image_prefix.enc.encoder.layer.1.attention.self.key.weight\n",
      "image_prefix.enc.encoder.layer.1.attention.self.key.bias\n",
      "image_prefix.enc.encoder.layer.1.attention.self.value.weight\n",
      "image_prefix.enc.encoder.layer.1.attention.self.value.bias\n",
      "image_prefix.enc.encoder.layer.1.attention.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.1.attention.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.1.intermediate.dense.weight\n",
      "image_prefix.enc.encoder.layer.1.intermediate.dense.bias\n",
      "image_prefix.enc.encoder.layer.1.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.1.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.1.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.1.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.2.attention.self.query.weight\n",
      "image_prefix.enc.encoder.layer.2.attention.self.query.bias\n",
      "image_prefix.enc.encoder.layer.2.attention.self.key.weight\n",
      "image_prefix.enc.encoder.layer.2.attention.self.key.bias\n",
      "image_prefix.enc.encoder.layer.2.attention.self.value.weight\n",
      "image_prefix.enc.encoder.layer.2.attention.self.value.bias\n",
      "image_prefix.enc.encoder.layer.2.attention.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.2.attention.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.2.intermediate.dense.weight\n",
      "image_prefix.enc.encoder.layer.2.intermediate.dense.bias\n",
      "image_prefix.enc.encoder.layer.2.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.2.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.2.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.2.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.3.attention.self.query.weight\n",
      "image_prefix.enc.encoder.layer.3.attention.self.query.bias\n",
      "image_prefix.enc.encoder.layer.3.attention.self.key.weight\n",
      "image_prefix.enc.encoder.layer.3.attention.self.key.bias\n",
      "image_prefix.enc.encoder.layer.3.attention.self.value.weight\n",
      "image_prefix.enc.encoder.layer.3.attention.self.value.bias\n",
      "image_prefix.enc.encoder.layer.3.attention.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.3.attention.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.3.intermediate.dense.weight\n",
      "image_prefix.enc.encoder.layer.3.intermediate.dense.bias\n",
      "image_prefix.enc.encoder.layer.3.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.3.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.3.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.3.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.4.attention.self.query.weight\n",
      "image_prefix.enc.encoder.layer.4.attention.self.query.bias\n",
      "image_prefix.enc.encoder.layer.4.attention.self.key.weight\n",
      "image_prefix.enc.encoder.layer.4.attention.self.key.bias\n",
      "image_prefix.enc.encoder.layer.4.attention.self.value.weight\n",
      "image_prefix.enc.encoder.layer.4.attention.self.value.bias\n",
      "image_prefix.enc.encoder.layer.4.attention.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.4.attention.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.4.intermediate.dense.weight\n",
      "image_prefix.enc.encoder.layer.4.intermediate.dense.bias\n",
      "image_prefix.enc.encoder.layer.4.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.4.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.4.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.4.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.5.attention.self.query.weight\n",
      "image_prefix.enc.encoder.layer.5.attention.self.query.bias\n",
      "image_prefix.enc.encoder.layer.5.attention.self.key.weight\n",
      "image_prefix.enc.encoder.layer.5.attention.self.key.bias\n",
      "image_prefix.enc.encoder.layer.5.attention.self.value.weight\n",
      "image_prefix.enc.encoder.layer.5.attention.self.value.bias\n",
      "image_prefix.enc.encoder.layer.5.attention.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.5.attention.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.5.intermediate.dense.weight\n",
      "image_prefix.enc.encoder.layer.5.intermediate.dense.bias\n",
      "image_prefix.enc.encoder.layer.5.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.5.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.5.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.5.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.6.attention.self.query.weight\n",
      "image_prefix.enc.encoder.layer.6.attention.self.query.bias\n",
      "image_prefix.enc.encoder.layer.6.attention.self.key.weight\n",
      "image_prefix.enc.encoder.layer.6.attention.self.key.bias\n",
      "image_prefix.enc.encoder.layer.6.attention.self.value.weight\n",
      "image_prefix.enc.encoder.layer.6.attention.self.value.bias\n",
      "image_prefix.enc.encoder.layer.6.attention.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.6.attention.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.6.intermediate.dense.weight\n",
      "image_prefix.enc.encoder.layer.6.intermediate.dense.bias\n",
      "image_prefix.enc.encoder.layer.6.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.6.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.6.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.6.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.7.attention.self.query.weight\n",
      "image_prefix.enc.encoder.layer.7.attention.self.query.bias\n",
      "image_prefix.enc.encoder.layer.7.attention.self.key.weight\n",
      "image_prefix.enc.encoder.layer.7.attention.self.key.bias\n",
      "image_prefix.enc.encoder.layer.7.attention.self.value.weight\n",
      "image_prefix.enc.encoder.layer.7.attention.self.value.bias\n",
      "image_prefix.enc.encoder.layer.7.attention.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.7.attention.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.7.intermediate.dense.weight\n",
      "image_prefix.enc.encoder.layer.7.intermediate.dense.bias\n",
      "image_prefix.enc.encoder.layer.7.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.7.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.7.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.7.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.8.attention.self.query.weight\n",
      "image_prefix.enc.encoder.layer.8.attention.self.query.bias\n",
      "image_prefix.enc.encoder.layer.8.attention.self.key.weight\n",
      "image_prefix.enc.encoder.layer.8.attention.self.key.bias\n",
      "image_prefix.enc.encoder.layer.8.attention.self.value.weight\n",
      "image_prefix.enc.encoder.layer.8.attention.self.value.bias\n",
      "image_prefix.enc.encoder.layer.8.attention.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.8.attention.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.8.intermediate.dense.weight\n",
      "image_prefix.enc.encoder.layer.8.intermediate.dense.bias\n",
      "image_prefix.enc.encoder.layer.8.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.8.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.8.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.8.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.9.attention.self.query.weight\n",
      "image_prefix.enc.encoder.layer.9.attention.self.query.bias\n",
      "image_prefix.enc.encoder.layer.9.attention.self.key.weight\n",
      "image_prefix.enc.encoder.layer.9.attention.self.key.bias\n",
      "image_prefix.enc.encoder.layer.9.attention.self.value.weight\n",
      "image_prefix.enc.encoder.layer.9.attention.self.value.bias\n",
      "image_prefix.enc.encoder.layer.9.attention.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.9.attention.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.9.intermediate.dense.weight\n",
      "image_prefix.enc.encoder.layer.9.intermediate.dense.bias\n",
      "image_prefix.enc.encoder.layer.9.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.9.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.9.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.9.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.10.attention.self.query.weight\n",
      "image_prefix.enc.encoder.layer.10.attention.self.query.bias\n",
      "image_prefix.enc.encoder.layer.10.attention.self.key.weight\n",
      "image_prefix.enc.encoder.layer.10.attention.self.key.bias\n",
      "image_prefix.enc.encoder.layer.10.attention.self.value.weight\n",
      "image_prefix.enc.encoder.layer.10.attention.self.value.bias\n",
      "image_prefix.enc.encoder.layer.10.attention.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.10.attention.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.10.intermediate.dense.weight\n",
      "image_prefix.enc.encoder.layer.10.intermediate.dense.bias\n",
      "image_prefix.enc.encoder.layer.10.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.10.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.10.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.10.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.11.attention.self.query.weight\n",
      "image_prefix.enc.encoder.layer.11.attention.self.query.bias\n",
      "image_prefix.enc.encoder.layer.11.attention.self.key.weight\n",
      "image_prefix.enc.encoder.layer.11.attention.self.key.bias\n",
      "image_prefix.enc.encoder.layer.11.attention.self.value.weight\n",
      "image_prefix.enc.encoder.layer.11.attention.self.value.bias\n",
      "image_prefix.enc.encoder.layer.11.attention.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.11.attention.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.layer.11.intermediate.dense.weight\n",
      "image_prefix.enc.encoder.layer.11.intermediate.dense.bias\n",
      "image_prefix.enc.encoder.layer.11.output.dense.weight\n",
      "image_prefix.enc.encoder.layer.11.output.dense.bias\n",
      "image_prefix.enc.encoder.layer.11.output.LayerNorm.weight\n",
      "image_prefix.enc.encoder.layer.11.output.LayerNorm.bias\n",
      "image_prefix.enc.encoder.rel_pos_bias.weight\n",
      "image_prefix.enc.encoder.rel_pos_x_bias.weight\n",
      "image_prefix.enc.encoder.rel_pos_y_bias.weight\n",
      "image_prefix.proj.weight\n",
      "image_prefix.proj.bias\n",
      "image_prefix.ln.weight\n",
      "image_prefix.ln.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        print(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "292acc92c4847c296ce710421ddf710c70c3b31759adb2c8d52ff24c0354894e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
