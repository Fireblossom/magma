[
  {
    "sim": 0.4597370511789338,
    "gen": {
      "title": "Hybrid Position/Force Control for Hydraulic Actuators",
      "url": "https://www.semanticscholar.org/paper/9b52ecf8550fcd8d3a560a6bc397aacaa6d1cfd4",
      "abstract": "In this paper a novel hybrid position/force control with autonomous switching between both control modes is introduced for hydraulic actuators. A hybrid position/force control structure with feed-forwarding, full-state feedback including integral control error, pre-compensator of the dead-zone nonlinearity and low-pass filtering of the control value is designed. Controller gains are obtained via local linearization and pole placement accomplished separately for the position and force control. A hysteresis-based autonomous switching is integrated into the closed control loop, while multiple Lyapunov function based approach is applied for stability analysis of the entire hybrid control system. Experimental evaluation is shown on the developed test setup with the standard industrial hydraulic cylinders, and that for different motion and load profiles.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "topics": [
        "force control",
        "integral control error",
        "multiple Lyapunov function based approach",
        "load profiles",
        "hydraulic actuators",
        "entire hybrid control system",
        "autonomous switching",
        "closed control loop",
        "stability analysis",
        "different motion",
        "control value",
        "control modes",
        "A hybrid position/force control structure",
        "novel hybrid position/force control",
        "compensator",
        "different motion and load profiles",
        "pole placement",
        "position and force control"
      ]
    },
    "org": {
      "title": "Bayesian inference for the stochastic identification of elastoplastic material parameters: Introduction, misconceptions and insights",
      "url": "https://www.semanticscholar.org/paper/4812f55ea61ab1a8e37937601d32944a434b31c8",
      "abstract": "We discuss Bayesian inference (BI) for the probabilistic identification of material parameters. This contribution aims to shed light on the use of BI for the identification of elastoplastic material parameters. For this purpose a single spring is considered, for which the stress-strain curves are artificially created. Besides offering a didactic introduction to BI, this paper proposes an approach to incorporate statistical errors both in the measured stresses, and in the measured strains. It is assumed that the uncertainty is only due to measurement errors and the material is homogeneous. Furthermore, a number of possible misconceptions on BI are highlighted based on the purely elastic case.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "material parameters",
        "elastoplastic material parameters",
        "statistical errors",
        "measurement errors",
        "BI",
        "measured stresses",
        "stress-strain curves",
        "Bayesian inference",
        "possible misconceptions",
        "light",
        "probabilistic identification",
        "material",
        "Bayesian",
        "purely elastic case",
        "identification"
      ]
    }
  },
  {
    "sim": 0.5519400305551116,
    "gen": {
      "title": "Safe Trajectory Generation for Complex Urban Environments Using Spatio-Temporal Semantic Corridor",
      "url": "https://www.semanticscholar.org/paper/2414d64831b1c3fe698f6b296fe69ac539f3e539",
      "abstract": "Planning safe trajectories for autonomous vehicles in complex urban environments is challenging since there are numerous semantic elements (such as dynamic agents, traffic lights, and speed limits) to consider. These semantic elements may have different mathematical descriptions, such as obstacle, constraint, and cost. It is non-trivial to tune the effects from different combinations of semantic elements for a stable and generalizable behavior. In this letter, we propose a novel unified spatio-temporal semantic corridor (SSC) structure, which provides a level of abstraction for different types of semantic elements. The SSC consists of a series of mutually connected collision-free cubes with dynamical constraints posed by the semantic elements in the spatio-temporal domain. The trajectory generation problem then boils down to a general quadratic programming formulation. Thanks to the unified SSC representation, our framework can generalize to any combination of semantic elements. Moreover, our formulation provides a theoretical guarantee that the entire trajectory is safe and constraint-satisfied, by using the convex hull and hodograph properties of piecewise B\u00e9zier curve parameterization. We also release the code of our method to accommodate benchmarking.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "topics": [
        "numerous semantic elements",
        "piecewise B\u00e9zier curve parameterization",
        "different combinations",
        "different mathematical descriptions",
        "different types",
        "speed limits",
        "semantic elements",
        "safe trajectories",
        "dynamical constraints",
        "traffic lights",
        "cost",
        "dynamic agents",
        "complex urban environments",
        "constraint"
      ]
    },
    "org": {
      "title": "An Optimal Bearing-Only-Information Strategy for Unmanned Aircraft Collision Avoidance",
      "url": "https://www.semanticscholar.org/paper/d4269bc92a54ca0611baa3adf78f16c8763c6d94",
      "abstract": "This paper presents a novel collision avoidance strategy for unmanned aircraft detect and avoid that requires only information about the relative bearing angle between an aircraft and hazard. It is shown that this bearing-only strategy can be conceived as the solution to a novel differential game formulation of collision avoidance, and has several intuitive properties including maximising the instantaneous range acceleration in situations where the hazard is stationary or has a finite turn rate. The performance of the bearing-only strategy is illustrated in simulations based on test cases drawn from draft minimum operating performance standards for unmanned aircraft detect and avoid systems.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "topics": [
        "draft minimum operating performance standards",
        "information",
        "hazard",
        "intuitive properties",
        "collision avoidance",
        "finite turn rate",
        "test cases",
        "novel collision avoidance strategy",
        "systems",
        "instantaneous range acceleration",
        "relative bearing angle",
        "novel differential game formulation",
        "simulations",
        "aircraft",
        "unmanned aircraft",
        "unmanned aircraft detect and avoid systems"
      ]
    }
  },
  {
    "sim": 0.5399763138531605,
    "gen": {
      "title": "Game Theory for Signal Processing in Networks",
      "url": "https://www.semanticscholar.org/paper/d88fba1b939b3eb785fa4c7b86750e74d1582410",
      "abstract": "In this tutorial, the basics of game theory are introduced along with an overview of its most recent and emerging applications in signal processing. One of the main features of this contribution is to gather in a single paper some fundamental game-theoretic notions and tools which, over the past few years, have become widely spread over a large number of papers. In particular, both strategic-form and coalition-form games are described in details while the key connections and differences between them are outlined. Moreover, a particular attention is also devoted to clarify the connections between strategic-form games and distributed optimization and learning algorithms. Beyond an introduction to the basic concepts and main solution approaches, several carefully designed examples are provided to allow a better understanding of how to apply the described tools.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "papers",
        "game theory",
        "signal processing",
        "tools",
        "past few years",
        "strategic-form games",
        "fundamental game-theoretic notions",
        "main solution approaches",
        "single paper",
        "described tools",
        "differences",
        "large number",
        "details",
        "optimization and learning algorithms",
        "key connections",
        "distributed optimization and learning algorithms"
      ]
    },
    "org": {
      "title": "AIXIjs: A Software Demo for General Reinforcement Learning",
      "url": "https://www.semanticscholar.org/paper/1234cd20688261084f6223909dc910c935235f7a",
      "abstract": "Reinforcement learning is a general and powerful framework with which to study and implement artificial intelligence. Recent advances in deep learning have enabled RL algorithms to achieve impressive performance in restricted domains such as playing Atari video games (Mnih et al., 2015) and, recently, the board game Go (Silver et al., 2016). However, we are still far from constructing a generally intelligent agent. Many of the obstacles and open questions are conceptual: What does it mean to be intelligent? How does one explore and learn optimally in general, unknown environments? What, in fact, does it mean to be optimal in the general sense? The universal Bayesian agent AIXI (Hutter, 2005) is a model of a maximally intelligent agent, and plays a central role in the sub-field of general reinforcement learning (GRL). Recently, AIXI has been shown to be flawed in important ways; it doesn't explore enough to be asymptotically optimal (Orseau, 2010), and it can perform poorly with certain priors (Leike and Hutter, 2015). Several variants of AIXI have been proposed to attempt to address these shortfalls: among them are entropy-seeking agents (Orseau, 2011), knowledge-seeking agents (Orseau et al., 2013), Bayes with bursts of exploration (Lattimore, 2013), MDL agents (Leike, 2016a), Thompson sampling (Leike et al., 2016), and optimism (Sunehag and Hutter, 2015). We present AIXIjs, a JavaScript implementation of these GRL agents. This implementation is accompanied by a framework for running experiments against various environments, similar to OpenAI Gym (Brockman et al., 2016), and a suite of interactive demos that explore different properties of the agents, similar to REINFORCEjs (Karpathy, 2015). We use AIXIjs to present numerous experiments illustrating fundamental properties of, and differences between, these agents.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "MDL agents",
        "Mnih et al.",
        "al",
        "Hutter",
        "Leike et al.",
        "Leike",
        "Atari video games",
        "knowledge-seeking agents",
        "entropy-seeking agents",
        "Thompson sampling",
        "Orseau",
        "Reinforcement learning",
        "GRL agents",
        "Silver et al",
        "interactive demos",
        "The universal Bayesian agent",
        "different properties"
      ]
    }
  },
  {
    "sim": 0.672204235112844,
    "gen": {
      "title": "Ultra-Reliable and Low-Latency Short-Packet Communications for Multihop MIMO Relaying",
      "url": "https://www.semanticscholar.org/paper/61191eba24c8b1c872eecff04f5d455dc5323195",
      "abstract": "This work considers the multihop multiple-input multiple-output relay network under short-packet communications to facilitate not only ultra-reliability but also low-latency communications. We assume that the transmit antenna selection (TAS) scheme is utilized at the transmit side, whereas either selection combining (SC) or maximum ratio combining (MRC) is leveraged at the receive side to achieve diversity gains. For quasistatic Rayleigh fading channels and the finite-blocklength regime, we derive the approximate closed-form expressions of the end-toend (e2e) block error rate (BLER) for both the TAS/MRC and TAS/SC schemes. The asymptotic performance in the high signalto-noise ratio regime is derived, from which the comparison of TAS/MRC and TAS/SC schemes in terms of the diversity order, e2e BLER loss, and SNR gap is provided. The e2e latency and throughputs are also analyzed for the considered schemes. The correctness of our analysis is confirmed via Monte Carlo simulations.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering",
        "Mathematics"
      ],
      "topics": [
        "TAS",
        "e2e BLER loss",
        "diversity gains",
        "SNR gap",
        "MRC",
        "SC",
        "TAS) scheme",
        "Monte Carlo simulations",
        "TAS/MRC",
        "SNR",
        "TAS/SC",
        "ultra-reliability but also low-latency communications",
        "short-packet communications",
        "terms",
        "low-latency communications",
        "reliability",
        "TAS/MRC and TAS/SC schemes",
        "considered schemes",
        "BLER",
        "diversity order"
      ]
    },
    "org": {
      "title": "Error Probability Bounds for Gaussian Channels Under Maximal and Average Power Constraints",
      "url": "https://www.semanticscholar.org/paper/ea2db46ec9a0c89eb2b832a26d7f08e474f7f782",
      "abstract": "This paper studies the performance of block coding on an additive white Gaussian noise channel under different power limitations at the transmitter. New lower bounds are presented for the minimum error probability of codes satisfying maximal and average power constraints. These bounds are tighter than previous results in the finite blocklength regime, and yield a better understanding on the structure of good codes under an average power limitation. Evaluation of these bounds for short and moderate blocklengths is also discussed.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "different power limitations",
        "good codes",
        "average power limitation",
        "maximal and average power constraints",
        "codes",
        "additive white Gaussian noise channel",
        "Gaussian",
        "New lower bounds",
        "previous results",
        "transmitter",
        "finite blocklength regime",
        "short and moderate blocklengths",
        "better understanding",
        "minimum error probability",
        "Evaluation",
        "block coding"
      ]
    }
  },
  null,
  null,
  null,
  {
    "sim": 0.29926594193984346,
    "gen": {
      "title": "Exploiting Spatial Interference Alignment and Opportunistic Scheduling in the Downlink of Interference-Limited Systems",
      "url": "https://www.semanticscholar.org/paper/bdb7f06971be52116cafcc19093e4cbd28fd2752",
      "abstract": "In this paper, we analyze the performance of single-stream and multistream spatial multiplexing (SM) systems employing opportunistic scheduling in the presence of interference. In the proposed downlink framework, every active user reports the postprocessing signal-to-interference-plus-noise power ratio (post-SINR) or the receiver-specific mutual information (MI) to its own transmitter using a feedback channel. The combination of scheduling and multiantenna receiver processing leads to substantial interference suppression gain. Specifically, we show that opportunistic scheduling exploits the spatial interference alignment (SIA) property inherent to a multiuser system for effective interference mitigation. We obtain bounds for the outage probability and the sum outage capacity for single-stream and multistream SM employing real or complex encoding for a symmetric interference channel (SIC) model. The techniques considered in this paper are optimal in different operating regimes. We show that the sum outage capacity can be maximized by reducing the SM rate to a value less than the maximum allowed value. The optimal SM rate depends on the number of interferers and the number of available active users. In particular, we show that the generalized multiuser SM (MU SM) method employing real-valued encoding provides a performance that is either comparable or significantly higher than that of MU SM employing complex encoding. A combination of analysis and simulation is used to describe the tradeoff between the multiplexing rate and the sum outage capacity for different antenna configurations.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering",
        "Mathematics"
      ],
      "topics": [
        "substantial interference suppression gain",
        "effective interference mitigation",
        "interference",
        "complex encoding",
        "post-SINR",
        "MU SM",
        "maximum allowed value",
        "available active users",
        "SIC",
        "SM",
        "symmetric interference channel",
        "different antenna configurations",
        "different operating regimes",
        "opportunistic scheduling",
        "MI",
        "MU SM employing",
        "multiantenna receiver processing",
        "SINR"
      ]
    },
    "org": {
      "title": "Application of polynomial vector (pv) processing to improve the estimation performance of bio diesel in variable compression ratio diesel engine",
      "url": "https://www.semanticscholar.org/paper/475f90c4ff2fe07a80847eccc9b28b63ee6d4006",
      "abstract": "This paper presents the implementation of polynomial vector back propagation algorithm (PVBPA) for estimating the power, torque, specific fuel consumption and presence of carbon monoxide, hydrocarbons in the emission of a direct injection diesel engine. Experimental readings were obtained using the biodiesel prepared form the waste low quality cooking oil collected from the canteen of Sri Sairam Engineering College, India.. This waste cooking oil was due to the preparation of varieties of food (vegetables fried and non vegetarian). Over more than a week, trans esterification was done in chemical lab and the biodiesel was obtained. The biodiesel was mixed in proportions of 10%, 20%, 30%, 40%, 50% with remaining combinations of the diesel supplied by the Indian government. Variable compression ratio (VCR) diesel engine with single cylinder, four stroke diesel type was used. The outputs of the engine as power, torque and specific fuel consumption were obtained from the computational facility attached to the engine. The data collected for different input conditions of the engine was further used to train (PVBPA). The trained PVBPA network was further used to predict the power, torque and brake specific fuel consumption (SFC) for different speed, biodiesel and diesel combinations and full load condition. The estimation performance of the PVBPA network is discussed.",
      "fieldsOfStudy": [
        "Engineering",
        "Computer Science"
      ],
      "topics": [
        "specific fuel consumption",
        "fuel consumption",
        "torque",
        "load condition",
        "different input conditions",
        "direct injection diesel engine",
        "power",
        "biodiesel",
        "Sri Sairam Engineering College",
        "cooking oil",
        "single cylinder",
        "PVBPA",
        "different speed",
        "carbon monoxide",
        "remaining combinations",
        "polynomial vector back propagation algorithm",
        "India",
        "stroke diesel type",
        "power, torque and brake specific fuel consumption"
      ]
    }
  },
  {
    "sim": 0.5395412130309256,
    "gen": {
      "title": "No bad local minima: Data independent training error guarantees for multilayer neural networks",
      "url": "https://www.semanticscholar.org/paper/97616121e0153bdd279630a645751d6616451f30",
      "abstract": "We use smoothed analysis techniques to provide guarantees on the training loss of Multilayer Neural Networks (MNNs) at differentiable local minima. Specifically, we examine MNNs with piecewise linear activation functions, quadratic loss and a single output, under mild over-parametrization. We prove that for a MNN with one hidden layer, the training error is zero at every differentiable local minimum, for almost every dataset and dropout-like noise realization. We then extend these results to the case of more than one hidden layer. Our theoretical guarantees assume essentially nothing on the training data, and are verified numerically. These results suggest why the highly non-convex loss of such MNNs can be easily optimized using local updates (e.g., stochastic gradient descent), as observed empirically.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "local updates",
        "quadratic loss",
        "Multilayer Neural Networks",
        "piecewise linear activation functions",
        "MNNs",
        "differentiable local minimum",
        "smoothed analysis techniques",
        "mild over-parametrization",
        "MNNs",
        "guarantees",
        "training error",
        "training data",
        "dataset and dropout-like noise realization",
        "dropout-like noise realization"
      ]
    },
    "org": {
      "title": "Network Horizon Dynamics I: Qualitative Aspects",
      "url": "https://www.semanticscholar.org/paper/185d8ea8e2bfe28f9551a8f69f74130de2d96c28",
      "abstract": "Mostly acyclic directed networks, treated mathematically as directed graphs, arise in machine learning, biology, social science, physics, and other applications. Newman [1] has noted the mathematical challenges of such networks. In this series of papers, we study their connectivity properties, focusing on three types of phase transitions that affect horizon sizes for typical nodes. The first two types involve the familiar emergence of giant components as average local connectivity increases, while the third type involves small-world horizon growth at variable distance from a typical node. In this first paper, we focus on qualitative behavior, simulations, and applications, leaving formal considerations for subsequent papers. We explain how such phase transitions distinguish deep neural networks from shallow machine learning architectures, and propose hybrid local/random network designs with surprising connectivity advantages. We also propose a small-world approach to the horizon problem in the cosmology of the early universe as a novel alternative to the inflationary hypothesis of Guth and Linde.",
      "fieldsOfStudy": [
        "Mathematics",
        "Physics",
        "Computer Science"
      ],
      "topics": [
        "subsequent papers",
        "average local connectivity increases",
        "typical nodes",
        "surprising connectivity advantages",
        "papers",
        "formal considerations",
        "shallow machine learning architectures",
        "applications",
        "deep neural networks",
        "machine learning",
        "directed networks",
        "networks",
        "phase transitions",
        "horizon sizes",
        "average local connectivity",
        "acyclic directed networks"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.3386374664828551,
    "gen": {
      "title": "Towards the use of Remote Sensing for Identification of Building Damage, Destruction, and Defensive Actions at Wildland-Urban Interface Fires",
      "url": "https://www.semanticscholar.org/paper/6f927b5018ef6243d7007ba31b2b194e743d2342",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    },
    "org": {
      "title": "AIQL: Enabling Efficient Attack Investigation from System Monitoring Data",
      "url": "https://www.semanticscholar.org/paper/ebb55bcad2a4fcc840b4a8abc578eb37059ac9d6",
      "abstract": "The need for countering Advanced Persistent Threat (APT) attacks has led to the solutions that ubiquitously monitor system activities in each host, and perform timely attack investigation over the monitoring data for analyzing attack provenance. However, existing query systems based on relational databases and graph databases lack language constructs to express key properties of major attack behaviors, and often execute queries inefficiently since their semantics-agnostic design cannot exploit the properties of system monitoring data to speed up query execution. \nTo address this problem, we propose a novel query system built on top of existing monitoring tools and databases, which is designed with novel types of optimizations to support timely attack investigation. Our system provides (1) domain-specific data model and storage for scaling the storage, (2) a domain-specific query language, Attack Investigation Query Language (AIQL) that integrates critical primitives for attack investigation, and (3) an optimized query engine based on the characteristics of the data and the semantics of the queries to efficiently schedule the query execution. We deployed our system in NEC Labs America comprising 150 hosts and evaluated it using 857 GB of real system monitoring data (containing 2.5 billion events). Our evaluations on a real-world APT attack and a broad set of attack behaviors show that our system surpasses existing systems in both efficiency (124x over PostgreSQL, 157x over Neo4j, and 16x over Greenplum) and conciseness (SQL, Neo4j Cypher, and Splunk SPL contain at least 2.4x more constraints than AIQL).",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "timely attack investigation",
        "major attack behaviors",
        "attack provenance",
        "query execution",
        "queries",
        "existing systems",
        "system activities",
        "system",
        "critical primitives",
        "data",
        "existing monitoring tools",
        "AIQL",
        "real system monitoring data",
        "novel query system"
      ]
    }
  },
  {
    "sim": 0.519598515027689,
    "gen": {
      "title": "Reinforcement Learning with Unsupervised Auxiliary Tasks",
      "url": "https://www.semanticscholar.org/paper/d7bd6e3addd8bc8e2e154048300eea15f030ed33",
      "abstract": "Deep reinforcement learning agents have achieved state-of-the-art results by directly maximising cumulative reward. However, environments contain a much wider variety of possible training signals. In this paper, we introduce an agent that also maximises many other pseudo-reward functions simultaneously by reinforcement learning. All of these tasks share a common representation that, like unsupervised learning, continues to develop in the absence of extrinsic rewards. We also introduce a novel mechanism for focusing this representation upon extrinsic rewards, so that learning can rapidly adapt to the most relevant aspects of the actual task. Our agent significantly outperforms the previous state-of-the-art on Atari, averaging 880\\% expert human performance, and a challenging suite of first-person, three-dimensional \\emph{Labyrinth} tasks leading to a mean speedup in learning of 10$\\times$ and averaging 87\\% expert human performance on Labyrinth.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "extrinsic rewards",
        "reinforcement learning",
        "unsupervised learning",
        "Deep reinforcement learning agents",
        "cumulative reward",
        "learning",
        "possible training signals",
        "pseudo-reward functions",
        "87\\%",
        "Labyrinth",
        "actual task",
        "880\\% expert human performance",
        "tasks",
        "10$\\times$"
      ]
    },
    "org": {
      "title": "Evolutionary Approach to Collectible Card Game Arena Deckbuilding using Active Genes",
      "url": "https://www.semanticscholar.org/paper/dc42847839337f306692a1bb4ad84cbaad8432c5",
      "abstract": "In this paper, we evolve a card-choice strategy for the arena mode of Legends of Code and Magic, a programming game inspired by popular collectible card games like Hearthstone or TES: Legends. In the arena game mode, before each match, a player has to construct his deck choosing cards one by one from the previously unknown options. Such a scenario is difficult from the optimization point of view, as not only the fitness function is non-deterministic, but its value, even for a given problem instance, is impossible to be calculated directly and can only be estimated with simulation-based approaches. We propose a variant of the evolutionary algorithm that uses a concept of an active gene to reduce the range of the operators only to generation-specific subsequences of the genotype. Thus, we batched learning process and constrained evolutionary updates only to the cards relevant for the particular draft, without forgetting the knowledge from the previous tests. We developed and tested various implementations of this idea, investigating their performance by taking into account the computational cost of each variant. Performed experiments show that some of the introduced active-genes algorithms tend to learn faster and produce statistically better draft policies than the compared methods.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "popular collectible card games",
        "cards",
        "Legends",
        "simulation-based approaches",
        "evolutionary updates",
        "TES",
        "arena game mode",
        "account",
        "statistically better draft policies",
        "given problem instance",
        "Hearthstone",
        "implementations",
        "generation-specific subsequences",
        "Magic",
        "previous tests",
        "Code",
        "programming game",
        "TES: Legends"
      ]
    }
  },
  null,
  {
    "sim": 0.6335316426280091,
    "gen": {
      "title": "Physics-Based Dexterous Manipulations with Estimated Hand Poses and Residual Reinforcement Learning",
      "url": "https://www.semanticscholar.org/paper/53e36185f1e98018f6d4d6e573b2cbbd5a984619",
      "abstract": "Dexterous manipulation of objects in virtual environments with our bare hands, by using only a depth sensor and a state-of-the-art 3D hand pose estimator (HPE), is challenging. While virtual environments are ruled by physics, e.g. object weights and surface frictions, the absence of force feedback makes the task challenging, as even slight inaccuracies on finger tips or contact points from HPE may make the interactions fail. Prior arts simply generate contact forces in the direction of the fingers\u2019 closures, when finger joints penetrate virtual objects. Although useful for simple grasping scenarios, they cannot be applied to dexterous manipulations such as inhand manipulation. Existing reinforcement learning (RL) and imitation learning (IL) approaches train agents that learn skills by using task-specific rewards, without considering any online user input. In this work, we propose to learn a model that maps noisy input hand poses to target virtual poses, which introduces the needed contacts to accomplish the tasks on a physics simulator. The agent is trained in a residual setting by using a model-free hybrid RL+IL approach. A 3D hand pose estimation reward is introduced leading to an improvement on HPE accuracy when the physics-guided corrected target poses are remapped to the input space. As the model corrects HPE errors by applying minor but crucial joint displacements for contacts, this helps to keep the generated motion visually close to the user input. Since HPE sequences performing successful virtual interactions do not exist, a data generation scheme to train and evaluate the system is proposed. We test our framework in two applications that use hand pose estimates for dexterous manipulations: hand-object interactions in VR and hand-object motion reconstruction in-the-wild. Experiments show that the proposed method outperforms various RL/IL baselines and the simple prior art of enforcing hand closure, both in task success and hand pose accuracy.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "noisy input hand poses",
        "hand closure",
        "virtual poses",
        "hand",
        "virtual objects",
        "successful virtual interactions",
        "contact forces",
        "HPE accuracy",
        "virtual environments",
        "contact points",
        "dexterous manipulations",
        "task success",
        "inhand manipulation",
        "hand pose estimates",
        "object weights",
        "finger tips"
      ]
    },
    "org": {
      "title": "Towards Empathic Deep Q-Learning",
      "url": "https://www.semanticscholar.org/paper/a1bc46541f161bb216498b0496589afc98e8a793",
      "abstract": "As reinforcement learning (RL) scales to solve increasingly complex tasks, interest continues to grow in the fields of AI safety and machine ethics. As a contribution to these fields, this paper introduces an extension to Deep Q-Networks (DQNs), called Empathic DQN, that is loosely inspired both by empathy and the golden rule (\"Do unto others as you would have them do unto you\"). Empathic DQN aims to help mitigate negative side effects to other agents resulting from myopic goal-directed behavior. We assume a setting where a learning agent coexists with other independent agents (who receive unknown rewards), where some types of reward (e.g. negative rewards from physical harm) may generalize across agents. Empathic DQN combines the typical (self-centered) value with the estimated value of other agents, by imagining (by its own standards) the value of it being in the other's situation (by considering constructed states where both agents are swapped). Proof-of-concept results in two gridworld environments highlight the approach's potential to decrease collateral harms. While extending Empathic DQN to complex environments is non-trivial, we believe that this first step highlights the potential of bridge-work between machine ethics and RL to contribute useful priors for norm-abiding RL agents.",
      "fieldsOfStudy": [
        "Computer Science",
        "Psychology"
      ],
      "topics": [
        "agents",
        "independent agents",
        "agents",
        "unknown rewards",
        "norm-abiding RL agents",
        "reward",
        "machine ethics",
        "physical harm",
        "RL",
        "collateral harms",
        "useful priors",
        "negative side effects",
        "learning agent",
        "complex environments",
        "constructed states"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.39266564300092477,
    "gen": {
      "title": "Learning Associative Inference Using Fast Weight Memory",
      "url": "https://www.semanticscholar.org/paper/5e11e806d24dd80ecf0f91e7aacedbba8d9fd6fc",
      "abstract": "Humans can quickly associate stimuli to solve problems in novel contexts. Our novel neural network model learns state representations of facts that can be composed to perform such associative inference. To this end, we augment the LSTM model with an associative memory, dubbed Fast Weight Memory (FWM). Through differentiable operations at every step of a given input sequence, the LSTM updates and maintains compositional associations stored in the rapidly changing FWM weights. Our model is trained end-to-end by gradient descent and yields excellent performance on compositional language reasoning problems, meta-reinforcement-learning for POMDPs, and small-scale word-level language modelling.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "compositional language reasoning problems",
        "FWM",
        "associative inference",
        "Fast Weight Memory",
        "compositional associations",
        "novel contexts",
        "problems",
        "small-scale word-level language modelling",
        "POMDPs",
        "state representations",
        "rapidly changing FWM weights",
        "gradient descent",
        "facts",
        "end",
        "associative memory",
        "meta-reinforcement-learning",
        "excellent performance"
      ]
    },
    "org": {
      "title": "Multiple topic identification in human/human conversations",
      "url": "https://www.semanticscholar.org/paper/caadbab46328eb6beb1deea9dd7c8f2291584a3a",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  null,
  {
    "sim": 0.4763512549798993,
    "gen": {
      "title": "MobiL: A 3-dimensional localization scheme for Mobile Underwater Sensor Networks",
      "url": "https://www.semanticscholar.org/paper/8547c195451e7fc57d2ee959e05252421b8343ba",
      "abstract": "In this paper, we introduce a 3-dimensional, distributed, iterative, and \u2018silent\u2019 localization protocol for Mobile Underwater Sensor Networks (MUSNs) named as Mobility Assisted Localization Scheme (MobiL). The existing solutions addressing the localization problem in underwater sensor networks (UWSNs) either consider the sensor nodes to be stationary or require powerful nodes, which can directly communicate with the surface sinks. Such assumptions are not applicable in MUSNs, where sensor nodes are affected by passive node mobility and the acoustic communication channel is severely impaired by high propagation loss. On the other hand, MobiL requires only three anchor nodes capable of providing the initial location beacon and all other nodes are ordinary sensor nodes. We exploit the spatially correlated mobility pattern of UWSNs and apply it to localize the sensor nodes. Also, we employ the \u2018silent\u2019 listening of beacon messages, which empowers MobiL to be energy-efficient. Simulations in NS-3 show that the proposed scheme successfully localizes nearly 90% of the total sensor nodes with localization error in the order of 25\u201330% of the error threshold in highly mobile UWSNs.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "ordinary sensor nodes",
        "powerful nodes",
        "passive node mobility",
        "high propagation loss",
        "localization error",
        "sensor nodes",
        "UWSNs",
        "MobiL",
        "Mobility Assisted Localization",
        "beacon messages",
        "Mobile Underwater Sensor Networks",
        "nodes",
        "Mobility Assisted Localization Scheme",
        "localization protocol"
      ]
    },
    "org": {
      "title": "An Oblivious Spanning Tree for Buy-at-Bulk Network Design Problems",
      "url": "https://www.semanticscholar.org/paper/535e6e9f49ae0ca2233fad7a7ccc7251f55ffa56",
      "abstract": "We consider the problem of constructing a single spanning tree for the single-source buyat-bulk network design problem for doubling-dimension graphs. We compute a spanning tree to route a set of demands (or data) along a graph to or from a designated root node. The demands could be aggregated at (or symmetrically distributed to) intermediate nodes where the fusion-cost is specied by a non-negative concave function f. We describe a novel approach for developing an oblivious spanning tree in the sense that it is independent of the number of data sources (or demands) and cost function at intermediate nodes. To our knowledge, this is the rst paper to propose a single spanning tree solution to this problem (as opposed to multiple overlay trees). There has been no prior work where the tree is oblivious to both the fusion cost function and the set of sources (demands). We present a deterministic, polynomial-time algorithm for constructing a spanning tree in low doubling graphs that guarantees log 3 D logn-approximation over the optimal cost, where D is the diameter of the graph and n the total number of nodes. With constant fusion-cost function our spanning tree gives a O(log 3 D)-approximation for every Steiner tree to the root.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "intermediate nodes",
        "nodes",
        "cost",
        "function",
        "multiple overlay trees",
        "low doubling graphs",
        "constant fusion-cost function",
        "data sources",
        "demands",
        "non-negative concave function",
        "sources",
        "designated root node",
        "single spanning tree",
        "cost function",
        "oblivious spanning tree"
      ]
    }
  },
  null,
  {
    "sim": 0.4760348632011093,
    "gen": {
      "title": "Learning to Play by Imitating Humans",
      "url": "https://www.semanticscholar.org/paper/dfca81607959eb7f101911288025a598bc5a6d18",
      "abstract": "Acquiring multiple skills has commonly involved collecting a large number of expert demonstrations per task or engineering custom reward functions. Recently it has been shown that it is possible to acquire a diverse set of skills by self-supervising control on top of human teleoperated play data. Play is rich in state space coverage and a policy trained on this data can generalize to specific tasks at test time outperforming policies trained on individual expert task demonstrations. In this work, we explore the question of whether robots can learn to play to autonomously generate play data that can ultimately enhance performance. By training a behavioral cloning policy on a relatively small quantity of human play, we autonomously generate a large quantity of cloned play data that can be used as additional training. We demonstrate that a general purpose goal-conditioned policy trained on this augmented dataset substantially outperforms one trained only with the original human data on 18 difficult user-specified manipulation tasks in a simulated robotic tabletop environment. A video example of a robot imitating human play can be seen here: this https URL",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "topics": [
        "individual expert task demonstrations",
        "play data",
        "engineering custom reward functions",
        "cloned play data",
        "specific tasks",
        "human play",
        "task",
        "expert demonstrations",
        "additional training",
        "policies",
        "test time",
        "Play",
        "performance",
        "original human data",
        "simulated robotic tabletop environment",
        "human teleoperated play data",
        "custom reward functions"
      ]
    },
    "org": {
      "title": "A Study On Convolutional Neural Network Based End-To-End Replay Anti-Spoofing",
      "url": "https://www.semanticscholar.org/paper/715474c2340a0e7aa8e68d78971d9745c67bb626",
      "abstract": "The second Automatic Speaker Verification Spoofing and Countermeasures challenge (ASVspoof 2017) focused on \"replay attack\" detection. The best deep-learning systems to compete in ASVspoof 2017 used Convolutional Neural Networks (CNNs) as a feature extractor. In this paper, we study their performance in an end-to-end setting. We find that these architectures show poor generalization in the evaluation dataset, but find a compact architecture that shows good generalization on the development data. We demonstrate that for this dataset it is not easy to obtain a similar level of generalization on both the development and evaluation data. This leads to a variety of open questions about what the differences are in the data; why these are more evident in an end-to-end setting; and how these issues can be overcome by increasing the training data.",
      "fieldsOfStudy": [
        "Engineering",
        "Computer Science"
      ],
      "topics": [
        "end",
        "training data",
        "development data",
        "Convolutional Neural Networks",
        "generalization",
        "data",
        "ASVspoof",
        "CNNs",
        "development and evaluation data",
        "open questions",
        "feature extractor",
        "evaluation dataset",
        "issues"
      ]
    }
  },
  {
    "sim": 0.5604698570809817,
    "gen": {
      "title": "Learning to Recommend With Multiple Cascading Behaviors",
      "url": "https://www.semanticscholar.org/paper/1346cef688f2c3431cf35ccfff558c08e04d5bd5",
      "abstract": "Most existing recommender systems leverage user behavior data of one type only, such as the purchase behavior in E-commerce that is directly related to the business Key Performance Indicator (KPI) of conversion rate. Besides the key behavioral data, we argue that other forms of user behaviors also provide valuable signal, such as views, clicks, adding a product to shopping carts and so on. They should be taken into account properly to provide quality recommendation for users. In this work, we contribute a new solution named short for Neural Multi-Task Recommendation (NMTR) for learning recommender systems from user multi-behavior data. We develop a neural network model to capture the complicated and multi-type interactions between users and items. In particular, our model accounts for the cascading relationship among different types of behaviors (e.g., a user must click on a product before purchasing it). To fully exploit the signal in the data of multiple types of behaviors, we perform a joint optimization based on the multi-task learning framework, where the optimization on a behavior is treated as a task. Extensive experiments on two real-world datasets demonstrate that NMTR significantly outperforms state-of-the-art recommender systems that are designed to learn from both single-behavior data and multi-behavior data. Further analysis shows that modeling multiple behaviors is particularly useful for providing recommendation for sparse users that have very few interactions.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "user behaviors",
        "multi-behavior data",
        "multiple behaviors",
        "sparse users",
        "users",
        "behaviors",
        "Most existing recommender systems leverage user behavior data",
        "conversion rate",
        "recommender systems",
        "shopping carts",
        "multiple types",
        "different types",
        "Neural Multi-Task Recommendation",
        "multi-task learning framework",
        "Most existing recommender systems"
      ]
    },
    "org": {
      "title": "Truth Inference on Sparse Crowdsourcing Data with Local Differential Privacy",
      "url": "https://www.semanticscholar.org/paper/2b190887dd241c999c0b868861b146f69af8e997",
      "abstract": "Crowdsourcing is a new problem-solving paradigm for tasks that are difficult for computers but easy for humans. Since the answers collected from the recruited participants (workers) may contain sensitive information, crowdsourcing raises serious privacy concerns. In this paper, we investigate the problem of protecting user privacy under local differential privacy (LDP), where individual workers randomize their answers independently and send the perturbed answers to the task requester. The utility goal is to ensure high accuracy of the inferred true answers (i.e., truth) from the perturbed data. One of the challenges of LDP perturbation is the sparsity of worker answers (i.e., each worker only answers a small number of tasks). Simple extension of existing approaches (e.g., Laplace perturbation and randomized response) may incur large errors in truth inference on sparse data. Thus we design a new matrix factorization (MF) algorithm under LDP that addresses the trade-off between privacy and utility (i.e., accuracy of truth inference). We prove that our MF algorithm can provide both LDP guarantee and small error of truth inference, regardless of the sparsity of worker answers. We perform extensive experiments on real-world and synthetic datasets, and demonstrate that the MF algorithm performs better than the existing LDP algorithms on sparse crowdsourcing data.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "worker answers",
        "sparse crowdsourcing data",
        "truth inference",
        "sparse data",
        "individual workers",
        "privacy concerns",
        "workers",
        "local differential privacy",
        "user privacy",
        "tasks",
        "privacy",
        "LDP perturbation",
        "humans",
        "small error",
        "LDP",
        "large errors"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.7741421975833371,
    "gen": {
      "title": "RepChain: A Reputation-Based Secure, Fast, and High Incentive Blockchain System via Sharding",
      "url": "https://www.semanticscholar.org/paper/3336ed0cfa97766ea2fc9f47fafcaa084a9e6a20",
      "abstract": "In today\u2019s blockchain system, designing a secure and high throughput blockchain on par with a centralized payment system is a difficult task. Sharding is one of the most worthwhile emerging technologies for improving the system throughput while maintain high-security level. However, previous sharding-related designs have two main limitations. First, the security and throughput of their random-based sharding system are not high enough as they did not leverage the heterogeneity among validators. Second, to design an incentive mechanism that promotes cooperation could incur a huge overhead on their system. In this article, we propose RepChain, a reputation-based secure and fast blockchain system via sharding, which also provides high incentive to stimulate node cooperation. RepChain utilizes reputation to explicitly characterize the heterogeneity among the validators and lay the foundation for the incentive mechanism. We propose a new double-chain architecture\u2014a transaction chain and a reputation chain. For the transaction chain, an efficient Raft-based synchronous consensus has been presented. For the reputation chain, the synchronous Byzantine fault tolerance consensus that combines collective signing has been utilized to prevent the attack on both reputation score and the related transaction blocks. It supports a high throughput transaction chain with moderate generation speed. Moreover, we propose a reputation-based sharding and leader selection scheme. To analyze the security of RepChain, we propose a recursive formula to calculate the epoch security within only $\\mathcal {O}(km^{2})$ time. Furthermore, we implement and evaluate RepChain on the Amazon Web Service platform. The results show our solution can enhance both throughout and security level of the existing sharding-based blockchain system.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "high incentive",
        "cooperation",
        "sharding",
        "high throughput transaction chain",
        "centralized payment system",
        "system throughput",
        "today\u2019s blockchain system",
        "moderate generation speed",
        "existing sharding-based blockchain system",
        "throughput",
        "collective signing",
        "tolerance consensus",
        "validators",
        "security level",
        "reputation"
      ]
    },
    "org": {
      "title": "GRuB: Gas-Efficient Blockchain Storage via Workload-Adaptive Data Replication",
      "url": "https://www.semanticscholar.org/paper/9441fc7c78c55308ab8959368c7357326c222cfe",
      "abstract": "Modern Blockchains support the execution of user programs, called smart contracts. As a trusted computing platform, smart contracts bring decentralization, computation integrity, open access and information transparency to average users on the Internet. However, running smart-contract programs leads to high costs, known as Gas. Such costs prevent the use of smart contracts in data-intensive application scenarios, such as high-frequency trading and transparency logging. This paper addresses the Gas-based cost effectiveness in the most consuming layer of a smart contract, namely data storage. We present GRuB, a dynamic data-replication framework that monitors the smart-contract workload and makes online replication decisions. A new online algorithm is proposed that provides constant-bounded 'competitiveness' in Gas. To further save Gas, the workload monitor and decision maker are run off the Blockchain and with security against the forging of workload trace being monitored. A GRuB prototype is built, including a smart-contract component on Ethereum and an off-chain middleware on top of Google LevelDB. The cost evaluation under the YCSB workloads shows that GRuB can converge quickly to changing workloads and save Gas significantly compared with static replication schemes. Two case studies are conducted for data-intensive applications, including high-frequency trading and transparency logging, in which running GRuB leads to affordable Gas.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "affordable Gas",
        "workload trace",
        "Gas",
        "changing workloads",
        "online replication decisions",
        "static replication schemes",
        "transparency logging",
        "high costs",
        "decision maker",
        "information transparency",
        "smart-contract programs",
        "Google LevelDB",
        "user programs",
        "smart contract",
        "smart contracts",
        "average users"
      ]
    }
  },
  {
    "sim": 0.5324748914094186,
    "gen": {
      "title": "An adaptive simulation of nonlinear heat and moisture transfer as a boundary value problem",
      "url": "https://www.semanticscholar.org/paper/03b9255551aff8505a35f2d011646a41bab5b842",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ]
    },
    "org": {
      "title": "Design and analysis of continuous hybrid differentiator",
      "url": "https://www.semanticscholar.org/paper/7ce9a0355dadff800baf150b0f11eddcb2ce8e9d",
      "abstract": "In this paper, a continuous hybrid differentiator is presented based on a strong Lyapunov function. The differentiator design can not only reduce sufficiently chattering phenomenon of derivative estimation by introducing a perturbation parameter, but also the dynamical performances are improved by adding linear correction terms to the nonlinear ones. Moreover, strong robustness ability is obtained by integrating sliding mode items and the linear filter. Frequency analysis is applied to compare the hybrid continuous differentiator with sliding mode differentiator. The merits of the continuous hybrid differentiator include the excellent dynamical performances, restraining noises sufficiently, and avoiding the chattering phenomenon.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "linear correction terms",
        "sliding mode differentiator",
        "derivative estimation",
        "sliding mode items",
        "linear",
        "strong robustness ability",
        "noises",
        "nonlinear ones",
        "dynamical performances",
        "sufficiently chattering phenomenon",
        "chattering phenomenon",
        "hybrid continuous differentiator",
        "linear filter"
      ]
    }
  },
  {
    "sim": 0.6221596350268255,
    "gen": {
      "title": "Jamming-Robust Uplink Transmission for Spatially Correlated Massive MIMO Systems",
      "url": "https://www.semanticscholar.org/paper/197f8030c74f18095c50391a0ba12d4a20effb33",
      "abstract": "In this paper, we consider how the uplink transmission of a spatially correlated massive multiple-input multiple-output (MIMO) system can be protected from a jamming attack. To suppress the jamming, we propose a novel framework including a new optimal linear estimator in the training phase and a bilinear equalizer in the data phase. The proposed estimator is optimal in the sense of maximizing the spectral efficiency of the legitimate system attacked by a jammer, and its implementation needs the statistical knowledge about the jammer\u2019s channel. We derive an efficient algorithm to estimate the jamming information needed for implementation of the proposed framework. Furthermore, we demonstrate that optimized power allocation at the legitimate users can improve the performance of the proposed framework regardless of the jamming power optimization. Our proposed framework can be exploited to combat jamming in scenarios with either ideal or non-ideal hardware at the legitimate users and the jammer. Numerical results reveal that using the proposed framework, the jammer cannot dramatically affect the performance of the legitimate system.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering",
        "Mathematics"
      ],
      "topics": [
        "combat jamming",
        "data phase",
        "implementation",
        "training phase",
        "legitimate system",
        "optimized power allocation",
        "proposed framework",
        "jammer\u2019s channel",
        "jamming power optimization",
        "bilinear equalizer",
        "legitimate users",
        "jamming attack",
        "new optimal linear estimator",
        "ideal or non-ideal hardware",
        "jamming",
        "The proposed estimator"
      ]
    },
    "org": {
      "title": "5G Ultradense Networks With Nonuniform Distributed Users",
      "url": "https://www.semanticscholar.org/paper/d6c0f64cc76a3ced1ef7fc95379ab582efe67e0e",
      "abstract": "User distribution in ultradense networks (UDNs) plays a crucial role in affecting the performance of UDNs due to the essential coupling between the traffic and the service provided by the networks. Existing studies are mostly based on the assumption that users are uniformly distributed in space. The nonuniform user distribution has not been widely considered despite that it is much closer to the real scenario. In this paper, radiation and absorbing model (R&A model) is first adopted to analyze the impact of the nonuniformly distributed users on the performance of 5G UDNs. Based on the R&A model and queueing network theory, the stationary user density in each hot area is investigated. Furthermore, the coverage probability, network throughput, and energy efficiency are derived based on the proposed theoretical model. Compared with the uniformly distributed assumption, it is shown that nonuniform user distribution has a significant impact on the performance of UDNs.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "network throughput",
        "UDNs",
        "ultradense networks",
        "user distribution",
        "R&A model",
        "absorbing model",
        "users",
        "energy efficiency",
        "5G UDNs",
        "stationary user density",
        "proposed theoretical model",
        "The nonuniform user distribution",
        "networks",
        "queueing network theory",
        "User distribution",
        "essential coupling"
      ]
    }
  },
  {
    "sim": 0.4119817531813854,
    "gen": {
      "title": "Constraint-based causal discovery from multiple interventions over overlapping variable sets",
      "url": "https://www.semanticscholar.org/paper/93863b2dc1a58202c115df48727bd998d374a9f2",
      "abstract": "Scientific practice typically involves repeatedly studying a system, each time trying to unravel a different perspective. In each study, the scientist may take measurements under different experimental conditions (interventions, manipulations, perturbations) and measure different sets of quantities (variables). The result is a collection of heterogeneous data sets coming from different data distributions. In this work, we present algorithm COmbINE, which accepts a collection of data sets over overlapping variable sets under different experimental conditions; COmbINE then outputs a summary of all causal models indicating the invariant and variant structural characteristics of all models that simultaneously fit all of the input data sets. COmbINE converts estimated dependencies and independencies in the data into path constraints on the data-generating causal model and encodes them as a SAT instance. The algorithm is sound and complete in the sample limit. To account for conflicting constraints arising from statistical errors, we introduce a general method for sorting constraints in order of confidence, computed as a function of their corresponding p-values. In our empirical evaluation, COmbINE outperforms in terms of efficiency the only pre-existing similar algorithm; the latter additionally admits feedback cycles, but does not admit conflicting constraints which hinders the applicability on real data. As a proof-of-concept, COmbINE is employed to co-analyze 4 real, mass-cytometry data sets measuring phosphorylated protein concentrations of overlapping protein sets under 3 different interventions.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "different sets",
        "data sets",
        "heterogeneous data sets",
        "different data distributions",
        "protein sets",
        "different experimental conditions",
        "variable sets",
        "real data",
        "phosphorylated protein concentrations",
        "conflicting constraints",
        "input data sets",
        "constraints",
        "variables",
        "3 different interventions",
        "overlapping protein sets",
        "overlapping variable sets",
        "algorithm COmbINE"
      ]
    },
    "org": {
      "title": "Satellite Relative Motion Modeling and Estimation via Nodal Elements",
      "url": "https://www.semanticscholar.org/paper/29a9ca2f7b5ad45ac4b1e1d4ea6148a806ca4277",
      "abstract": "In this paper, a new parametrization of the relative motion between two satellites orbiting a central body is presented. The parametrization is based on the nodal elements: a set of angles describing the orbit geometry with respect to the relative line of nodes. These are combined with classical orbital elements to yield a nonsingular relative motion description. The exact nonlinear, perturbed dynamic model resulting from the new parametrization is established. The proposed parameter set captures the fundamental Keplerian invariants, while retaining a simple relationship with local orbital coordinates. An angles-only relative navigation filter and a collision avoidance scheme are devised by exploiting these features. The navigation solution is validated on a case study of an asteroid flyby mission. It is shown that a collision can be detected early on in the estimation process, which allows one to issue a timely evasive maneuver.",
      "fieldsOfStudy": [
        "Engineering",
        "Computer Science",
        "Physics"
      ],
      "topics": [
        "local orbital coordinates",
        "classical orbital elements",
        "nodes",
        "nonsingular relative motion description",
        "dynamic model",
        "timely evasive maneuver",
        "respect",
        "asteroid flyby mission",
        "angles",
        "relative line",
        "Keplerian",
        "central body",
        "fundamental Keplerian invariants",
        "collision avoidance scheme",
        "simple relationship",
        "new parametrization"
      ]
    }
  },
  {
    "sim": 0.6659803045523032,
    "gen": {
      "title": "Geodesic Distance Descriptors",
      "url": "https://www.semanticscholar.org/paper/041edc9023dc1607763a028e37ab5eb7bb543796",
      "abstract": "The Gromov-Hausdorff (GH) distance is traditionally used for measuring distances between metric spaces. It was adapted for non-rigid shape comparison and matching of isometric surfaces, and is defined as the minimal distortion of embedding one surface into the other, while the optimal correspondence can be described as the map that minimizes this distortion. Solving such a minimization is a hard combinatorial problem that requires precomputation and storing of all pairwise geodesic distances for the matched surfaces. A popular way for compact representation of functions on surfaces is by projecting them into the leading eigenfunctions of the Laplace-Beltrami Operator (LBO). When truncated, the basis of the LBO is known to be the optimal for representing functions with bounded gradient in a min-max sense. Methods such as Spectral-GMDS exploit this idea to simplify and efficiently approximate a minimization related to the GH distance by operating in the truncated spectral domain, and obtain state of the art results for matching of nearly isometric shapes. However, when considering only a specific set of functions on the surface, such as geodesic distances, an optimized basis could be considered as an even better alternative. Moreover, current simplifications of approximating the GH distance introduce errors due to low rank approximations and relaxations of the permutation matrices. Here, we define the geodesic distance basis, which is optimal for compact approximation of geodesic distances, in terms of Frobenius norm. We use the suggested basis to extract the Geodesic Distance Descriptor (GDD), which encodes the geodesic distances information as a linear combination of the basis functions. We then show how these ideas can be used to efficiently and accurately approximate the metric spaces matching problem with almost no loss of information. We incorporate recent methods for efficient approximation of the proposed basis and descriptor without actually computing and storing all geodesic distances. These observations are used to construct a very simple and efficient procedure for shape correspondence. Experimental results show that the GDD improves both accuracy and efficiency of state of the art shape matching procedures.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "isometric surfaces",
        "surfaces",
        "shape correspondence",
        "distances",
        "non-rigid shape comparison",
        "geodesic distance basis",
        "functions",
        "geodesic distances information",
        "LBO",
        "matching",
        "compact approximation",
        "low rank approximations",
        "bounded gradient",
        "geodesic distances",
        "pairwise geodesic distances"
      ]
    },
    "org": {
      "title": "New and Improved Spanning Ratios for Yao Graphs",
      "url": "https://www.semanticscholar.org/paper/ce5998a66b9a64dd37f3d525b00c761c4969fc5d",
      "abstract": "For a set of points in the plane and a fixed integer k > 0, the Yao graph Yk partitions the space around each point into k equiangular cones of angle \u03b8 = 2\u03c0/k, and connects each point to a nearest neighbor in each cone. It is known for all Yao graphs, with the sole exception of Y5, whether or not they are geometric spanners. In this paper we close this gap by showing that for odd k \u2265 5, the spanning ratio of Yk is at most 1/(1\u22122sin(3\u03b8/8)), which gives the first constant upper bound for Y5, and is an improvement over the previous bound of 1/(1\u22122sin(\u03b8/2)) for odd k \u2265 7. We further reduce the upper bound on the spanning ratio for Y5 from 10.9 to 2 + \u221a3 \u2248 3.74, which falls slightly below the lower bound of 3.79 established for the spanning ratio of \u229d5 (\u229d-graphs differ from Yao graphs only in the way they select the closest neighbor in each cone). This is the first such separation between a Yao and \u229d-graph with the same number of cones. We also give a lower bound of 2.87 on the spanning ratio of Y5. Finally, we revisit the Y6 graph, which plays a particularly important role as the transition between the graphs (k > 6) for which simple inductive proofs are known, and the graphs (k \u2264 6) whose best spanning ratios have been established by complex arguments. Here we reduce the known spanning ratio of Y6 from 17.6 to 5.8, getting closer to the spanning ratio of 2 established for \u229d6.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "cones",
        "k equiangular cones",
        "Yao graphs",
        "k \u2264",
        "2\u03c0",
        "points",
        "angle",
        "Yao",
        "Y5",
        "geometric spanners",
        "complex arguments",
        "simple inductive proofs",
        "best spanning ratios",
        "Yao graph Yk",
        "odd k",
        "known spanning ratio",
        "cone",
        "nearest neighbor"
      ]
    }
  },
  null,
  {
    "sim": 0.723422217811536,
    "gen": {
      "title": "Throughput optimized using evolutionary computing to guarantee QoS in IEEE 802.16 networks",
      "url": "https://www.semanticscholar.org/paper/ebe4d4e621b8c06ad4de1bd0b5a5469701f9a895",
      "abstract": "The rapid growth of technology and smart phone industries has led to growth of wireless communication. Recent trends show that there is increasing in network traffic due to sharing of multimedia data such as VoIP (Voice over internet protocol), video conferencing, IPTV and so on. These services require strict QoS (Quality of Service) and network resources. To cater, new network protocol such as 4G and 5G is developed. However it induces high networkdeployment cost. The Wimax 802.16 network is currently adopted by all major service providers. Therefore the Wimax network has to provision policies and QoS for varied application. However, the WiMax does not provide implementation of these QoS policies for various application needs. Various scheduling mechanism has been developed in recent time for QoS provisioning. However these models are not efficient, due to improper synchronization of users. To develop an efficient QoS provisioning model by adopting evolutionary computing for finding ideal threshold, this work presents an uplink scheduling that minimize transmission error, buffer delay for low priority connection. The experiments are conducted to evaluate the performance of proposed model interm of throughput efficiency and slot utilization. The model achieves significant performance improvement over existing approach.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "low priority connection",
        "application needs",
        "QoS provisioning",
        "new network protocol",
        "network resources",
        "slot utilization",
        "network traffic",
        "varied application",
        "buffer delay",
        "wireless communication",
        "internet protocol",
        "QoS",
        "Various scheduling mechanism",
        "proposed model interm",
        "video conferencing",
        "strict QoS"
      ]
    },
    "org": {
      "title": "Performance Evaluation Of Qos In Wimax Network",
      "url": "https://www.semanticscholar.org/paper/da29b66afc7ef9a0fd0c9779fd9fc0ae64ff11a0",
      "abstract": "OPNET Modeler is used to simulate the architecture and to calculate the performance criteria (i.e. throughput, delay and data dropped) that slightly concerned in network estimation. It is concluded that our models shorten the time quite a bit for obtaining the performance measures of an end-to-end delay as well as throughput can be used as an effective tool for this purpose.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "network estimation",
        "delay",
        "end",
        "data",
        "performance criteria",
        "performance measures",
        "OPNET Modeler",
        "effective tool",
        "purpose",
        "i.e. throughput",
        "architecture",
        "time",
        "models"
      ]
    }
  },
  {
    "sim": 0.7135981801072492,
    "gen": {
      "title": "An Achievable Rate Region for the Broadcast Channel With Feedback",
      "url": "https://www.semanticscholar.org/paper/c41b6f48f35971219f5739744e1757fdcf8f4c6c",
      "abstract": "A single-letter achievable rate region is proposed for the two-receiver discrete memoryless broadcast channel with generalized feedback. The coding strategy involves block-Markov superposition coding using Marton's coding scheme for the broadcast channel without feedback as the starting point. If the message rates in the Marton scheme are too high to be decoded at the end of a block, each receiver is left with a list of messages compatible with its output. Resolution information is sent in the following block to enable each receiver to resolve its list. The key observation is that the resolution information of the first receiver is correlated with that of the second. This correlated information is efficiently transmitted via joint source-channel coding, using ideas similar to the Han-Costa coding scheme. Using the result, we obtain an achievable rate region for the stochastically degraded additive white Gaussian noise broadcast channel with noisy feedback from only one receiver. It is shown that this region is strictly larger than the no-feedback capacity region.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "generalized feedback",
        "noisy feedback",
        "feedback",
        "messages",
        "joint source-channel coding",
        "stochastically degraded additive white Gaussian noise broadcast channel",
        "second",
        "achievable rate region",
        "Martons coding scheme",
        "broadcast channel",
        "block-Markov superposition coding",
        "Marton",
        "receiver",
        "Gaussian",
        "two-receiver discrete memoryless broadcast channel",
        "Resolution information",
        "starting point"
      ]
    },
    "org": {
      "title": "Analysis and Design of Tuned Turbo Codes",
      "url": "https://www.semanticscholar.org/paper/41260424de2707cfcb8687323b60630767472d76",
      "abstract": "It has been widely observed that there exists a fundamental tradeoff between the minimum (Hamming) distance properties and the iterative decoding convergence behavior of turbo- like codes. While capacity-achieving code ensembles typically are asymptotically bad in the sense that their minimum distance does not grow linearly with block length, and they therefore exhibit an error floor at moderate-to-high signal-to-noise ratios, asymptotically good codes usually converge further away from channel capacity. In this paper, we introduce the concept of tuned turbo codes, a family of asymptotically good hybrid concatenated code ensembles, where asymptotic minimum distance growth rates, convergence thresholds, and code rates can be tradedoff using two tuning parameters: \u03bb and \u03bc. By decreasing \u03bb, the asymptotic minimum distance growth rate is reduced in exchange for improved iterative decoding convergence behavior, while increasing \u03bb raises the asymptotic minimum distance growth rate at the expense of worse convergence behavior, and thus, the code performance can be tuned to fit the desired application. By decreasing \u03bc, a similar tuning behavior can be achieved for higher rate code ensembles.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "higher rate code ensembles",
        "code rates",
        "codes",
        "worse convergence behavior",
        "tuned turbo codes",
        "asymptotic minimum distance growth rate",
        "convergence thresholds",
        "asymptotically good hybrid concatenated code ensembles",
        "capacity-achieving code ensembles",
        "channel capacity",
        "iterative decoding convergence behavior",
        "asymptotically good codes",
        "code performance",
        "turbo- like codes"
      ]
    }
  },
  {
    "sim": 0.7509193163107238,
    "gen": {
      "title": "Joint Pilot and Payload Power Allocation for Massive-MIMO-Enabled URLLC IIoT Networks",
      "url": "https://www.semanticscholar.org/paper/74205ea9f9ecf49d82b7db98f05290c28eedd96e",
      "abstract": "The Fourth Industrial Revolution (Industrial 4.0) is coming, and this revolution will fundamentally enhance the way factories manufacture products. The conventional wired lines connecting central controller to robots or actuators will be replaced by wireless communication networks due to its low cost of maintenance and high deployment flexibility. However, some critical industrial applications require ultra-high reliability and low latency communication (URLLC). In this paper, we advocate the adoption of massive multiple-input multiple output (MIMO) to support the wireless transmission for industrial applications as it can provide deterministic communications similar as wired lines thanks to its channel hardening effects. To reduce the latency, the channel blocklength for packet transmission is finite, which incurs transmission rate degradation and decoding error probability. Thus, conventional resource allocation for massive MIMO transmission based on Shannon capacity assuming the infinite channel blocklength is no longer optimal. We first derive the closed-form expression of lower bound (LB) of achievable uplink data rate for massive MIMO system with imperfect channel state information (CSI) for both maximum-ratio combining (MRC) and zero-forcing (ZF) receivers. Then, we propose novel low complexity algorithms to solve the achievable data rate maximization problems by jointly optimizing the pilot and payload transmission power for both MRC and ZF. Simulation results confirm the rapid convergence speed and performance advantage over the existing benchmark algorithms.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "topics": [
        "transmission rate degradation",
        "achievable uplink data rate",
        "massive MIMO transmission",
        "packet transmission",
        "low latency communication",
        "imperfect channel state information",
        "wireless communication networks",
        "novel low complexity algorithms",
        "high deployment flexibility",
        "error probability",
        "ZF",
        "massive MIMO system",
        "deterministic communications",
        "ultra-high reliability",
        "achievable data rate maximization problems",
        "decoding error probability"
      ]
    },
    "org": {
      "title": "Performance Analysis of MIMO K-user Interference Channels with Hardware Impairments",
      "url": "https://www.semanticscholar.org/paper/04e999f83397146775727a38a1888d75a8d14ab1",
      "abstract": "Next generation of wireless systems will employ many antenna branches with low-cost devices and hence, may suffer from severe hardware impairments (HWI) like I/Q imbalance, phase noise, etc. With I/Q imbalance, the received signal is a widely linear transformation of the transmitted signal and noise. Thus, the effective noise may be improper, which means that its real and imaginary parts are not independent and identically distributed. Improper Gaussian signaling (IGS) can improve system performance with improper noise and/or improper interference. This paper studies IGS for multiple-input, multiple-output (MIMO) $K$-user interference channels (IC) with imperfect devices in terms of two performance metrics: achievable rate and energy efficiency (EE). We also define an optimization framework for interference-limited systems when treating interference as noise. This framework obtains a stationary point of any optimization problem in which either the objective function and/or constraints are linear functions of rates. These include the optimization of the rate region, the sum-rate, the EE region, or the global EE, among others. Our numerical results show that IGS can improve the performance of MIMO $K$-user IC with HWI and I/Q imbalance, where its benefits increase with $K$ and the imbalance level and decrease with the number of antennas.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering",
        "Mathematics"
      ],
      "topics": [
        "improper noise",
        "phase noise",
        "EE",
        "improper interference",
        "noise",
        "achievable rate",
        "antenna branches",
        "system performance",
        "severe hardware impairments",
        "linear functions",
        "Improper Gaussian",
        "rates",
        "imperfect devices",
        "interference",
        "antennas",
        "Improper Gaussian signaling"
      ]
    }
  },
  {
    "sim": 0.6749659975130065,
    "gen": {
      "title": "Topic Modeling of Hierarchical Corpora /",
      "url": "https://www.semanticscholar.org/paper/81d2e0d81910fcb097cfff4025b8b91a58ae830b",
      "abstract": "The sizes of modern digital libraries have grown beyond our capacity to comprehend manually. Thus we need new tools to help us in organizing and browsing large corpora of text that do not require manually examining each document. To this end, machine learning researchers have developed topic models, statistical learning algorithms for automatic comprehension of large collections of text. Topic models provide both global and local views of a corpus; they discover topics that run through the corpus and describe each document as a mixture of the discovered topics. In this dissertation, I consider the topic modeling of corpora whose documents are organized in a multi-level hierarchy. My interest in this subject arose from the need to analyze two sprawling, real-world corpora from the field of computer security. The first is a collection of job postings on a crowdsourcing site, where many advertisers seek cheap human labor for different forms of Web service abuse. I view this corpus as a three- layer tree in which an interior node represents a buyer, and children of the interior node represent the buyer's postings. The second corpus is a collection of threads from an underground Internet forum, where blackhat operatives discuss tactics for abusive forms of Internet marketing such as spamming and search engine optimization. The subforums and threads in this data set form a five- level deep hierarchy. Using these two data sets as test beds, I develop topic models that incorporate hierarchies in corpora. The models I consider can be viewed as special (finite-dimensional) instances of hierarchical Dirichlet processes (HDPs). For these models I show that there exists a simple variational approximation for probabilistic inference and demonstrate a parallel inference algorithm that can scale to corpora with deep hierarchies and large numbers of documents. On several hierarchical corpora, I show advantages of my topic models over other topic models that do not consider hierarchies. Also I compare my variational method to existing implementations of HDPs and find that my approach is faster than Gibbs sampling and able to learn more predictive models than existing variational methods",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "documents",
        "large corpora",
        "topic models",
        "hierarchies",
        "large numbers",
        "topics",
        "large collections",
        "corpora",
        "hierarchical corpora",
        "multi-level hierarchy",
        "existing variational methods",
        "Web service abuse",
        "search engine optimization"
      ]
    },
    "org": {
      "title": "Modeling hierarchical usage context for software exceptions based on interaction data",
      "url": "https://www.semanticscholar.org/paper/ccac3b4d10eaf299994c8950f01042f9937adeab",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  {
    "sim": 0.6413745532090182,
    "gen": {
      "title": "Energy Efficiency Optimization for MIMO Distributed Antenna Systems",
      "url": "https://www.semanticscholar.org/paper/e7f1faccca15ce687b885c6954443588f7daf71b",
      "abstract": "In this paper, we propose a transmit covariance optimization method to maximize the energy efficiency (EE) for a single-user distributed antenna system, where both the remote access units (RAUs) and the user are equipped with multiple antennas. Unlike previous related work, both the rate requirement and the RAU selection are taken into consideration. Here, the total circuit power consumption is related to the number of active RAUs. Given this setup, we first propose an optimal transmit covariance optimization method to solve the EE optimization problem under a fixed set of active RAUs. More specifically, we split this problem into three subproblems, namely, the rate maximization problem, the EE maximization problem without rate constraint, and the power minimization problem, and each subproblem can be efficiently solved. Then, a novel distance-based RAU selection method is proposed to determine the optimal set of active RAUs. Simulation results show that the performance of the proposed RAU selection is almost identical to the optimal exhaustive search method with significantly reduced computational complexity, and the performance of the proposed algorithm significantly outperforms the existing EE optimization methods.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "antenna system",
        "multiple antennas",
        "active RAUs",
        "EE",
        "existing EE optimization methods",
        "rate constraint",
        "single-user distributed antenna system",
        "transmit covariance optimization method",
        "optimal exhaustive search method",
        "rate maximization problem",
        "RAU",
        "RAUs",
        "EE maximization problem",
        "proposed RAU selection",
        "novel distance-based RAU selection method",
        "consideration"
      ]
    },
    "org": {
      "title": "Price-Based Resource Allocation for Edge Computing: A Market Equilibrium Approach",
      "url": "https://www.semanticscholar.org/paper/4e030ebccf53423f50c4631d064a782dacced7c7",
      "abstract": "The emerging edge computing paradigm promises to deliver superior user experience and enable a wide range of Internet of Things (IoT) applications. In this paper, we propose a new market-based framework for efficiently allocating resources of heterogeneous capacity-limited edge nodes (EN) to multiple competing services at the network edge. By properly pricing the geographically distributed ENs, the proposed framework generates a market equilibrium (ME) solution that not only maximizes the edge computing resource utilization but also allocates optimal resource bundles to the services given their budget constraints. When the utility of a service is defined as the maximum revenue that the service can achieve from its resource allotment, the equilibrium can be computed centrally by solving the Eisenberg-Gale (EG) convex program. We further show that the equilibrium allocation is Pareto-optimal and satisfies desired fairness properties including sharing incentive, proportionality, and envy-freeness. Also, two distributed algorithms, which efficiently converge to an ME, are introduced. When each service aims to maximize its net profit (i.e., revenue minus cost) instead of the revenue, we derive a novel convex optimization problem and rigorously prove that its solution is exactly an ME. Extensive numerical results are presented to validate the effectiveness of the proposed techniques.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "multiple competing services",
        "optimal resource bundles",
        "resource utilization",
        "resources",
        "superior user experience",
        "heterogeneous capacity-limited edge nodes",
        "fairness properties",
        "novel convex optimization problem",
        "The emerging edge computing paradigm",
        "Internet",
        "proportionality",
        "EN",
        "incentive",
        "network edge",
        "resource allotment",
        "edge computing resource utilization",
        "desired fairness properties",
        "sharing incentive",
        "IoT",
        "Things"
      ]
    }
  },
  {
    "sim": 0.6670076738915317,
    "gen": {
      "title": "RANet: Ranking Attention Network for Fast Video Object Segmentation",
      "url": "https://www.semanticscholar.org/paper/7d19afefc1ef823fd6f64f28ee1d620bf925156d",
      "abstract": "Despite online learning (OL) techniques have boosted the performance of semi-supervised video object segmentation (VOS) methods, the huge time costs of OL greatly restricts their practicality. Matching based and propagation based methods run at a faster speed by avoiding OL techniques. However, they are limited by sub-optimal accuracy, due to mismatching and drifting problems. In this paper, we develop a real-time yet very accurate Ranking Attention Network (RANet) for VOS. Specifically, to integrate the insights of matching based and propagation based methods, we employ an encoder-decoder framework to learn pixel-level similarity and segmentation in an end-to-end manner. To better utilize the similarity maps, we propose a novel ranking attention module, which automatically ranks and selects these maps for fine-grained VOS performance. Experiments on DAVIS16 and DAVIS17 datasets show that our RANet achieves the best speed-accuracy trade-off, e.g., with 33 milliseconds per frame and J&F=85.5% on DAVIS16. With OL, our RANet reaches J&F=87.1% on DAVIS16, exceeding state-of-the-art VOS methods. The code can be found at https://github.com/Storife/RANet.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "VOS",
        "OL techniques",
        "sub-optimal accuracy",
        "OL",
        "segmentation",
        "end",
        "Ranking Attention Network",
        "based and propagation based methods",
        "problems",
        "huge time costs",
        "fine-grained VOS performance",
        "frame",
        "novel ranking attention module",
        "pixel-level similarity",
        "DAVIS16",
        "RANet",
        "matching based and propagation based methods",
        "DAVIS16 and DAVIS17 datasets",
        "mismatching and drifting problems"
      ]
    },
    "org": {
      "title": "Visual Tracking by Reinforced Decision Making",
      "url": "https://www.semanticscholar.org/paper/001d36f857ae634b98e8c629853df324c21f323f",
      "abstract": "One of the major challenges of model-free visual tracking problem has been the difficulty originating from the unpredictable and drastic changes in the appearance of objects we target to track. Existing methods tackle this problem by updating the appearance model on-line in order to adapt to the changes in the appearance. Despite the success of these methods however, inaccurate and erroneous updates of the appearance model result in a tracker drift. In this paper, we introduce a novel visual tracking algorithm based on a template selection strategy constructed by deep reinforcement learning methods. The tracking algorithm utilizes this strategy to choose the best template for tracking a given frame. The template selection strategy is selflearned by utilizing a simple policy gradient method on numerous training episodes randomly generated from a tracking benchmark dataset. Our proposed reinforcement learning framework is generally applicable to other confidence map based tracking algorithms. The experiment shows that our tracking algorithm effectively decides the best template for visual tracking.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "confidence map based tracking algorithms",
        "visual tracking",
        "deep reinforcement learning methods",
        "track",
        "numerous training episodes",
        "model-free visual tracking problem",
        "Existing methods",
        "novel visual tracking algorithm",
        "appearance model",
        "objects",
        "template selection strategy",
        "tracking benchmark dataset",
        "tracking algorithm",
        "The tracking algorithm",
        "simple policy gradient method"
      ]
    }
  },
  {
    "sim": 0.35514478559993135,
    "gen": {
      "title": "ML-HDP: A Hierarchical Bayesian Nonparametric Model for Recognizing Human Actions in Video",
      "url": "https://www.semanticscholar.org/paper/5c0d23485c0ece214000ff8c0dcb3042bc114048",
      "abstract": "Action recognition from videos is an important area of computer vision research due to its various applications, ranging from visual surveillance to human\u2013computer interaction. To address action recognition problems, this paper presents a framework that jointly models multiple complex actions and motion units at different hierarchical levels. We achieve this by proposing a generative topic model, namely, multi-label hierarchical Dirichlet process (ML-HDP). The ML-HDP model formulates the co-occurrence relationship of actions and motion units, and enables highly accurate recognition. In particular, our topic model possesses the three-level representation in action understanding, where low-level local features are connected to high-level actions via mid-level atomic actions. This allows the recognition model to work discriminatively. In our ML-HDP, atomic actions are treated as latent topics and automatically discovered from data. In addition, we incorporate the notion of class labels into our model in a semi-supervised fashion to effectively learn and infer multi-labeled videos. Using discovered topics and inferred labels, which are jointly assigned to local features, we present the straightforward methods to perform three recognition tasks including action classification, joint classification and segmentation of continuous actions, and spatiotemporal action localization. In experiments, we explore the use of three different features and demonstrate the effectiveness of our proposed approach for these tasks on four public datasets: KTH, MSR-II, Hollywood2, and UCF101.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "action recognition problems",
        "action classification",
        "atomic actions",
        "continuous actions",
        "action understanding",
        "actions",
        "mid-level atomic actions",
        "spatiotemporal action localization",
        "multiple complex actions",
        "computer vision research",
        "different hierarchical levels",
        "multi-labeled videos",
        "local features",
        "motion units",
        "computer interaction"
      ]
    },
    "org": {
      "title": "Connectivity-aware traffic phase scheduling for heterogeneously connected vehicles",
      "url": "https://www.semanticscholar.org/paper/16e4c01f0aca68364080d9ad7a7a250ee0aa0174",
      "abstract": "We consider a transportation system of heterogeneously connected vehicles, where not all vehicles are able to communicate. Heterogeneous connectivity in transportation systems is coupled to practical constraints such that (i) not all vehicles may be equipped with devices having communication interfaces, (ii) some vehicles may not prefer to communicate due to privacy and security reasons, and (iii) communication links are not perfect and packet losses and delay occur in practice. In this context, it is crucial to develop control algorithms by taking into account the heterogeneity. In this paper, we particularly focus on making traffic phase scheduling decisions. We develop a connectivity-aware traffic phase scheduling algorithm for heterogeneously connected vehicles that increases the intersection efficiency (in terms of the average number of vehicles that are allowed to pass the intersection) by taking into account the heterogeneity. The simulation results show that our algorithm significantly improves the efficiency of intersections as compared to the baselines.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "topics": [
        "vehicles",
        "communication interfaces",
        "practice",
        "traffic phase scheduling decisions",
        "intersections",
        "account",
        "control algorithms",
        "losses",
        "delay",
        "privacy and security reasons",
        "heterogeneously connected vehicles",
        "practical constraints",
        "transportation systems",
        "devices",
        "terms",
        "communication links",
        "packet losses"
      ]
    }
  },
  null,
  {
    "sim": 0.6377356605299435,
    "gen": {
      "title": "Millimeter-Wave Beamformed Full-Dimensional MIMO Channel Estimation Based on Atomic Norm Minimization",
      "url": "https://www.semanticscholar.org/paper/0de155513495c28d1e2d4d3da101ab7cce6ec822",
      "abstract": "The millimeter-wave (mmWave) full-dimensional (FD) MIMO system employs planar arrays at both the base station and the user equipment and can simultaneously support both azimuth and elevation beamforming. In this paper, we propose atomic-norm-based methods for mm-wave FD-MIMO channel estimation under both uniform planar arrays (UPA) and non-uniform planar arrays (NUPA). Unlike existing algorithms, such as compressive sensing (CS) or subspace methods, the atomic-norm-based algorithms do not require to discretize the angle spaces of the angle of arrival and angle of departure into grids, thus provide much better accuracy in estimation. In the UPA case, to reduce the computational complexity, the original large-scale atomic norm minimization problem is approximately reformulated as a semi-definite program (SDP) containing two decoupled two-level Toeplitz matrices. The SDP is then solved via the alternating direction method of multipliers where each iteration involves only closed-form computations. In the NUPA case, the atomic-norm-based formulation for channel estimation becomes nonconvex and a gradient-decent-based algorithm is proposed to solve the problem. Simulation results show that the proposed algorithms achieve better performance than the CS-based and subspace-based algorithms.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "channel estimation",
        "non-uniform planar",
        "subspace methods",
        "estimation",
        "existing algorithms",
        "angle",
        "better performance",
        "atomic-norm-based methods",
        "CS",
        "Toeplitz",
        "semi-definite program",
        "original large-scale atomic norm minimization problem",
        "compressive sensing",
        "UPA",
        "planar arrays",
        "uniform planar arrays",
        "mm-wave FD-MIMO channel estimation",
        "SDP"
      ]
    },
    "org": {
      "title": "Queue-Aware Beam Scheduling for Half-Duplex mmWave Relay Networks",
      "url": "https://www.semanticscholar.org/paper/cb2d7b4a882b7ac5a01fe16ad9188f8ca957878d",
      "abstract": "We focus on two basic millimeter wave (mmWave) relay networks and for each network, we propose three beam scheduling methods to approach the network information theoretic capacity. The proposed beam scheduling methods include the deterministic horizontal continuous edge coloring (HC-EC) scheduler, the adaptive back pressure (BP) scheduler and the adaptive low-delay new back pressure (newBP) scheduler. With the aid of computer simulations, we show that within the network capacity range, the proposed schedulers provide good guarantees for the network stability, meanwhile achieve very low packet end-to-end delay.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "adaptive low-delay new back pressure",
        "end",
        "adaptive back pressure",
        "good guarantees",
        "BP) scheduler",
        "proposed schedulers",
        "newBP",
        "network information theoretic capacity",
        "network capacity range",
        "HC-EC) scheduler",
        "network stability",
        "deterministic horizontal continuous edge coloring",
        "beam scheduling methods",
        "adaptive back pressure (BP) scheduler",
        "deterministic horizontal continuous edge coloring (HC-EC) scheduler",
        "millimeter wave",
        "network",
        "computer simulations",
        "mmWave",
        "(newBP"
      ]
    }
  },
  {
    "sim": 0.28032556054274416,
    "gen": {
      "title": "Accuracy Evaluation of a Three-Dimensional Model Generated from Patient-Specific Monocular Video Data for Maxillofacial Prosthetic Rehabilitation: A Pilot Study.",
      "url": "https://www.semanticscholar.org/paper/c04a9b6021a2b2190313e9a087442d8a28734d2e",
      "abstract": "PURPOSE\nTo evaluate if the combination of a monoscopic photogrammetry technique and smartphone-recorded monocular video data could be appropriately applied to maxillofacial prosthesis fabrication.\n\n\nMATERIALS AND METHODS\nSmartphone video and laser scanning data were recorded for five healthy volunteers (24.1\u00a0\u00b10.7 years). Three-dimensional facial models were generated using photogrammetry software and a laser scanner. Smartphone-recorded video data were used to generate a photogrammetric three-dimensional model. The videos were recorded at two resolutions: 1080 \u00d7 1920 (high resolution) and 720 \u00d7 1280 pixels (low resolution). The lengths of five nasal component parts (nose height, nasal dorsum length, nasal column length, nasal ala length, and nose breadth) were compared in the photogrammetric three-dimensional models (as the test model) and the laser scanned three-dimensional models (as the validation model) using reverse engineering software.\n\n\nRESULTS\nThere was a significant difference in the nasal dorsum length between the test model and the validation model (High resolution; 95% confidence interval, 2.05-5.07, Low resolution; confidence interval, 2.19-5.69). In contrast to the nasal dorsum length, there were no significant differences in nose height, nose breadth, nasal ala length, and nasal column length.\n\n\nCONCLUSION\nUsing smartphone-recorded video data and a photogrammetry technique may be a promising technique to apply in the maxillofacial prosthetic rehabilitation workflow. This article is protected by copyright. All rights reserved.",
      "fieldsOfStudy": [
        "Medicine",
        "Computer Science"
      ],
      "topics": [
        "low resolution",
        "nasal ala length",
        "laser scanning data",
        "nose height",
        "nose breadth",
        "95% confidence interval",
        "nasal dorsum length",
        "photogrammetry software",
        "(High resolution",
        "reverse engineering software",
        "nasal column length",
        "Smartphone video and laser scanning data",
        "(high resolution",
        "maxillofacial prosthesis fabrication",
        "smartphone-recorded monocular video data"
      ]
    },
    "org": {
      "title": "Generative Design of Hardware-aware DNNs",
      "url": "https://www.semanticscholar.org/paper/00a15dda3093ac3e679f4d956fd086b6a6bfef82",
      "abstract": "To efficiently run DNNs on the edge/cloud, many new DNN inference accelerators are being designed and deployed frequently. To enhance the resource efficiency of DNNs, model quantization is a widely-used approach. However, different accelerator/HW has different resources leading to the need for specialized quantization strategy of each HW. Moreover, using the same quantization for every layer may be sub-optimal, increasing the designspace of possible quantization choices. This makes manual-tuning infeasible. Recent work in automatically determining quantization for each layer is driven by optimization methods such as reinforcement learning. However, these approaches need re-training the RL for every new HW platform. We propose a new way for autonomous quantization and HW-aware tuning. We propose a generative model, AQGAN, which takes a target accuracy as the condition and generates a suite of quantization configurations. With the conditional generative model, the user can autonomously generate different configurations with different targets in inference time. Moreover, we propose a simplified HW-tuning flow, which uses the generative model to generate proposals and execute simple selection based on the HW resource budget, whose process is fast and interactive. We evaluate our model on five of the widely-used efficient models on the ImageNet dataset. We compare with existing uniform quantization and state-of-the-art autonomous quantization methods. Our generative model shows competitive achieved accuracy, however, with around two degrees less search cost for each design point. Our generative model shows the generated quantization configuration can lead to less than 3.5% error across all experiments.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "quantization configurations",
        "autonomous quantization",
        "possible quantization choices",
        "quantization",
        "specialized quantization strategy",
        "existing uniform quantization",
        "reinforcement learning",
        "new DNN inference accelerators",
        "HW",
        "different configurations",
        "different resources",
        "different targets",
        "different accelerator",
        "generated quantization configuration",
        "optimization methods",
        "inference time",
        "HW-aware tuning"
      ]
    }
  },
  null,
  {
    "sim": 0.5461816506549276,
    "gen": {
      "title": "Lipschitz constant estimation of Neural Networks via sparse polynomial optimization",
      "url": "https://www.semanticscholar.org/paper/126882eb187575788375f2a38e9145551fbdc2f6",
      "abstract": "We introduce LiPopt, a polynomial optimization framework for computing increasingly tighter upper bound on the Lipschitz constant of neural networks. The underlying optimization problems boil down to either linear (LP) or semidefinite (SDP) programming. We show how to use structural properties of the network, such as sparsity, to significantly reduce the complexity of computation. This is specially useful for convolutional as well as pruned neural networks. We conduct experiments on networks with random weights as well as networks trained on MNIST, showing that in the particular case of the $\\ell_\\infty$-Lipschitz constant, our approach yields superior estimates as compared to other baselines available in the literature.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "pruned neural networks",
        "networks",
        "baselines",
        "superior estimates",
        "computation",
        "random weights",
        "MNIST",
        "structural properties",
        "sparsity",
        "SDP",
        "Lipschitz",
        "network",
        "linear",
        "literature",
        "neural networks",
        "Lipschitz constant",
        "increasingly tighter upper bound",
        "convolutional as well as pruned neural networks",
        "particular case"
      ]
    },
    "org": {
      "title": "A new framework for dynamical models on multiplex networks",
      "url": "https://www.semanticscholar.org/paper/76fe08a6a3ed8ef5e570f7c3d5baf4c08b797c08",
      "abstract": "Many complex systems have natural representations as multi-layer networks. While these formulations retain more information than standard single-layer network models, there is not yet a fully developed theory for computing network metrics and statistics on these objects. We introduce a family of models of multiplex processes motivated by dynamical applications and investigate the properties of their spectra both theoretically and computationally. We study special cases of multiplex diffusion and Markov dynamics, using the spectral results to compute their rates of convergence. We use our framework to define a version of multiplex eigenvector centrality, which generalizes some existing notions in the literature. Last, we compare our operator to structurally-derived models on synthetic and real-world networks, helping delineate the contexts in which the different frameworks are appropriate.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics"
      ],
      "topics": [
        "network metrics",
        "multi-layer networks",
        "multiplex eigenvector centrality",
        "standard single-layer network models",
        "convergence",
        "models",
        "dynamical applications",
        "statistics",
        "multiplex processes",
        "multiplex diffusion",
        "Markov dynamics",
        "natural representations",
        "synthetic and real-world networks",
        "information",
        "Many complex systems"
      ]
    }
  },
  {
    "sim": 0.6176906266602985,
    "gen": {
      "title": "Sparse Phase Retrieval via Truncated Amplitude Flow",
      "url": "https://www.semanticscholar.org/paper/48f9a62a538af8326736f2351a5d09e195221238",
      "abstract": "This paper develops a novel algorithm, termed <italic>SPARse Truncated Amplitude flow</italic> (SPARTA), to reconstruct a sparse signal from a small number of magnitude-only measurements. It deals with what is also known as sparse phase retrieval (PR), which is <italic>NP-hard</italic> in general and emerges in many science and engineering applications. Upon formulating sparse PR as an amplitude-based nonconvex optimization task, SPARTA works iteratively in two stages: In stage one, the support of the underlying sparse signal is recovered using an analytically well-justified rule, and subsequently a sparse orthogonality-promoting initialization is obtained via power iterations restricted on the support; and in the second stage, the initialization is successively refined by means of hard thresholding based gradient-type iterations. SPARTA is a simple yet effective, scalable, and fast sparse PR solver. On the theoretical side, for any <inline-formula><tex-math notation=\"LaTeX\">$n$</tex-math></inline-formula>-dimensional <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math></inline-formula>-sparse (<inline-formula> <tex-math notation=\"LaTeX\">$k\\ll n$</tex-math></inline-formula>) signal <inline-formula><tex-math notation=\"LaTeX\"> $\\boldsymbol {x}$</tex-math></inline-formula> with minimum (in modulus) nonzero entries on the order of <inline-formula> <tex-math notation=\"LaTeX\">$(1/\\sqrt{k})\\Vert \\boldsymbol {x}\\Vert _2$</tex-math></inline-formula>, SPARTA recovers the signal exactly (up to a global unimodular constant) from about <inline-formula><tex-math notation=\"LaTeX\">$k^2\\log n$ </tex-math></inline-formula> random Gaussian measurements with high probability. Furthermore, SPARTA incurs computational complexity on the order of <inline-formula><tex-math notation=\"LaTeX\">$k^2n\\log n$</tex-math> </inline-formula> with total runtime proportional to the time required to read the data, which improves upon the state of the art by at least a factor of <inline-formula><tex-math notation=\"LaTeX\">$k$</tex-math></inline-formula>. Finally, SPARTA is robust against additive noise of bounded support. Extensive numerical tests corroborate markedly improved recovery performance and speedups of SPARTA relative to existing alternatives.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "formula",
        "high probability",
        "bounded support",
        "power iterations",
        "stage",
        "SPARTA",
        "sparse PR",
        "hard thresholding based gradient-type iterations",
        "sparse phase retrieval",
        "formula><tex-math",
        "second",
        "existing alternatives",
        "NP-hard</italic",
        "n$</tex-math",
        "underlying sparse signal",
        "\\boldsymbol",
        "total runtime",
        "sparse signal"
      ]
    },
    "org": {
      "title": "Randomized Projection Methods for Linear Systems with Arbitrarily Large Sparse Corruptions",
      "url": "https://www.semanticscholar.org/paper/44489a14d7fad45238d14fb1567f5e568c6ddc06",
      "abstract": "In applications like medical imaging, error correction, and sensor networks, one needs to solve large-scale linear systems that may be corrupted by a small number of arbitrarily large corruptions. We consider solving such large-scale systems of linear equations $A\\mathbf{x}=\\mathbf{b}$ that are inconsistent due to corruptions in the measurement vector $\\mathbf{b}$. With this as our motivating example, we develop an approach for this setting that allows detection of the corrupted entries and thus convergence to the \"true\" solution of the original system. We provide analytical justification for our approaches as well as experimental evidence on real and synthetic systems.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "corruptions",
        "linear equations",
        "large-scale linear systems",
        "large-scale systems",
        "real and synthetic systems",
        "original system",
        "linear",
        "arbitrarily large corruptions",
        "detection",
        "experimental evidence",
        "measurement vector",
        "sensor networks",
        "motivating example",
        "small number",
        "error correction",
        "\\mathbf{b}$.",
        "A\\mathbf{x}=\\mathbf{b}$",
        "corrupted entries"
      ]
    }
  },
  {
    "sim": 0.49613853318853973,
    "gen": {
      "title": "Robust Estimation of Dispersion Matrices and Principal Components",
      "url": "https://www.semanticscholar.org/paper/ec2ded1c15a73194f9a64a70183854b09bc1ea86",
      "abstract": "Abstract This paper uses Monte Carlo methods to compare the performances of several robust procedures for estimating a correlation matrix and its principal components. The estimators are formed either from separate bivariate analyses or by simultaneous manipulation of all variables by using techniques such as multivariate trimming and M-estimation. The M-estimators stand up exceptionally well. They and the multivariate trimming procedure are especially effective at estimating the principal components, including a near singularity. However, the M-estimators can break down relatively easily when the dimensionality is large and the outliers are asymmetric. With missing data, the element-wise approach becomes more attractive.",
      "fieldsOfStudy": [
        "Mathematics"
      ],
      "topics": [
        "robust procedures",
        "Monte Carlo methods",
        "simultaneous manipulation",
        "asymmetric",
        "near singularity",
        "separate bivariate analyses",
        "Monte Carlo",
        "principal components",
        "techniques",
        "multivariate trimming procedure",
        "M-estimation",
        "missing data",
        "correlation matrix",
        "element-wise approach",
        "multivariate trimming",
        "performances",
        "variables"
      ]
    },
    "org": {
      "title": "Kinetic Compressive Sensing",
      "url": "https://www.semanticscholar.org/paper/1e3f35697cc6ab478bf0cbfab2bce8a27746bdde",
      "abstract": "Parametric images provide insight into the spatial distribution of physiological parameters, but they are often extremely noisy, due to low SNR of tomographic data. Direct estimation from projections allows accurate noise modeling, improving the results of post-reconstruction fitting. We propose a method, which we name kinetic compressive sensing (KCS), based on a hierarchical Bayesian model and on a novel reconstruction algorithm, that encodes sparsity of kinetic parameters. Parametric maps are reconstructed by maximizing the joint probability, with an Iterated Conditional Modes (ICM) approach, alternating the optimization of activity time series (OS-MAP-OSL), and kinetic parameters (MAP-LM). We evaluated the proposed algorithm on a simulated dynamic phantom: a bias/variance study confirmed how direct estimates can improve the quality of parametric maps over a post-reconstruction fitting, and showed how the novel sparsity prior can further reduce their variance, without affecting bias. Real FDG PET human brain data (Siemens mMR, 40min) images were also processed. Results enforced how the proposed KCS-regularized direct method can produce spatially coherent images and parametric maps, with lower spatial noise and better tissue contrast. A GPU-based open source implementation of the algorithm is provided.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Physics"
      ],
      "topics": [
        "kinetic parameters",
        "lower spatial noise",
        "tomographic data",
        "physiological parameters",
        "post-reconstruction fitting",
        "low SNR",
        "parametric maps",
        "kinetic compressive sensing",
        "better tissue contrast",
        "bias",
        "Siemens mMR",
        "activity time series",
        "MAP",
        "accurate noise modeling",
        "direct estimates"
      ]
    }
  },
  {
    "sim": 0.5397538692294748,
    "gen": {
      "title": "A New Approach to Choke Flow Models Using Machine Learning Algorithms",
      "url": "https://www.semanticscholar.org/paper/501312eb1ff658c152c3572d3a722502f05e2b51",
      "abstract": "\n Computer Science Technology has been widely used for simulation of Gas and Petroleum Networks. Wellhead chokes or Pressure Control Valves are specialized equipment used extensively in the Hydrocarbon Industry for two purposes; to maintain stable downstream pressure from the wells, and to provide necessary backpressure to balance gas well productivity while controlling downhole drawdown. Use of multiphase choke flow models and empirical choke flow equations have been developed in the past half-century to improve gas estimation at different fluid, flow regime, flow types and pressure drop scenarios. All these have carried over certain measurement errors which make it difficult to predict well performance parameters with the mentioned methods.\n Traditional models use sonic flow equation and Gilbert-type formulae for critical flow of multiphase choke cases as a base line. Evolution of new models capture further regression refinements, constrains values and multiple regression studies at different pressure drop, PVT properties, gas-liquid ratios, and choke sizes. The new Algorithm has been developed by using Random Forests Regression (RFR) and has applied the help and learn method to data classification by constructing a multitude of decision trees for stored measurements of multiple gas production variables.\n A decade ago a second generation of choke equation models was developed, consolidating multiple databases from production operations. This choke equation has been used extensively showing single digit errors in most of gas estimations when compared against conventional well testing physical equipment readings. The use of this 2010 Choke Gas Equation (Ref. 9) has been valuable on reducing use of conventional testing equipment without jeopardizing data quality. However, the prediction error of these models starts to increase in deviating conditions such as low gas rates or increased water and condensate ratios. New data collection has been taking place considering multiple different scenarios, different time laps and additional variables. These new and enhanced databases help evaluate new models and better data-driven analytics. The application of this algorithm improves the prediction accuracy compared to traditional regression methods as it captures more of the variance in the data, thus the implementation of RFR and enables more accurate prediction of the Separator rate for the overall gas wells in the field.\n This paper, explains and applies the machine learning algorithm known as RFR (Random Forest Regression) and compare with GPR (Gaussian Process Regression) to this particular request on Gas Production Engineering metering. The algorithm allows the computer to understand underlying patterns in the data and make better predictions based on different regression trees and their use for nonlinear multiple regressions. This paper explains the application of RFR and GPR methods to the separator gas rate estimation, and shows better prediction results. This paper also explains and application of those two-machine learning algorithm (Random Forest Regression and Gaussian Process Regression) helping us to predict gas volume, using choke size, upstream and downstream flowing pressures, condensate to gas ratio (CGR) and upstream temperatures. These approaches are benchmarked against the first (back 2005) and second models (Ref. 9) and demonstrate a drastic reduction in prediction error and a more robust ability to manage high variability in the data in comparison previous models using single variable statistics tools.",
      "fieldsOfStudy": null,
      "topics": [
        "multiple gas production variables",
        "gas ratio",
        "gas estimations",
        "low gas rates",
        "gas",
        "gas volume",
        "multiple different scenarios",
        "different regression trees",
        "different pressure drop",
        "multiphase choke flow models",
        "choke equation models",
        "multiple regression studies",
        "nonlinear multiple regressions",
        "stable downstream pressure",
        "gas well productivity",
        "empirical choke flow equations",
        "choke size"
      ]
    },
    "org": {
      "title": "Training Recurrent Neural Networks by Diffusion",
      "url": "https://www.semanticscholar.org/paper/1db9ad7582ff6052f2a2cdc2d0a1bbfeeb399725",
      "abstract": "This work presents a new algorithm for training recurrent neural networks (although ideas are applicable to feedforward networks as well). The algorithm is derived from a theory in nonconvex optimization related to the diffusion equation. The contributions made in this work are two fold. First, we show how some seemingly disconnected mechanisms used in deep learning such as smart initialization, annealed learning rate, layerwise pretraining, and noise injection (as done in dropout and SGD) arise naturally and automatically from this framework, without manually crafting them into the algorithms. Second, we present some preliminary results on comparing the proposed method against SGD. It turns out that the new algorithm can achieve similar level of generalization accuracy of SGD in much fewer number of epochs.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "networks",
        "recurrent neural networks",
        "SGD",
        "annealed learning rate",
        "ideas",
        "epochs",
        "noise injection",
        "deep learning",
        "generalization accuracy",
        "smart initialization",
        "similar level",
        "nonconvex optimization",
        "dropout",
        "pretraining",
        "new algorithm",
        "feedforward networks",
        "fewer number"
      ]
    }
  },
  {
    "sim": 0.5711067887126796,
    "gen": {
      "title": "Coupled dynamics of node and link states in complex networks: a model for language competition",
      "url": "https://www.semanticscholar.org/paper/0d8381961e46f3c472952763b78f99bc701489e1",
      "abstract": "Inspired by language competition processes, we present a model of coupled evolution of node and link states. In particular, we focus on the interplay between the use of a language and the preference or attitude of the speakers towards it, which we model, respectively, as a property of the interactions between speakers (a link state) and as a property of the speakers themselves (a node state). Furthermore, we restrict our attention to the case of two socially equivalent languages and to socially inspired network topologies based on a mechanism of triadic closure. As opposed to most of the previous literature, where language extinction is an inevitable outcome of the dynamics, we find a broad range of possible asymptotic configurations, which we classify as: frozen extinction states, frozen coexistence states, and dynamically trapped coexistence states. Moreover, metastable coexistence states with very long survival times and displaying a non-trivial dynamics are found to be abundant. Interestingly, a system size scaling analysis shows, on the one hand, that the probability of language extinction vanishes exponentially for increasing system sizes and, on the other hand, that the time scale of survival of the non-trivial dynamical metastable states increases linearly with the size of the system. Thus, non-trivial dynamical coexistence is the only possible outcome for large enough systems. Finally, we show how this coexistence is characterized by one of the languages becoming clearly predominant while the other one becomes increasingly confined to \u2018ghetto-like\u2019 structures: small groups of bilingual speakers arranged in triangles, with a strong preference for the minority language, and using it for their intra-group interactions while they switch to the predominant language for communications with the rest of the population.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics"
      ],
      "topics": [
        "coexistence states",
        "frozen extinction states",
        "non-trivial dynamical coexistence",
        "language extinction vanishes",
        "increasing system sizes",
        "bilingual speakers",
        "large enough systems",
        "language competition processes",
        "non-trivial dynamical metastable states",
        "speakers",
        "possible asymptotic configurations",
        "node and link states",
        "link state",
        "frozen coexistence states",
        "metastable coexistence states",
        "language extinction",
        "system sizes",
        "dynamically trapped coexistence states"
      ]
    },
    "org": {
      "title": "Information sharing promotes prosocial behaviour",
      "url": "https://www.semanticscholar.org/paper/71bee0702bfec66f7ec4cd8899d7bef1918082bb",
      "abstract": "More often than not, bad decisions are bad regardless of where and when they are made. Information sharing might thus be utilized to mitigate them. Here we show that sharing information about strategy choice between players residing on two different networks reinforces the evolution of cooperation. In evolutionary games, the strategy reflects the action of each individual that warrants the highest utility in a competitive setting. We therefore assume that identical strategies on the two networks reinforce themselves by lessening their propensity to change. Besides network reciprocity working in favour of cooperation on each individual network, we observe the spontaneous emergence of correlated behaviour between the two networks, which further deters defection. If information is shared not just between individuals but also between groups, the positive effect is even stronger, and this despite the fact that information sharing is implemented without any assumptions with regard to content.",
      "fieldsOfStudy": [
        "Physics",
        "Computer Science",
        "Biology"
      ],
      "topics": [
        "network reciprocity",
        "correlated behaviour",
        "defection",
        "cooperation",
        "information sharing",
        "content",
        "strategy choice",
        "individual network",
        "information",
        "identical strategies",
        "different networks",
        "regard",
        "bad decisions",
        "individuals"
      ]
    }
  },
  {
    "sim": 0.5155300574429664,
    "gen": {
      "title": "Generalized Local Attention Pooling for Deep Metric Learning",
      "url": "https://www.semanticscholar.org/paper/8748d40842ab4b688cb68f636be18c40f93010e0",
      "abstract": "Deep metric learning has been key to recent advances in face verification and image retrieval amongst others. These systems consist on a feature extraction block (extracts feature maps from images) followed by a spatial dimensionality reduction block (generates compact image representations from the feature maps) and an embedding generation module (projects the image representation to the embedding space). While research on deep metric learning has focused on improving the losses for the embedding generation module, the dimensionality reduction block has been overlooked. In this work, we propose a novel method to generate compact image representations which uses local spatial information through an attention mechanism, named Generalized Local Attention Pooling (GLAP). This method, instead of being placed at the end layer of the backbone, is connected at an intermediate level, resulting in lower memory requirements. We assess the performance of the aforementioned method by comparing it with multiple dimensionality reduction techniques, demonstrating the importance of using attention weights to generate robust compact image representations. Moreover, we compare the performance of multiple state-of-the-art losses using the standard deep metric learning system against the same experiment with our GLAP. Experiments showcase that the proposed Generalized Local Attention Pooling mechanism outperforms other pooling methods when compared with current state-of-the-art losses for deep metric learning.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "robust compact image representations",
        "image retrieval",
        "images",
        "multiple dimensionality reduction techniques",
        "deep metric learning",
        "Generalized Local Attention",
        "feature maps",
        "lower memory requirements",
        "pooling methods",
        "local spatial information",
        "attention weights",
        "spatial dimensionality reduction block",
        "Generalized Local Attention Pooling",
        "Deep metric learning",
        "proposed Generalized Local Attention Pooling mechanism"
      ]
    },
    "org": {
      "title": "Delay learning architectures for memory and classification",
      "url": "https://www.semanticscholar.org/paper/b8c2db40ec53dc2e146c9acf539eff2187dc3907",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Biology"
      ]
    }
  },
  {
    "sim": 0.5379856680866528,
    "gen": {
      "title": "SemanticFusion: Dense 3D semantic mapping with convolutional neural networks",
      "url": "https://www.semanticscholar.org/paper/09c0c993500f5d15b3ccbfbec11bbb445bf51e57",
      "abstract": "Ever more robust, accurate and detailed mapping using visual sensing has proven to be an enabling factor for mobile robots across a wide variety of applications. For the next level of robot intelligence and intuitive user interaction, maps need to extend beyond geometry and appearance \u2014 they need to contain semantics. We address this challenge by combining Convolutional Neural Networks (CNNs) and a state-of-the-art dense Simultaneous Localization and Mapping (SLAM) system, ElasticFusion, which provides long-term dense correspondences between frames of indoor RGB-D video even during loopy scanning trajectories. These correspondences allow the CNN's semantic predictions from multiple view points to be probabilistically fused into a map. This not only produces a useful semantic 3D map, but we also show on the NYUv2 dataset that fusing multiple predictions leads to an improvement even in the 2D semantic labelling over baseline single frame predictions. We also show that for a smaller reconstruction dataset with larger variation in prediction viewpoint, the improvement over single frame segmentation increases. Our system is efficient enough to allow real-time interactive use at frame-rates of \u224825Hz.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "baseline single frame predictions",
        "single frame segmentation increases",
        "multiple predictions",
        "prediction viewpoint",
        "frames",
        "multiple view points",
        "maps",
        "trajectories",
        "semantics",
        "mobile robots",
        "applications",
        "\u224825Hz",
        "intuitive user interaction",
        "robot intelligence",
        "Convolutional Neural Networks",
        "single frame segmentation",
        "loopy scanning trajectories",
        "long-term dense correspondences"
      ]
    },
    "org": {
      "title": "Calorie Counter: RGB-Depth Visual Estimation of Energy Expenditure at Home",
      "url": "https://www.semanticscholar.org/paper/d3ff2dd847a4d58ef4c2536f1ae5c32cc8d6b6cc",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  {
    "sim": 0.21824978264262507,
    "gen": {
      "title": "Context-Aware Proactive Content Caching With Service Differentiation in Wireless Networks",
      "url": "https://www.semanticscholar.org/paper/85d961aa4c567e9c1d63f78e05a9f1d7b8d06820",
      "abstract": "Content caching in small base stations or wireless infostations is considered to be a suitable approach to improve the efficiency in wireless content delivery. Placing the optimal content into local caches is crucial due to storage limitations, but it requires knowledge about the content popularity distribution, which is often not available in advance. Moreover, local content popularity is subject to fluctuations, since mobile users with different interests connect to the caching entity over time. Which content a user prefers may depend on the user\u2019s context. In this paper, we propose a novel algorithm for context-aware proactive caching. The algorithm learns context-specific content popularity online by regularly observing context information of connected users, updating the cache content and observing cache hits subsequently. We derive a sublinear regret bound, which characterizes the learning speed and proves that our algorithm converges to the optimal cache content placement strategy in terms of maximizing the number of cache hits. Furthermore, our algorithm supports service differentiation by allowing operators of caching entities to prioritize customer groups. Our numerical results confirm that our algorithm outperforms state-of-the-art algorithms in a real world data set, with an increase in the number of cache hits of at least 14%.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "cache hits",
        "wireless content delivery",
        "local content popularity",
        "local caches",
        "connected users",
        "caching entities",
        "optimal cache content placement strategy",
        "mobile users",
        "customer groups",
        "context information",
        "wireless infostations",
        "context-specific content popularity",
        "cache content",
        "content popularity distribution",
        "advance",
        "Content caching",
        "small base stations"
      ]
    },
    "org": {
      "title": "Dual Reconstruction: a Unifying Objective for Semi-Supervised Neural Machine Translation",
      "url": "https://www.semanticscholar.org/paper/32ad6cdacd5229e80d14c0c5ea959867a79ad41a",
      "abstract": "While Iterative Back-Translation and Dual Learning effectively incorporate monolingual training data in neural machine translation, they use different objectives and heuristic gradient approximation strategies, and have not been extensively compared. We introduce a novel dual reconstruction objective that provides a unified view of Iterative Back-Translation and Dual Learning. It motivates a theoretical analysis and controlled empirical study on German-English and Turkish-English tasks, which both suggest that Iterative Back-Translation is more effective than Dual Learning despite its relative simplicity.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "neural machine translation",
        "Dual Learning",
        "heuristic gradient approximation strategies",
        "monolingual training data",
        "different objectives",
        "Iterative Back-Translation",
        "Iterative Back-Translation and Dual Learning",
        "controlled empirical study",
        "relative simplicity",
        "novel dual reconstruction objective",
        "Turkish-English",
        "German-English and Turkish-English tasks",
        "German-English",
        "unified view",
        "theoretical analysis",
        "English",
        "Turkish",
        "German"
      ]
    }
  },
  null,
  {
    "sim": 0.5301232040422621,
    "gen": {
      "title": "Physics-informed deep learning for incompressible laminar flows",
      "url": "https://www.semanticscholar.org/paper/88f57bdc27f45b37e916bc21702f7561753213ac",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Physics"
      ]
    },
    "org": {
      "title": "Accuracy-Reliability Cost Function for Empirical Variance Estimation",
      "url": "https://www.semanticscholar.org/paper/12155ff035066d08d585e2de3ebf62700e2c1530",
      "abstract": "In this paper we focus on the problem of assigning uncertainties to single-point predictions. We introduce a cost function that encodes the trade-off between accuracy and reliability in probabilistic forecast. We derive analytic formula for the case of forecasts of continuous scalar variables expressed in terms of Gaussian distributions. The Accuracy-Reliability cost function can be used to empirically estimate the variance in heteroskedastic regression problems (input dependent noise), by solving a two-objective optimization problem. The simple philosophy behind this strategy is that predictions based on the estimated variances should be both accurate and reliable (i.e. statistical consistent with observations). We show several examples with synthetic data, where the underlying hidden noise function can be accurately recovered, both in one and multi-dimensional problems. The practical implementation of the method has been done using a Neural Network and, in the one-dimensional case, with a simple polynomial fit.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "heteroskedastic regression problems",
        "Gaussian distributions",
        "predictions",
        "continuous scalar variables",
        "probabilistic forecast",
        "observations",
        "forecasts",
        "Gaussian",
        "single-point predictions",
        "terms",
        "underlying hidden noise function",
        "uncertainties",
        "multi-dimensional problems",
        "estimated variances",
        "problem",
        "input dependent noise"
      ]
    }
  },
  {
    "sim": 0.6142425293053448,
    "gen": {
      "title": "Robust Estimation of Multivariate Location and Scatter in the Presence of Missing Data",
      "url": "https://www.semanticscholar.org/paper/43686251bf7240305583952afe5a104a4033c2b1",
      "abstract": "Two main issues regarding data quality are data contamination (outliers) and data completion (missing data). These two problems have attracted much attention and research but surprisingly, they are seldom considered together. Popular robust methods such as S-estimators of multivariate location and scatter offer protection against outliers but cannot deal with missing data, except for the obviously inefficient approach of deleting all incomplete cases. We generalize the definition of S-estimators of multivariate location and scatter to simultaneously deal with missing data and outliers. We show that the proposed estimators are strongly consistent under elliptical models when data are missing completely at random. We derive an algorithm similar to the Expectation-Maximization algorithm for computing the proposed estimators. This algorithm is initialized by an extension for missing data of the minimum volume ellipsoid. We assess the performance of our proposal by Monte Carlo simulation and give some real data examples. This article has supplementary material online.",
      "fieldsOfStudy": [
        "Mathematics"
      ],
      "topics": [
        "missing data",
        "data contamination",
        "data quality",
        "data",
        "outliers",
        "data completion",
        "real data examples",
        "multivariate location",
        "elliptical models",
        "Monte Carlo simulation",
        "scatter",
        "Monte Carlo",
        "incomplete cases",
        "attention",
        "protection",
        "estimators",
        "minimum volume ellipsoid",
        "supplementary material"
      ]
    },
    "org": {
      "title": "MAGSAC++, a Fast, Reliable and Accurate Robust Estimator",
      "url": "https://www.semanticscholar.org/paper/69bcc03ff0ae7559bd29df88f4d47ce76795300b",
      "abstract": "We propose MAGSAC++ and Progressive NAPSAC sampler, P-NAPSAC in short. In MAGSAC++, we replace the model quality and polishing functions of the original method by an iteratively re-weighted least-squares fitting with weights determined via marginalizing over the noise scale. MAGSAC++ is fast -- often an order of magnitude faster -- and more geometrically accurate than MAGSAC. P-NAPSAC merges the advantages of local and global sampling by drawing samples from gradually growing neighborhoods. Exploiting that nearby points are more likely to originate from the same geometric model, P-NAPSAC finds local structures earlier than global samplers. We show that the progressive spatial sampling in P-NAPSAC can be integrated with PROSAC sampling, which is applied to the first, location-defining, point. The methods are tested on homography and fundamental matrix fitting on six publicly available datasets. MAGSAC combined with P-NAPSAC sampler is superior to state-of-the-art robust estimators in terms of speed, accuracy and failure rate.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "failure rate",
        "global samplers",
        "PROSAC sampling",
        "nearby points",
        "local structures",
        "P-NAPSAC sampler",
        "local and global sampling",
        "accuracy",
        "P-NAPSAC merges",
        "speed",
        "fundamental matrix",
        "terms",
        "geometric model",
        "MAGSAC",
        "weights",
        "Progressive NAPSAC sampler",
        "fundamental matrix fitting",
        "P-NAPSAC"
      ]
    }
  },
  {
    "sim": 0.6429658619378467,
    "gen": {
      "title": "Efficient estimation of eigenvalue counts in an interval",
      "url": "https://www.semanticscholar.org/paper/acb7d1dcee4dc3421115df0dcb54e976049809bc",
      "abstract": "Estimating the number of eigenvalues located in a given interval of a large sparse Hermitian matrix is an important problem in certain applications, and it is a prerequisite of eigensolvers based on a divide\u2010and\u2010conquer paradigm. Often, an exact count is not necessary, and methods based on stochastic estimates can be utilized to yield rough approximations. This paper examines a number of techniques tailored to this specific task. It reviews standard approaches and explores new ones based on polynomial and rational approximation filtering combined with a stochastic procedure. We also discuss how the latter method is particularly well\u2010suited for the FEAST eigensolver. Copyright \u00a9 2016 John Wiley & Sons, Ltd.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "rough approximations",
        "stochastic estimates",
        "eigensolvers",
        "certain applications",
        "polynomial and rational approximation filtering",
        "stochastic procedure",
        "Ltd.",
        "new ones",
        "divide\u2010and\u2010conquer paradigm",
        "Hermitian",
        "large sparse Hermitian matrix",
        "methods",
        "FEAST eigensolver",
        "Sons",
        "FEAST",
        "paradigm",
        "standard approaches"
      ]
    },
    "org": {
      "title": "MRRR-based eigensolvers for multi-core processors and supercomputers",
      "url": "https://www.semanticscholar.org/paper/7b99feba181fccdf6c2576b971b5b77a7b2c7008",
      "abstract": "The real symmetric tridiagonal eigenproblem is of outstanding importance in numerical computations; it arises frequently as part of eigensolvers for standard and generalized dense Hermitian eigenproblems that are based on a reduction to tridiagonal form. For its solution, the algorithm of Multiple Relatively Robust Representations (MRRR or MR3 in short) - introduced in the late 1990s - is among the fastest methods. To compute k eigenpairs of a real n-by-n tridiagonal T, MRRR only requires O(kn) arithmetic operations; in contrast, all the other practical methods require O(k^2 n) or O(n^3) operations in the worst case. This thesis centers around the performance and accuracy of MRRR.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "arithmetic operations",
        "tridiagonal form",
        "MRRR",
        "O(n^3",
        "numerical computations",
        "standard and generalized dense Hermitian eigenproblems",
        "outstanding importance",
        "contrast",
        "Hermitian",
        "worst case",
        "fastest methods",
        "eigensolvers",
        "The real symmetric tridiagonal eigenproblem",
        "O(kn",
        "Multiple Relatively Robust Representations",
        "O(kn) arithmetic operations"
      ]
    }
  },
  null,
  {
    "sim": 0.6802277429639418,
    "gen": {
      "title": "A Game-Theoretic Approach to Design Secure and Resilient Distributed Support Vector Machines",
      "url": "https://www.semanticscholar.org/paper/e339204a70917d8e27cac1cce59119ae8d665d1f",
      "abstract": "Distributed support vector machines (DSVMs) have been developed to solve large-scale classification problems in networked systems with a large number of sensors and control units. However, the systems become more vulnerable, as detection and defense are increasingly difficult and expensive. This paper aims to develop secure and resilient DSVM algorithms under adversarial environments in which an attacker can manipulate the training data to achieve his objective. We establish a game-theoretic framework to capture the conflicting interests between an adversary and a set of distributed data processing units. The Nash equilibrium of the game allows predicting the outcome of learning algorithms in adversarial environments and enhancing the resilience of the machine learning through dynamic distributed learning algorithms. We prove that the convergence of the distributed algorithm is guaranteed without assumptions on the training data or network topologies. Numerical experiments are conducted to corroborate the results. We show that the network topology plays an important role in the security of DSVM. Networks with fewer nodes and higher average degrees are more secure. Moreover, a balanced network is found to be less vulnerable to attacks.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Medicine"
      ],
      "topics": [
        "distributed data processing units",
        "dynamic distributed learning algorithms",
        "adversarial environments",
        "algorithms",
        "Distributed support vector machines",
        "DSVMs",
        "networked systems",
        "network topologies",
        "secure and resilient DSVM algorithms",
        "large-scale classification problems",
        "sensors and control units",
        "higher average degrees",
        "Networks",
        "distributed algorithm",
        "learning algorithms",
        "control units",
        "DSVM",
        "training data"
      ]
    },
    "org": {
      "title": "Spatial-Temporal Moving Target Defense: A Markov Stackelberg Game Model",
      "url": "https://www.semanticscholar.org/paper/b46ca7cb5ec71294e644d362350e98ac0b0d125c",
      "abstract": "Moving target defense has emerged as a critical paradigm of protecting a vulnerable system against persistent and stealthy attacks. To protect a system, a defender proactively changes the system configurations to limit the exposure of security vulnerabilities to potential attackers. In doing so, the defender creates asymmetric uncertainty and complexity for the attackers, making it much harder for them to compromise the system. In practice, the defender incurs a switching cost for each migration of the system configurations. The switching cost usually depends on both the current configuration and the following configuration. Besides, different system configurations typically require a different amount of time for an attacker to exploit and attack. Therefore, a defender must simultaneously decide both the optimal sequences of system configurations and the optimal timing for switching. In this paper, we propose a Markov Stackelberg Game framework to precisely characterize the defender's spatial and temporal decision-making in the face of advanced attackers. We introduce a relative value iteration algorithm that computes the defender's optimal moving target defense strategies. Empirical evaluation on real-world problems demonstrates the advantages of the Markov Stackelberg game model for spatial-temporal moving target defense.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "different system configurations",
        "potential attackers",
        "advanced attackers",
        "Moving target defense",
        "system configurations",
        "security vulnerabilities",
        "persistent and stealthy attacks",
        "Markov Stackelberg",
        "vulnerable system",
        "spatial-temporal moving target defense",
        "defenders optimal moving target defense strategies",
        "system",
        "system",
        "following configuration",
        "target defense"
      ]
    }
  },
  {
    "sim": 0.5293275659995338,
    "gen": {
      "title": "Pruning Filters for Efficient ConvNets",
      "url": "https://www.semanticscholar.org/paper/c2a1cb1612ba21e067a5c3ba478a8d73b796b77a",
      "abstract": "The success of CNNs in various applications is accompanied by a significant increase in the computation and parameter storage costs. Recent efforts toward reducing these overheads involve pruning and compressing the weights of various layers without hurting original accuracy. However, magnitude-based pruning of weights reduces a significant number of parameters from the fully connected layers and may not adequately reduce the computation costs in the convolutional layers due to irregular sparsity in the pruned networks. We present an acceleration method for CNNs, where we prune filters from CNNs that are identified as having a small effect on the output accuracy. By removing whole filters in the network together with their connecting feature maps, the computation costs are reduced significantly. In contrast to pruning weights, this approach does not result in sparse connectivity patterns. Hence, it does not need the support of sparse convolution libraries and can work with existing efficient BLAS libraries for dense matrix multiplications. We show that even simple filter pruning techniques can reduce inference costs for VGG-16 by up to 34% and ResNet-110 by up to 38% on CIFAR10 while regaining close to the original accuracy by retraining the networks.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "inference costs",
        "original accuracy",
        "layers",
        "dense matrix multiplications",
        "irregular sparsity",
        "connecting feature maps",
        "computation costs",
        "existing efficient BLAS libraries",
        "pruned networks",
        "sparse connectivity patterns",
        "sparse convolution libraries",
        "computation and parameter storage costs",
        "parameters",
        "networks",
        "ResNet-110"
      ]
    },
    "org": {
      "title": "Data-dependent Pruning to find the Winning Lottery Ticket",
      "url": "https://www.semanticscholar.org/paper/15ee10ffa90a4b354928d3e3e5fa18a9a9aff1a9",
      "abstract": "The Lottery Ticket Hypothesis postulates that a freshly initialized neural network contains a small subnetwork that can be trained in isolation to achieve similar performance as the full network. Our paper examines several alternatives to search for such subnetworks. We conclude that incorporating a data dependent component into the pruning criterion in the form of the gradient of the training loss -- as done in the SNIP method -- consistently improves the performance of existing pruning algorithms.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "similar performance",
        "existing pruning algorithms",
        "subnetworks",
        "isolation",
        "network",
        "SNIP",
        "small subnetwork",
        "pruning criterion",
        "alternatives",
        "performance",
        "freshly initialized neural network",
        "SNIP method",
        "training loss",
        "data dependent component",
        "gradient",
        "The Lottery Ticket Hypothesis"
      ]
    }
  },
  {
    "sim": 0.686546671164153,
    "gen": {
      "title": "Learning to compress and search visual data in large-scale systems",
      "url": "https://www.semanticscholar.org/paper/b58a9cf29e4754538a916a971737a9475aa2df9b",
      "abstract": "The problem of high-dimensional and large-scale representation of visual data is addressed from an unsupervised learning perspective. The emphasis is put on discrete representations, where the description length can be measured in bits and hence the model capacity can be controlled. The algorithmic infrastructure is developed based on the synthesis and analysis prior models whose rate-distortion properties, as well as capacity vs. sample complexity trade-offs are carefully optimized. These models are then extended to multi-layers, namely the RRQ and the ML-STC frameworks, where the latter is further evolved as a powerful deep neural network architecture with fast and sample-efficient training and discrete representations. For the developed algorithms, three important applications are developed. First, the problem of large-scale similarity search in retrieval systems is addressed, where a double-stage solution is proposed leading to faster query times and shorter database storage. Second, the problem of learned image compression is targeted, where the proposed models can capture more redundancies from the training images than the conventional compression codecs. Finally, the proposed algorithms are used to solve ill-posed inverse problems. In particular, the problems of image denoising and compressive sensing are addressed with promising results.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "shorter database storage",
        "faster query times",
        "prior models",
        "discrete representations",
        "learned image compression",
        "promising results",
        "capacity",
        "image denoising",
        "sample complexity trade-offs",
        "redundancies",
        "powerful deep neural network architecture",
        "visual data",
        "retrieval systems",
        "compressive sensing",
        "bits",
        "sample complexity",
        "model capacity",
        "fast and sample-efficient training"
      ]
    },
    "org": {
      "title": "Superpixels: An evaluation of the state-of-the-art",
      "url": "https://www.semanticscholar.org/paper/f4d62a0c053da65ad5888547b3c9e3b18361cb44",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  {
    "sim": 0.6665987168078598,
    "gen": {
      "title": "Scalable Video Streaming over Wireless Access Networks",
      "url": "https://www.semanticscholar.org/paper/07d1cb7615b1193b61975cd59d364aacce827a55",
      "abstract": ": Cloud mixed media administrations give a competent, adaptable, and versatile information preparing technique and offer an illustration for the client requests of high calibre, differentiate sight and sound. As a rule, getting to sight and sound video benefits through systems is never again a problem. The real video stages, for example, YouTube and Amazon, have great administration styles and give clients to share interactive media recordings effectively with enhanced administrations. Regardless of what the administration is, clients will dependably anticipate ground-breaking, sound and stable capacities. For sight and sound recordings, solidness is of the best significance. As astute cell phones and remote systems turn out to be increasingly prevalent, organize administrations for clients are never again constrained to the home. Mixed media data can be acquired effectively utilizing cell phones; enabling clients to appreciate wherever arrange administrations. b) Abstract: The goal of minimizing the distortion of the received videos is why we are considering the problem of scalable video streaming from a server to multi network clients over heterogeneous access networks. This problem has multiple applications including: 1) mobile devices that connects to multiple licensed and ISM bands, and 2) intellectual multi radio devices employing spectrum bonding. This paper is to discover how to transmits the correct video packets over the networks. In order to capture the network conditions and video characteristics and develop an integer program for packet scheduling, the models are being presented by us. We develop heuristic algorithms for deterministic packet scheduling and convex optimization problems for randomized packet scheduling to solve the integer program exactly which is typically not tractable. A thorough study of the tradeoff between performance and computational complexity is carried out and convex programming-based algorithm that yields good performance while being suitable for real-time applications is being proposed. We conduct extensive trace-driven simulations to rate the proposed algorithms using real network conditions and scalable video streams. The results show that the proposed convex programming-based algorithm: 1) the rate control algorithms defined in the Datagram Congestion Control Protocol (DCCP) by about 10\u201315 dB higher video quality is outstripped; 2) average delivery delay by over 90% compared to DCCP has been reduced; 3) higher average video quality of 4.47 and 1.92 dB than the two developed heuristics is being resulted; 4) runs efficiently, up to six times faster than the best-performing heuristic; and 5) does indeed provide service differentiation among users. b) Abstract: In this paper, wireless video transmissions under total bandwidth and energy efficiency constraints are studied. The quality of service requirements such as statistical delay constraints are also considered, to provide the desired performance levels to the end-users in real-time video transmissions. Effective capacity is used as the throughput metric in the presence of such statistical delay constraints since deterministic delay bounds are difficult to guarantee due to the time-varying nature of wireless fading channels. A multiuser setup where different users have different delay guarantees is addressed. Following characterizations from the rate-distortion theory, a logarithmic model of the quality-rate relation is used for predicting the quality of the reconstructed video in terms of the peak signal-to-noise ratio at the receiver side. The sum video quality subject to total bandwidth and minimum EE constraints are derived that are maximized by the optimal bandwidth allocation and the optimal power allocation/power control policies. Investigations are being done for the five different resource allocation and the joint optimization of the bandwidth allocation and power control provides the best performance are shown as the result. The tradeoff between EE and video quality is also demonstrated since higher EE results in lower quality of received video sequence. under band- power quality reveal that increasing the QoS exponent _ leads to a decrease in quality. Additionally, increasing the EE threshold decreases the performance. Overall, we have considered different strategies of bandwidth allocation and power allocation/power control, and we have demonstrated that the JBAPC has the best performance since it maximizes the PSNR by allocating bandwidth and performing power control jointly while taking advantage of the instantaneous CSI of each channel b) Abstract: A good real-time encryption with high flexibility is achieved by Stream cryptosystems, that implements encryption by selecting parts of the block data and header information of the compressed video stream. Chaotic random number generator-based approaches, for example, logistics maps, are better promising approaches but are exposed to attacks by nonlinear dynamic forecasting. So as to encode the packed video with the co ordinations map with a Z field straight congruential calculation to reinforce the security of the mono-disorderly cryptography, a composite clamorous cryptography plot was created. The real-time performance and flexibility of the chaotic sequence cryptography is maintained by the scheme. The scheme also integrated asymmetrical public-key cryptography and encryption and identity authentication of control parameters at the initialization phase. c) Conclusion: A composite chaotic sequence encryption approach combines the original logistics map with the linear congruentual algorithm in the Mersenne field to provide real-time processing for the security requirements of multimedia streams. The algorithm has the following advantages: Preserves the advantages, the flexible implementation of mono-chaotic schemes, adaptable parameters, and a large pseudo-random sequence space. Effectively resists nonlinear forecasting and attractive point attacks. Less iterations and computation complexity to develop large sequences with reasonable pseudo randomness. 4) Layered and content based encryption can be used for real-time, effective encryption of compressed video. 5) Public cryptosystem is employed for control parameter encryption and signatures for network security requirements. 5) Paper Title: How Dia-Shows Turn Into Video Flows: Adapting Scalable Video Communication to Heterogeneous Network Conditions in Real-Time the early congestion at the on the variation A sustained good put to extract a feasible scaling used for b) Abstract: Some state-of-the-art video stabilization methods can achieve quite good visual effect, but they always cost a lot of time. current real-time video stabilization methods were not found generate satisfactory results. Here, a novel trajectory-based video stabilization method is proposed that generates high-quality results in real time. Since many techniques are proposed for acceleration, our method runs fast. Trajectories are extracted, pre-processed, and smoothed in the trajectory smoothing step,. For pre-processing, and binomial _altering, a video splitting algorithm is proposed which is used for b) Abstract: An imperative plan of adjusting multi-client video spilling over remote systems is the means by which to advance the deliberate planning by keenly using the accessible system assets while, in the meantime, to fulfill each video's Nature of Administration (QoS) prerequisite. In this work, the problem of video steaming over multi-channel multi-radio multi-hop wireless networks is studied and fully distributed scheduling schemes with the goals of minimizing the video distortion is developed and certain fairness is obtained. A general distortion model according to the network\u2019s transmission mechanism is being constructed and also video\u2019s rate-distortion characteristics is studied. After that we a convex optimization problem is scheduled and distributed solution by joint considering channel assignment, rate allocation, and routing is proposed. sensor good example. As we know, current sensor networks due to their limit transmit capacities can large of multimedia data Peer-to-Peer File- Workload 2) Abstract: For an astonishing volume of current Internet traffic, Peer-to-peer (P2P) file sharing accounts is used. This paper investigates deeply into modern P2P file sharing systems as well as the forces that drive them. So, our understanding of P2P file sharing workloads is increased and their implications for future multimedia workloads is also higher. We have used a three-tiered approach. Initially, we went through a 200-day trace of over 20 terabytes of Kazaa P2P traffic collected at the University of Washington. Then, a model of multimedia workloads is developed that lets us isolate, vary, and explore the smack of key system parameters. This model, which we measure with statistics from our trace, will enable us to confirm various hypotheses about file-sharing behavior observed in the trace. Third, the potential impact of locality awareness in Kazaa is being explored. Dramatic differences between P2P file sharing and Web traffic is resulted. For instance, we show how the changelessness of Kazaa's sight and sound articles drives customers to get protests at most once; conversely, a World-Wide Web customer may get a prominent page a large number of times. Moreover, we demonstrate that: (1) The Kazaa popularity distribution is deviated substantially from Zipf curves due to this \u201cfetch-at-most-once\u201d behavior we see for the Web and (2) this caused significant implications for the performance of multimedia file-sharing systems. Hose workload is driven by document change, unlike the Web. Traffic identification has become a key issue for efficient network management, with the rapid development of the Internet and a vigorous emergence of new applications. Though various methods have been proposed, there are still many limitations to achieving ",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "higher video quality",
        "video",
        "compressed video",
        "received video sequence",
        "video characteristics",
        "Video Flows",
        "wireless video transmissions",
        "real time",
        "scalable video streaming",
        "sound video benefits",
        "multi-client video",
        "real network conditions",
        "network clients",
        "control parameter encryption",
        "video quality",
        "Scalable Video Communication",
        "multi network clients",
        "multi-channel multi-radio multi-hop wireless networks"
      ]
    },
    "org": {
      "title": "Online strategies for intra and inter provider service migration in virtual networks",
      "url": "https://www.semanticscholar.org/paper/f9b8e11639fb975ca9b95c7787c4f8b9d59a33f7",
      "abstract": "Network virtualization allows one to build dynamic distributed systems in which resources can be dynamically allocated at locations where they are most useful. In order to fully exploit the benefits of this new technology, protocols need to be devised which react efficiently to changes in the demand. This paper argues that the field of online algorithms and competitive analysis provides useful tools to deal with and reason about the uncertainty in the request dynamics, and to design algorithms with provable performance guarantees.\n As a case study, we describe a system (e.g., a gaming application) where network virtualization is used to support thin client applications for mobile devices to improve their Quality-of-Service (QoS). By decoupling the service from the underlying resource infrastructure, it can be migrated closer to the current client locations while taking into account migration cost. This paper identifies the major cost factors in such a system, and formalizes the corresponding optimization problem. Both randomized and deterministic, gravity center based online algorithms are presented which achieve a good tradeoff between improved QoS and migration cost in the worst-case, both for service migration within an infrastructure provider as well as for networks supporting cross-provider migration. We report on our simulation results and also present an explicit construction of an optimal offline algorithm which can be used, e.g., to evaluate the competitive ratio empirically.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "migration cost",
        "account migration cost",
        "service migration",
        "cross-provider migration",
        "provable performance guarantees",
        "online algorithms",
        "thin client applications",
        "useful tools",
        "algorithms",
        "dynamic distributed systems",
        "network virtualization",
        "improved QoS",
        "competitive analysis",
        "networks",
        "Service",
        "locations"
      ]
    }
  },
  {
    "sim": 0.37018898845138026,
    "gen": {
      "title": "Review of Remote ECG signal Monitoring , Preprocessing and Arrhythmia Detection",
      "url": "https://www.semanticscholar.org/paper/687c118d7a50d5b84e185c89802eadb8aa4d0711",
      "abstract": "ECG signal is one of the most significant biomedical signals, which is used to reflect the activity of human heart, and it is considered as one of better understood signals, that can provide basic information to diagnosis of heart disease. Therefore, different study and intensive research are developed in recent years, also different effective techniques and methods are proposed for analysis and processing in order to discover essential and new diagnostic information. In this paper, we are introduced literature review of significant study, techniques and algorithms, which are applied to ECG signal, some of these method are used to pre-process the ECG signal in order to increase the accuracy of diagnosis of heart problem, while other techniques are used to classify the signal automatically. The study is explained the methods that are applied to extract the ECG signal with different monitoring system either directly or by using remote monitoring system depending on some technique, also the ECG signal algorithms and methods are described in some details. Because QRS complex part of the ECG signal is considered the most significant information of the signal, different algorithm to detect this peak are explained in our study, finally, the classification algorithm of the ECG signal is described, classification is used to determine the statue of the heart activity and according it, classify the problem. Key word: ECG, ANN, Raspberry Pi and QRS. 1-Introduction: In recent years, different smart systems have been researched by using internet of things and intelligent algorithm, some of these research are devoted for monitoring purpose, and the others is proposed for prediction or classification for controlling purpose based on intelligent deep learning algorithms. The studies and researches of the previous works will be presented according to devoted research efforts and method used. Cardiovascular disease is considered largest threat to human health fin last decades, and millions of people is died because of treatment is delayed ,so (ECG) signal can be used to analysis the patients statue because it provide high indication about heart activity, ECG analysis is become key point of analysis patient condition , and this make it very important signal, ECG has different characteristics, the As the most important information of ECG is QRS complex .different research and study are introduced to deal with this signal some of it are used extract it, other are used to preprocessing it in different method such as de-noising and enhancement and other techniques are used to detect QRS complex by using two approaches of study , which is accomplished by software and hardware methods [1]. In this paper, Journal of Education for Pure ScienceUniversity of Thi-Qar Vol.10, No.2 (June, 2020) Website: jceps.utq.edu.iq Email: jceps@eps.utq.edu.iq 168 literature review of some significant study and techniques are introduced, which are performed to ECG signal in order to increase the accuracy of diagnosis of heart problem, the study are explained the methods that are applied to extract the ECG signal with different monitoring system either directly or by using remote monitoring system depending on some technique, also the ECG signal algorithms and methods are described in some details. Because QRS complex part of the ECG signal is considered the most significant information of the signal, different algorithm to detect this peak are explained in our study, finally, the classification algorithm of the ECG signal is described, classification is used to determine the statue of the heart activity and according it, classify the problem [1][2]. 1. ECG Monitoring Systems: There are wide range of interesting fields of IOT researches that are applied to extract the ECG signal for monitoring, this research can be summarized in the following sections. In 2019, Warish et.al.[1] Proposed a System, by using internet of medical think (IoMT) that can be used detect the Heartbeats and classify different types of abnormal Rhythms. This work was used ECG sensor, Raspberry Pi 3 and temperature sensor to monitor real time state of patients. This technique is used by doctor to detect problems of health, in this work different types of filters was used to eliminate electrograph noise with other functions that is used to preprocess the collected signals. The proposed system delivers appropriate medical assistance by using Deep Neural Networks (DNN) to analysis the collected data. In 2019, Jasti et.al.[2] proposed work for continuously monitoring patient by using sensors like body temperature sensor, pulse rate and ECG sensor.in this system the sensors read the data continuously, If the sensor values of the temperature and the ECG sensor reading value greater than specific threshold value, it will alert the patient and patient\u2019s relative by sending the SMS to the android mobile otherwise the reading is repeated. In 2017, Rashida et.al [3] proposed an IOT Gateway based on using Wi-Fi protocols and Zigbee to transmit data between WSNs and mobile communication networks. In this work, the data is checked by checksum bit Before sending it to internet. Checksum bit is transmitted by sensor and it is calculated again at Gateway. If calculated checksum bit is equal to those, which are sent by by sensor nodes, then data is sent to internet. In 2017, Andre et.al [4] presented IoT gateway for real-time monitoring, the proposed system is accomplished by hardware, which is used to support multiple communication protocols and flexible to run adaptable software. Hard ware component of the system was consisting of a Raspberry Pi, which is used as station node, with Arduino in addition to sensors to collect data and a web to be used for monitor the network. In 2018, Surekha. et.al. [5] propose health monitor system based on different sensors such as temperature, blood pressure, ECG and heart beat readings, these data are monitored using Microcontroller, also they used amplifier circuit to gain up the signal and transmit the signals to the Microcontroller. The internet it acts as a server. Which sends the data to the website? anybody anywhere in the world can monitor the patient\u2019s health using any device connected to the internet. If the sensed data is going abnormal according to some parameters, then the system automatically send SMS alert message to doctors and patient\u2019s relative. In 2016, Poonam et. al. [6] proposed an idea to save a patient's life, which can be benefitted for users as it is save time. The ambulance can arrive at patient location based on the information, which is given through the app and can provide the basic requirement for patient's health. By using this application, the Journal of Education for Pure ScienceUniversity of Thi-Qar Vol.10, No.2 (June, 2020) Website: jceps.utq.edu.iq Email: jceps@eps.utq.edu.iq 169 information about the appropriate hospital which is suitable can be obtained. This data is sent through the ambulance to keep track the patient\u2019s status. And this information is send to hospitals helps the hospital staff to give the necessary treatment. In 2017, Harishchandra et.al.[7] implemented a fog computing system based on Raspberry Pi, which is used for extraction, storage and computing, to collect the various medical data like Phonocardiogram (PCG) signal, and Electrocardiogram (ECG)-based on Q, R, S detection. Their system was constructed from wearable data collection to collect data with gate way, fog architecture, which is assisted the medical internet of think, cloud that is used for storage and computation purpose and display unit that is used for clinical. They are proved that the proposed system can be used to enhance the signal, analysis and processing different kinds of bio-signals. In 2017, Anand et.al.[8] designed monitoring of health system to measure blood pressure, heart rate and heart sound count using Raspberry Pi. They used IOT device with Raspberry Pi Board to interfaces with device sensor. The sensor is sensed the patient health parameters and send the collected data to the raspberry pi. Also camera can be used to send image of patient to raspberry pi, this image with other sensed data parameters are sent to user interface page, so doctor or any other user can get patient information by access the Raspberry based on address of IP of Raspberry Pi in the internet. In 2018, Rohit et. al [9] used different sensors for sensing the real time status of the patients such as ECG sensors, blood pressure sensor, etc, in order to diagnosis the patient disease and provided efficient medical services to the patient in fast time. The proposed system includes a data extraction and data processing, which is used to transmit patient data to the medical staff through Internet of things (IoT). this system increased the efficiency of wireless sensor nodes and satisfied high storage capacity serves compared with other system. In 2018, Chandini et.al in [10] proposed a n ECG monitoring system based on wearable ECG monitoring node, which can collect the ECG signal from patients and transmitted it to IoT cloud based on Wi-Fi by using open source protocols like DTLS/UDP, TLS/TCP, CoAP/HTTP, MQTT and OMALWM2M protocol in data communication. Also they are used Various networks including, Zig-bee, Wi-Fi, Bluetooth and BLE and they are compared between them according to the achieved results. Monitoring methods are produced and implemented for ECG monitoring based different IOT models and protocols. In 2019, Seena et. al. [11] proposed monitoring system based on different sensors such as, heartbeat sensor, the temperature sensor, an acceleration sensor and an ECG sensor, these sensors are interconnected with the Raspberry Pi device. It gathered the data at every time and they used 3G to displayed the collected information on LCD user devices and also on the doctor\u2019s device, those should be synchronized with the server system. In 2018, Ayaskanta et. al. [12] p",
      "fieldsOfStudy": null,
      "topics": [
        "ECG signal",
        "ECG sensors",
        "ECG monitoring",
        "different sensors",
        "different monitoring system",
        "signals",
        "ECG analysis",
        "wearable ECG monitoring node",
        "ECG",
        "device sensor",
        "different smart systems",
        "system",
        "temperature sensor",
        "different method",
        "patient data",
        "patient information",
        "monitoring system",
        "health system",
        "sensed data parameters",
        "patient"
      ]
    },
    "org": {
      "title": "Closed-Form Critical Conditions of Subharmonic Oscillations for Buck Converters",
      "url": "https://www.semanticscholar.org/paper/8d682adde8aaff96743f355bd85c4a4deee5bb84",
      "abstract": "Based on a general critical condition of subharmonic oscillation in terms of the loop gain, many closed-form critical conditions for various control schemes in terms of converter parameters are derived. Some previously known critical conditions become special cases in the generalized framework. Given an arbitrary control scheme, a systematic procedure is proposed to derive the critical condition for that control scheme. Different control schemes share similar forms of critical conditions. For example, both V2 control and proportional voltage mode control have the same form of critical condition. A peculiar phenomenon in average current mode control where subharmonic oscillation occurs in a window value of pole can be explained by the derived critical condition. A ripple amplitude index to predict subharmonic oscillation proposed in the past research has limited application and is shown invalid for a converter with a large pole comparable to the switching frequency.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Physics"
      ],
      "topics": [
        "control schemes",
        "Different control schemes",
        "proportional voltage mode control",
        "closed-form critical conditions",
        "average current mode control",
        "subharmonic oscillation",
        "similar forms",
        "critical condition",
        "converter parameters",
        "special cases",
        "pole"
      ]
    }
  },
  {
    "sim": 0.6380761524946383,
    "gen": {
      "title": "Importance Driven Continual Learning for Segmentation Across Domains",
      "url": "https://www.semanticscholar.org/paper/9663d435cf29e5b62b7ebf859bb21b0f3c37b75f",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    },
    "org": {
      "title": "The Heterogeneity Hypothesis: Finding Layer-Wise Differentiated Network Architectures",
      "url": "https://www.semanticscholar.org/paper/db373bb8b75d74baef533e58c3f3d08b0aa20b3f",
      "abstract": "In this paper, we tackle the problem of convolutional neural network design. Instead of focusing on the design of the overall architecture, we investigate a design space that is usually overlooked, i.e. adjusting the channel configurations of predefined networks. We find that this adjustment can be achieved by shrinking widened baseline networks and leads to superior performance. Based on that, we articulate the \"heterogeneity hypothesis\": with the same training protocol, there exists a layer-wise differentiated net-work architecture (LW-DNA) that can outperform the original network with regular channel configurations but with a lower level of model complexity.The LW-DNA models are identified without extra computational cost or training time compared with the original network. This constraint leads to controlled experiments which direct the focus to the importance of layer-wise specific channel configurations. LW-DNA models come with advantages related to overfitting, i.e. the relative relationship between model complexity and dataset size. Experiments are conducted on various networks and datasets for image classification, visual tracking and image restoration. The resultant LW-DNA models consistently outperform the baseline models. Code is available at https://github.com/ofsoundof/Heterogeneity_Hypothesis.git.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "predefined networks",
        "model complexity",
        "regular channel configurations",
        "convolutional neural network design",
        "networks",
        "image restoration",
        "shrinking widened baseline networks",
        "image classification",
        "visual tracking",
        "superior performance",
        "layer-wise specific channel configurations",
        "datasets",
        "training time",
        "extra computational cost",
        "widened baseline networks",
        "original network"
      ]
    }
  },
  {
    "sim": 0.25000380304790004,
    "gen": {
      "title": "Wearable Electromagnetic Head Imaging System",
      "url": "https://www.semanticscholar.org/paper/5808b4d6e436bf444081adac45971f1dacf37afb",
      "abstract": "Strokes are among the leading causes of long-term disability and death worldwide. This emergency health dilemma requires a rapid and accurate medical diagnosis for prompt medicinal treatment to prevent permanent disability or the possibility of death. Currently, MRI and CT scan devices are used for stroke diagnosis, and they can provide accurate detection. However, they are relatively costly, not accessible in all hospitals, especially in rural areas.\u00a0 Besides, these devices are bulky and mostly fixed, so cannot be transported by the first paramedic responders and consequently, cannot enable the early detection of stroke that would enable the patient to receive life-saving medication instantly. The aim of this thesis is to present the design and development of a wearable, wideband electromagnetic head imaging system for on-the-spot stroke diagnosis; one that is compatible, safe, lightweight, compact, and low-cost.This thesis makes several contributions to the current state of knowledge in the field of electromagnetic imaging. The first contribution includes the design and development of several flexible, low-profile, compact, and wideband on-body matched imaging antennas that operate at the lower microwave frequencies, with unidirectional near-field radiation and low SAR values.The second contribution is the design and development of multiple wearable wideband single-array electromagnetic head imaging systems as a proof-of-concept, utilizing the developed on-body matched imaging antennas. Subsequently, a fully integrated single-array wideband flexible custom-built electromagnetic cap for stroke detection is developed. The custom-built electromagnetic cap aims at overcoming the challenges of sizes, rigidities, and the complex structures of existing electromagnetic head imaging systems. The developed electromagnetic cap is experimentally validated with homogeneous head models, 3D realistic head phantoms, and several stroke-emulating targets. The imaging results using a polar sensitivity encoding (PSE) image processing algorithm demonstrate the merits and feasibility of the system for preclinical trials.The third contribution is the development of a new flexible, high-permittivity custom-made polymer-ceramic composite dielectric substrate, namely PDMS-Al2O3-C for on-body imaging antennas to attain higher efficiency and better match with the human head. The dielectric properties of the developed PDMS-Al2O3-C substrate can be tuned using different weight-ratio of fillers to suit various sensing antenna designs. Furthermore, an ultra-flexible, stretchy, and robust high-permittivity RTV-Al2O3 dielectric substrate is also developed from the mixture of the room-temperature-vulcanizing (RTV) silicone and aluminum oxide (Al2O3) powder. The advantages of developed dielectric substrates include the desirable dielectric properties that can improve the matching of the antennas with human head tissues, and the flexibility feature that allows the system to be configured and assembled in desired conformal shapes.To improve the coupling of the electromagnetic signal into the brain tissues, and to overcome the critical signal mismatch between the antenna array and skin of the head that can occur due to thick hairs or an air-gap in front of the antenna elements, different resilient purpose-built matching mediums are developed to cover the apertures of the antenna array with actual-mimicking dispersive dielectric properties close to those in head tissues. Unlike the existing matching mediums that mostly utilize liquids or semi-liquid materials and require complicated handling techniques to avoid leaking, the developed materials are highly flexible, durable and can be removed and replaced without affecting the antenna elements.The fifth contribution of this thesis includes the development of a double-array wideband flexible electromagnetic cap for stroke detection with the aim of achieving 3D and 2D multi-slice image reconstructions. The antenna array is configured as two semi-elliptical rings in the developed cap with a total of 24 elements to enable the generation of a 3D or 2D image of the brain. The detection capability of the system is then experimentally verified on the homogenous and 3D realistic head phantoms with multiple imaging scenarios and different types of stroke-emulating targets. The reconstructed 3D and 2D multi-slice images using the beamforming and polar sensitivity encoding (PSE) image processing algorithms indicate the applicability and potential of the proposed cap for future brain imaging.Finally, the developed compact, wideband, flexible, on-body matched antennas with comprehensive near-field and time-domain analysis have positively contributed to the fundamental specifications and requirements of efficient biomedical imaging antennas. On the other hand, the developed flexible polymer-ceramic substrate materials and matching medium materials in this thesis, contribute to the ongoing research in the field of electronic materials, which indicates the possibility of customizing the dielectric materials and their dielectric properties and mechanical features to meet not only the requirements of a wearable electromagnetic imaging system, but also other RF and microwave applications.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "existing electromagnetic head imaging systems",
        "electromagnetic imaging",
        "human head tissues",
        "developed dielectric substrates",
        "3D realistic head phantoms",
        "future brain imaging",
        "efficient biomedical imaging antennas",
        "sensing antenna designs",
        "multiple imaging scenarios",
        "multiple wearable wideband single-array electromagnetic head imaging systems",
        "homogeneous head models",
        "stroke detection",
        "semi-liquid materials",
        "stroke diagnosis",
        "matching medium materials"
      ]
    },
    "org": {
      "title": "Importance Sampling for Pathwise Sensitivity of Stochastic Chaotic Systems",
      "url": "https://www.semanticscholar.org/paper/b58077ab005797e8b7e02f3db2038c34a8f29ffb",
      "abstract": "This paper proposes a new pathwise sensitivity estimator for chaotic SDEs. By introducing a spring term between the original and perturbated SDEs, we derive a new estimator by importance sampling. The variance of the new estimator increases only linearly in time $T,$ compared with the exponential increase of the standard pathwise estimator. We compare our estimator with the Malliavin estimator and extend both of them to the Multilevel Monte Carlo method, which further improves the computational efficiency. Finally, we also consider using this estimator for the SDE with small volatility to approximate the sensitivities of the invariant measure of chaotic ODEs. Furthermore, Richardson-Romberg extrapolation on the volatility parameter gives a more accurate and efficient estimator. Numerical experiments support our analysis.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "chaotic ODEs",
        "new pathwise sensitivity estimator",
        "importance sampling",
        "standard pathwise estimator",
        "small volatility",
        "new estimator",
        "Malliavin estimator",
        "Multilevel Monte Carlo method",
        "estimator",
        "estimator",
        "computational efficiency",
        "time",
        "accurate and efficient estimator",
        "Malliavin"
      ]
    }
  },
  null,
  {
    "sim": 0.521531902152038,
    "gen": {
      "title": "Learning from the memory of Atari 2600",
      "url": "https://www.semanticscholar.org/paper/6d5dcccf53d671d69cd0fc95b6ca9fbb8618c88e",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    },
    "org": {
      "title": "Revealing the Structure of Deep Neural Networks via Convex Duality",
      "url": "https://www.semanticscholar.org/paper/6aa86110a83febcb6064348644470d90678aa7cd",
      "abstract": "We study regularized deep neural networks (DNNs) and introduce a convex analytic framework to characterize the structure of the hidden layers. We show that a set of optimal hidden layer weights for a norm regularized DNN training problem can be explicitly found as the extreme points of a convex set. For the special case of deep linear networks with $K$ outputs, we prove that each optimal weight matrix is rank-$K$ and aligns with the previous layers via duality. More importantly, we apply the same characterization to deep ReLU networks with whitened data and prove the same weight alignment holds. As a corollary, we prove that norm regularized deep ReLU networks yield spline interpolation for one-dimensional datasets which was previously known only for two-layer networks. Furthermore, we provide closed-form solutions for the optimal layer weights when data is rank-one or whitened. We then verify our theory via numerical experiments.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "optimal hidden layer weights",
        "whitened data",
        "deep neural networks",
        "deep linear networks",
        "optimal layer weights",
        "data",
        "norm regularized DNN training problem",
        "spline interpolation",
        "norm",
        "weight alignment",
        "hidden layers",
        "optimal weight matrix",
        "duality",
        "DNNs",
        "deep ReLU networks",
        "regularized deep neural networks",
        "previous layers"
      ]
    }
  },
  null,
  {
    "sim": 0.3849740909731342,
    "gen": {
      "title": "Noninvasive Cuffless Blood Pressure Estimation With Dendritic Neural Regression.",
      "url": "https://www.semanticscholar.org/paper/8f281ef06868d1417b3c337133617c7406e54beb",
      "abstract": "Blood pressure (BP) is one of the most important indicators of health. BP that is too high or too low causes varying degrees of diseases, such as renal impairment, cerebrovascular incidents, and cardiovascular diseases. Since traditional cuff-based BP measurement techniques have the drawbacks of patient discomfort and the impossibility of continuous BP monitoring, noninvasive cuffless continuous BP measurement has become a popular topic. The common noninvasive approach uses machine-learning (ML) algorithms to estimate BP by using the features extracted from simultaneous photoplethysmogram (PPG) and electrocardiogram (ECG) signals, such as the pulse transit time and pulse wave velocity. This study investigates the BP estimation performance of the novel dendritic neural regression (DNR) method proposed by us. Unlike conventional neural networks, DNR utilizes the multiplication operator as the excitation function in each dendritic branch, inspired by biological neuron phenomena, and can effectively capture nonlinear relationships between distinct input features. In addition, AMSGrad is used as the optimization algorithm to further enhance the dendritic neural model's performance. The experimental results show that by being fed a combination of the raw features extracted from the ECG and PPG signals and the components of the BP mathematical models, DNR can increase the accuracy of systolic BP, diastolic BP, and mean arterial pressure estimation significantly, which are superior to the state-of-the-art ML techniques. According to the British Hypertension Society protocol, DNR achieves a grade of A for the long-term BP estimation. Considering its architectural simplicity and powerful performance, the proposed method can be regarded as a reliable tool for estimating long-term continuous BP in a noninvasive cuffless way.",
      "fieldsOfStudy": [
        "Medicine"
      ],
      "topics": [
        "noninvasive cuffless continuous BP measurement",
        "continuous BP monitoring",
        "systolic BP",
        "diastolic BP",
        "BP",
        "cardiovascular diseases",
        "pulse wave velocity",
        "distinct input features",
        "diseases",
        "renal impairment",
        "cerebrovascular incidents",
        "arterial pressure estimation",
        "BP estimation performance",
        "traditional cuff-based BP measurement techniques",
        "BP mathematical models",
        "mean arterial pressure estimation",
        "patient discomfort"
      ]
    },
    "org": {
      "title": "Metrology for AI: From Benchmarks to Instruments",
      "url": "https://www.semanticscholar.org/paper/c0e63b1b9b4181a13f810a836ceec52707773616",
      "abstract": "In this paper we present the first steps towards hardening the science of measuring AI systems, by adopting metrology, the science of measurement and its application, and applying it to human (crowd) powered evaluations. We begin with the intuitive observation that evaluating the performance of an AI system is a form of measurement. In all other science and engineering disciplines, the devices used to measure are called instruments, and all measurements are recorded with respect to the characteristics of the instruments used. One does not report mass, speed, or length, for example, of a studied object without disclosing the precision (measurement variance) and resolution (smallest detectable change) of the instrument used. It is extremely common in the AI literature to compare the performance of two systems by using a crowd-sourced dataset as an instrument, but failing to report if the performance difference lies within the capability of that instrument to measure. To illustrate the adoption of metrology to benchmark datasets we use the word similarity benchmark WS353 and several previously published experiments that use it for evaluation.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "measurement variance",
        "measurement",
        "evaluation",
        "AI systems",
        "smallest detectable change",
        "datasets",
        "respect",
        "word similarity benchmark WS353",
        "AI",
        "instrument",
        "instruments",
        "WS353",
        "resolution",
        "human (crowd) powered evaluations"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.6428272675335629,
    "gen": {
      "title": "A novel approach for automatic acoustic novelty detection using a denoising autoencoder with bidirectional LSTM neural networks",
      "url": "https://www.semanticscholar.org/paper/e1d7afefd8f1d107bce9cc5f9a4faa5d4f207264",
      "abstract": "Acoustic novelty detection aims at identifying abnormal/novel acoustic signals which differ from the reference/normal data that the system was trained with. In this paper we present a novel unsupervised approach based on a denoising autoencoder. In our approach auditory spectral features are processed by a denoising autoencoder with bidirectional Long Short-Term Memory recurrent neural networks. We use the reconstruction error between the input and the output of the autoencoder as activation signal to detect novel events. The autoencoder is trained on a public database which contains recordings of typical in-home situations such as talking, watching television, playing and eating. The evaluation was performed on more than 260 different abnormal events. We compare results with state-of-the-art methods and we conclude that our novel approach significantly outperforms existing methods by achieving up to 93.4% F-Measure.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "novel events",
        "neural networks",
        "eating",
        "existing methods",
        "television",
        "home",
        "abnormal/novel acoustic signals",
        "recordings",
        "Acoustic novelty detection",
        "bidirectional Long Short-Term Memory",
        "novel unsupervised approach",
        "auditory spectral features",
        "novel approach",
        "acoustic",
        "bidirectional Long Short-Term Memory recurrent neural networks",
        "activation signal",
        "denoising autoencoder",
        "public database",
        "260 different abnormal events"
      ]
    },
    "org": {
      "title": "Effective Quantization Approaches for Recurrent Neural Networks",
      "url": "https://www.semanticscholar.org/paper/a79451e1d253a3e21c1bb2c024b309e829ef58ec",
      "abstract": "Deep learning, Recurrent Neural Networks (RNN) in particular have shown superior accuracy in a large variety oftasks including machine translation, language understanding, and movie frames generation. However, these deep learning approaches are very expensive in terms of computation. In most cases, Graphic Processing Units (GPUs) are in used for large scale implementations. Meanwhile, energy efficient RNN approaches are proposed for deploying solutions on special purpose hardware including Field Programming Gate Arrays (FPGAs) and mobile platforms. In this paper, we propose an effective quantization approach for Recurrent Neural Networks (RNN) techniques including Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), and Convolutional Long Short Term Memory (ConvLSTM). We have implemented different quantization methods including Binary Connect $\\{-1, 1\\}$, Ternary Connect $\\{-1, 0$, 1}, and Quaternary Connect $\\{-1, -0.5, 0.5, 1\\}$. These proposed approaches are evaluated on different datasets for sentiment analysis on IMDB and video frame predictions on the moving MNIST dataset. The experimental results are compared against the full precision versions of the LSTM, GRU, and ConvLSTM. They show promising results for both sentiment analysis and video frame prediction.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "video frame predictions",
        "different datasets",
        "movie frames generation",
        "Convolutional Long Short Term Memory",
        "sentiment analysis",
        "Gated Recurrent Units",
        "mobile platforms",
        "large scale implementations",
        "Recurrent Neural Networks",
        "moving MNIST dataset",
        "Ternary Connect",
        "Field Programming Gate Arrays",
        "Binary Connect",
        "IMDB",
        "MNIST",
        "Ternary Connect $"
      ]
    }
  },
  {
    "sim": 0.6354753810859575,
    "gen": {
      "title": "Self-Supervised Learning of Geometrically Stable Features Through Probabilistic Introspection",
      "url": "https://www.semanticscholar.org/paper/7d94103c5e3796721388200ddaf94ed6e984ab0f",
      "abstract": "Self-supervision can dramatically cut back the amount of manually-labelled data required to train deep neural networks. While self-supervision has usually been considered for tasks such as image classification, in this paper we aim at extending it to geometry-oriented tasks such as semantic matching and part detection. We do so by building on several recent ideas in unsupervised landmark detection. Our approach learns dense distinctive visual descriptors from an unlabeled dataset of images using synthetic image transformations. It does so by means of a robust probabilistic formulation that can introspectively determine which image regions are likely to result in stable image matching. We show empirically that a network pre-trained in this manner requires significantly less supervision to learn semantic object parts compared to numerous pre-training alternatives. We also show that the pre-trained representation is excellent for semantic object matching.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "stable image matching",
        "semantic object matching",
        "semantic object parts",
        "synthetic image transformations",
        "image classification",
        "numerous pre-training alternatives",
        "images",
        "unsupervised landmark detection",
        "semantic matching and part detection",
        "deep neural networks",
        "pre-trained representation",
        "dense distinctive visual descriptors",
        "tasks",
        "image regions",
        "recent ideas",
        "detection",
        "semantic matching"
      ]
    },
    "org": {
      "title": "Provable Alternating Gradient Descent for Non-negative Matrix Factorization with Strong Correlations",
      "url": "https://www.semanticscholar.org/paper/e65ee98d6e373e0677112befc8ef16076b9fd90a",
      "abstract": "Non-negative matrix factorization is a basic tool for decomposing data into the feature and weight matrices under non-negativity constraints, and in practice is often solved in the alternating minimization framework. However, it is unclear whether such algorithms can recover the ground-truth feature matrix when the weights for different features are highly correlated, which is common in applications. This paper proposes a simple and natural alternating gradient descent based algorithm, and shows that with a mild initialization it provably recovers the ground-truth in the presence of strong correlations. In most interesting cases, the correlation can be in the same order as the highest possible. Our analysis also reveals its several favorable features including robustness to noise. We complement our theoretical results with empirical studies on semi-synthetic datasets, demonstrating its advantage over several popular methods in recovering the ground-truth.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "weight matrices",
        "different features",
        "Non-negative matrix factorization",
        "strong correlations",
        "non-negativity constraints",
        "semi-synthetic datasets",
        "popular methods",
        "applications",
        "ground-truth feature matrix",
        "algorithms",
        "favorable features",
        "algorithm",
        "data",
        "empirical studies",
        "alternating minimization framework",
        "noise",
        "practice",
        "feature and weight matrices"
      ]
    }
  },
  {
    "sim": 0.4705881456944827,
    "gen": {
      "title": "A Generalized Probabilistic Framework for Compact Codebook Creation",
      "url": "https://www.semanticscholar.org/paper/1eb3feb77ea540f2551920843258b8de70c9b9dd",
      "abstract": "Compact and discriminative visual codebooks are preferred in many visual recognition tasks. In the literature, a number of works have taken the approach of hierarchically merging visual words of an initial large-sized codebook, but implemented this approach with different merging criteria. In this work, we propose a single probabilistic framework to unify these merging criteria, by identifying two key factors: the function used to model the class-conditional distribution and the method used to estimate the distribution parameters. More importantly, by adopting new distribution functions and/or parameter estimation methods, our framework can readily produce a spectrum of novel merging criteria. Three of them are specifically discussed in this paper. For the first criterion, we adopt the multinomial distribution with the Bayesian method; For the second criterion, we integrate the Gaussian distribution with maximum likelihood parameter estimation. For the third criterion, which shows the best merging performance, we propose a max-margin-based parameter estimation method and apply it with the multinomial distribution. Extensive experimental study is conducted to systematically analyze the performance of the above three criteria and compare them with existing ones. As demonstrated, the best criterion within our framework achieves the overall best merging performance among the compared merging criteria developed in the literature.",
      "fieldsOfStudy": [
        "Computer Science",
        "Medicine",
        "Mathematics"
      ],
      "topics": [
        "different merging criteria",
        "estimation methods",
        "maximum likelihood parameter estimation",
        "new distribution functions",
        "compared merging criteria",
        "visual recognition tasks",
        "merging criteria",
        "distribution parameters",
        "existing ones",
        "best merging performance",
        "multinomial distribution",
        "best criterion",
        "Gaussian distribution",
        "parameter estimation methods",
        "visual words",
        "overall best merging performance",
        "second criterion"
      ]
    },
    "org": {
      "title": "Recoverable Robust Single Machine Scheduling with Polyhedral Uncertainty",
      "url": "https://www.semanticscholar.org/paper/3e3bec09ffc1134431ac699a40be41be03adeb14",
      "abstract": "This paper considers a recoverable robust single-machine scheduling problem under polyhedral uncertainty with the objective of minimising the total flow time. In this setting, a decision-maker must determine a first-stage schedule subject to the uncertain job processing times. Then following the realisation of these processing times, they have the option to swap the positions of up to \u2206 disjoint pairs of jobs to obtain a second-stage schedule. We first formulate this scheduling problem using a general recoverable robust framework, before we examine the incremental subproblem in further detail. We prove a general result for max-weight matching problems, showing that for edge weights of a specific form, the matching polytope can be fully characterised by polynomially many constraints. We use this result to derive a matching-based compact formulation for the full problem. Further analysis of the incremental problem leads to an additional assignment-based compact formulation. Computational results on budgeted uncertainty sets compare the relative strengths of the three compact models we propose.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "jobs",
        "disjoint pairs",
        "uncertain job processing times",
        "second",
        "edge weights",
        "max-weight matching problems",
        "processing times",
        "total flow time",
        "polyhedral uncertainty",
        "detail",
        "budgeted uncertainty sets",
        "first-stage schedule subject",
        "problem",
        "second-stage schedule",
        "incremental problem",
        "scheduling problem"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.4243724709950534,
    "gen": {
      "title": "Channel Assignment With Access Contention Resolution for Cognitive Radio Networks",
      "url": "https://www.semanticscholar.org/paper/74976ed64158fc2edacb3a35d21c7745f339d1b3",
      "abstract": "In this paper, we consider the channel assignment problem for cognitive radio networks with hardware-constrained secondary users (SUs). In particular, we assume that SUs exploit spectrum holes on a set of channels where each SU can use at most one available channel for communication. We present the optimal brute-force search algorithm to solve the corresponding nonlinear integer optimization problem and analyze its complexity. Because the optimal solution has exponential complexity with the numbers of channels and SUs, we develop two low-complexity channel assignment algorithms that can efficiently utilize the spectrum holes. In the first algorithm, SUs are assigned distinct sets of channels. We show that this algorithm achieves the maximum throughput limit if the number of channels is sufficiently large. In addition, we propose an overlapping channel assignment algorithm that can improve the throughput performance compared with its nonoverlapping channel assignment counterpart. Moreover, we design a distributed medium access control (MAC) protocol for access contention resolution and integrate it into the overlapping channel assignment algorithm. We then analyze the saturation throughput and the complexity of the proposed channel assignment algorithms. We also present several potential extensions, including the development of greedy channel assignment algorithms under the max-min fairness criterion and throughput analysis, considering sensing errors. Finally, numerical results are presented to validate the developed theoretical results and illustrate the performance gains due to the proposed channel assignment algorithms.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "channels",
        "overlapping channel assignment algorithm",
        "nonoverlapping channel assignment counterpart",
        "channel assignment problem",
        "low-complexity channel assignment algorithms",
        "SUs",
        "distinct sets",
        "exponential complexity",
        "cognitive radio networks",
        "holes",
        "access contention resolution",
        "errors",
        "spectrum holes",
        "throughput analysis",
        "sensing errors"
      ]
    },
    "org": {
      "title": "Adaptive Neighborhood Graph Construction for Inference in Multi-Relational Networks",
      "url": "https://www.semanticscholar.org/paper/3eb8db5b0487d870afd1191c4254c18ddf2f9501",
      "abstract": "A neighborhood graph, which represents the instances as vertices and their relations as weighted edges, is the basis of many semi-supervised and relational models for node labeling and link prediction. Most methods employ a sequential process to construct the neighborhood graph. This process often consists of generating a candidate graph, pruning the candidate graph to make a neighborhood graph, and then performing inference on the variables (i.e., nodes) in the neighborhood graph. In this paper, we propose a framework that can dynamically adapt the neighborhood graph based on the states of variables from intermediate inference results, as well as structural properties of the relations connecting them. A key strength of our framework is its ability to handle multi-relational data and employ varying amounts of relations for each instance based on the intermediate inference results. We formulate the link prediction task as inference on neighborhood graphs, and include preliminary results illustrating the effects of different strategies in our proposed framework.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "inference",
        "multi-relational data",
        "preliminary results",
        "relations",
        "neighborhood graph",
        "different strategies",
        "structural properties",
        "intermediate inference results",
        "semi-supervised and relational models",
        "weighted edges",
        "variables",
        "node labeling",
        "link prediction"
      ]
    }
  },
  {
    "sim": 0.5284419484572156,
    "gen": {
      "title": "On the capacity of vector Gaussian channels with bounded inputs",
      "url": "https://www.semanticscholar.org/paper/429586c360e27bffc03e4ff4bed50b846945f7a1",
      "abstract": "The capacity of a multiple-input multiple-output (MIMO) identity channel under the peak and average power constraints is investigated. The approach of Shamai et al. is generalized to the higher dimension settings to derive the necessary and sufficient conditions for the optimal input probability density function. This approach prevents the usage of the identity theorem of the holomorphic functions of several complex variables which seems to fail in the multi-dimensional scenarios. It is proved that in the spherical coordinates, the magnitude and phases of the capacity-achieving distribution are mutually independent and its support is a finite set of hyper-spheres where the points are uniformly distributed on them. Subsequently, it is shown that when the average power constraint is relaxed, if the number of antennas is large enough (e.g. massive MIMO), the capacity has a closed form solution and constant amplitude signaling at the peak power achieves it. Finally, it will be observed that in a discrete-time memoryless Gaussian channel, the average power constrained capacity, which results from a Gaussian input distribution, can be closely obtained by an input where the support of its magnitude is a discrete finite set.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "hyper-spheres",
        "complex variables",
        "optimal input probability density function",
        "multi-dimensional scenarios",
        "constant amplitude",
        "MIMO",
        "Gaussian input distribution",
        "antennas",
        "peak power",
        "peak and average power constraints",
        "discrete finite set",
        "average power",
        "Gaussian",
        "finite set",
        "constant amplitude signaling",
        "spheres",
        "hyper"
      ]
    },
    "org": {
      "title": "Stability of the Lanczos Method for Matrix Function Approximation",
      "url": "https://www.semanticscholar.org/paper/80e249898a6472c9aa616d21c1b44a737425c1e8",
      "abstract": "The ubiquitous Lanczos method can approximate $f(A)x$ for any symmetric $n \\times n$ matrix $A$, vector $x$, and function $f$. In exact arithmetic, the method's error after $k$ iterations is bounded by the error of the best degree-$k$ polynomial uniformly approximating $f(x)$ on the range $[\\lambda_{min}(A), \\lambda_{max}(A)]$. However, despite decades of work, it has been unclear if this powerful guarantee holds in finite precision. \nWe resolve this problem, proving that when $\\max_{x \\in [\\lambda_{min}, \\lambda_{max}]}|f(x)| \\le C$, Lanczos essentially matches the exact arithmetic guarantee if computations use roughly $\\log(nC\\|A\\|)$ bits of precision. Our proof extends work of Druskin and Knizhnerman [DK91], leveraging the stability of the classic Chebyshev recurrence to bound the stability of any polynomial approximating $f(x)$. \nWe also study the special case of $f(A) = A^{-1}$, where stronger guarantees hold. In exact arithmetic Lanczos performs as well as the best polynomial approximating $1/x$ at each of $A$'s eigenvalues, rather than on the full eigenvalue range. In seminal work, Greenbaum gives an approach to extending this bound to finite precision: she proves that finite precision Lanczos and the related CG method match any polynomial approximating $1/x$ in a tiny range around each eigenvalue [Gre89]. \nFor $A^{-1}$, this bound appears stronger than ours. However, we exhibit matrices with condition number $\\kappa$ where exact arithmetic Lanczos converges in $polylog(\\kappa)$ iterations, but Greenbaum's bound predicts $\\Omega(\\kappa^{1/5})$ iterations. It thus cannot offer significant improvement over the $O(\\kappa^{1/2})$ bound achievable via our result. Our analysis raises the question of if convergence in less than $poly(\\kappa)$ iterations can be expected in finite precision, even for matrices with clustered, skewed, or otherwise favorable eigenvalue distributions.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "finite precision",
        "precision",
        "exact arithmetic",
        "Lanczos",
        "n$ matrix",
        "x$",
        "stronger guarantees",
        "work",
        "seminal work",
        "matrices",
        "\\lambda_{max}]}|f(x)| \\le C$",
        "f(A",
        "eigenvalue range",
        "tiny range",
        "$A$s eigenvalues",
        "range",
        "clustered, skewed, or otherwise favorable eigenvalue distributions"
      ]
    }
  },
  {
    "sim": 0.6289099564711021,
    "gen": {
      "title": "Generative Imputation and Stochastic Prediction",
      "url": "https://www.semanticscholar.org/paper/19dc932a72bc8384c0bf331eaaec8e1798e7676c",
      "abstract": "In many machine learning applications, we are faced with incomplete datasets. In the literature, missing data imputation techniques have been mostly concerned with filling missing values. However, the existence of missing values is synonymous with uncertainties not only over the distribution of missing values but also over target class assignments that require careful consideration. In this paper, we propose a simple and effective method for imputing missing features and estimating the distribution of target assignments given incomplete data. In order to make imputations, we train a simple and effective generator network to generate imputations that a discriminator network is tasked to distinguish. Following this, a predictor network is trained using the imputed samples from the generator network to capture the classification uncertainties and make predictions accordingly. The proposed method is evaluated on CIFAR-10 and MNIST image datasets as well as five real-world tabular classification datasets, under different missingness rates and structures. Our experimental results show the effectiveness of the proposed method in generating imputations as well as providing estimates for the class uncertainties in a classification task when faced with missing values.",
      "fieldsOfStudy": [
        "Computer Science",
        "Medicine",
        "Mathematics"
      ],
      "topics": [
        "missing values",
        "target assignments",
        "MNIST image datasets",
        "incomplete data",
        "different missingness rates",
        "careful consideration",
        "missing features",
        "structures",
        "generating imputations",
        "uncertainties",
        "data imputation techniques",
        "imputations",
        "real-world tabular classification datasets",
        "missing data imputation techniques",
        "CIFAR-10 and MNIST image datasets",
        "classification uncertainties"
      ]
    },
    "org": {
      "title": "Recovering loss to followup information using denoising autoencoders",
      "url": "https://www.semanticscholar.org/paper/55a1815df60a50cef6abd1beccb9c7e639308e63",
      "abstract": "Loss to followup is a significant issue in healthcare and has serious consequences for a study's validity and cost. Methods available at present for recovering loss to followup information are restricted by their expressive capabilities and struggle to model highly non-linear relations and complex interactions. In this paper we propose a model based on overcomplete denoising autoencoders to recover loss to followup information. Designed to work with high volume data, results on various simulated and real life datasets show our model is appropriate under varying dataset and loss to followup conditions and outperforms the state-of-the-art methods by a wide margin (\u2265 20% in some scenarios) while preserving the dataset utility for final analysis.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "complex interactions",
        "final analysis",
        "followup information",
        "followup conditions",
        "varying dataset",
        "loss",
        "cost",
        "overcomplete denoising autoencoders",
        "consequences",
        "highly non-linear relations",
        "simulated and real life datasets",
        "high volume data",
        "Methods",
        "followup",
        "information",
        "dataset utility",
        "healthcare"
      ]
    }
  },
  {
    "sim": 0.5911850630811074,
    "gen": {
      "title": "Fast and Practical Algorithms for Planted (l, d) Motif Search",
      "url": "https://www.semanticscholar.org/paper/f5e4fae8f6e58112a799cc71c8625f8564729693",
      "abstract": "We consider the planted (I, d) motif search problem, which consists of finding a substring of length I that occurs in a set of input sequences {si,. ..,sn} with up to d errors, a problem that arises from the need to find transcription factor-binding sites in genomic information. We propose a sequence of practical algorithms, which start based on the ideas considered in PMS1. These algorithms are exact, have little space requirements, and are able to tackle challenging instances with bigger d, taking less time in the instances reported solved by exact algorithms. In particular, one of the proposed algorithms, PMSprune, is able to solve the challenging instances, such as (17, 6) and (19, 7), which were not previously reported as solved in the literature.",
      "fieldsOfStudy": [
        "Computer Science",
        "Medicine"
      ],
      "topics": [
        "genomic information",
        "exact algorithms",
        "little space requirements",
        "practical algorithms",
        "input sequences",
        "bigger d",
        "time",
        "si",
        "PMS1",
        "transcription factor-binding sites",
        "challenging instances",
        "length",
        "transcription",
        "length I",
        "instances",
        "planted (I, d) motif search problem",
        "PMSprune"
      ]
    },
    "org": {
      "title": "On Low-High Orders of Directed Graphs: Incremental Algorithms and Applications",
      "url": "https://www.semanticscholar.org/paper/f31f0ca9dbba33dc0a0096cf20e2de6022fff6d9",
      "abstract": "A flow graph $G=(V,E,s)$ is a directed graph with a distinguished start vertex $s$. The dominator tree $D$ of $G$ is a tree rooted at $s$, such that a vertex $v$ is an ancestor of a vertex $w$ if and only if all paths from $s$ to $w$ include $v$. The dominator tree is a central tool in program optimization and code generation and has many applications in other diverse areas including constraint programming, circuit testing, biology, and in algorithms for graph connectivity problems. A low-high order of $G$ is a preorder $\\delta$ of $D$ that certifies the correctness of $D$ and has further applications in connectivity and path-determination problems. In this paper, we first consider how to maintain efficiently a low-high order of a flow graph incrementally under edge insertions. We present algorithms that run in $O(mn)$ total time for a sequence of $m$ edge insertions in an initially empty flow graph with $n$ vertices.These immediately provide the first incremental certifying algorithms for maintaining the dominator tree in $O(mn)$ total time, and also imply incremental algorithms for other problems. Hence, we provide a substantial improvement over the $O(m^2)$ simple-minded algorithms, which recompute the solution from scratch after each edge insertion. We also show how to apply low-high orders to obtain a linear-time $2$-approximation algorithm for the smallest $2$-vertex-connected spanning subgraph problem (2VCSS). Finally, we present efficient implementations of our new algorithms for the incremental low-high and 2VCSS problems and conduct an extensive experimental study on real-world graphs taken from a variety of application areas. The experimental results show that our algorithms perform very well in practice.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "graph connectivity problems",
        "problems",
        "subgraph problem",
        "application areas",
        "incremental algorithms",
        "algorithms",
        "edge insertions",
        "diverse areas",
        "applications",
        "applications",
        "constraint programming",
        "circuit testing",
        "real-world graphs",
        "total time",
        "2VCSS",
        "biology",
        "A flow graph"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.3714269942503815,
    "gen": {
      "title": "Spectral Theory of Unsigned and Signed Graphs. Applications to Graph Clustering: a Survey",
      "url": "https://www.semanticscholar.org/paper/3dd5d6a5983baa6e63f5bca951074ae8b21a5cc0",
      "abstract": "This is a survey of the method of graph cuts and its applications to graph clustering of weighted unsigned and signed graphs. I provide a fairly thorough treatment of the method of normalized graph cuts, a deeply original method due to Shi and Malik, including complete proofs. The main thrust of this paper is the method of normalized cuts. I give a detailed account for K = 2 clusters, and also for K > 2 clusters, based on the work of Yu and Shi. I also show how both graph drawing and normalized cut K-clustering can be easily generalized to handle signed graphs, which are weighted graphs in which the weight matrix W may have negative coefficients. Intuitively, negative coefficients indicate distance or dissimilarity. The solution is to replace the degree matrix by the matrix in which absolute values of the weights are used, and to replace the Laplacian by the Laplacian with the new degree matrix of absolute values. As far as I know, the generalization of K-way normalized clustering to signed graphs is new. Finally, I show how the method of ratio cuts, in which a cut is normalized by the size of the cluster rather than its volume, is just a special case of normalized cuts.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "graph cuts",
        "signed graphs",
        "normalized cuts",
        "complete proofs",
        "ratio cuts",
        "absolute values",
        "graphs",
        "negative coefficients",
        "dissimilarity",
        "Laplacian",
        "Shi",
        "weighted unsigned and signed graphs",
        "new degree matrix",
        "weight matrix W",
        "graph clustering",
        "weighted graphs",
        "normalized cut K-clustering"
      ]
    },
    "org": {
      "title": "Average Case Recovery Analysis of Tomographic Compressive Sensing",
      "url": "https://www.semanticscholar.org/paper/1ff2eacde3598f627fdbafaed3f752aef4d5111f",
      "abstract": null,
      "fieldsOfStudy": [
        "Mathematics",
        "Physics",
        "Computer Science"
      ]
    }
  },
  {
    "sim": 0.5074702904725262,
    "gen": {
      "title": "A Unified Off-Policy Evaluation Approach for General Value Function",
      "url": "https://www.semanticscholar.org/paper/7b200d0435ca9594f16d37e1cbea665928d9a9a8",
      "abstract": "General Value Function (GVF) is a powerful tool to represent both the predictive and retrospective knowledge in reinforcement learning (RL). In practice, often multiple interrelated GVFs need to be evaluated jointly with pre-collected offpolicy samples. In the literature, the gradient temporal difference (GTD) learning method has been adopted to evaluate GVFs in the off-policy setting, but such an approach may suffer from a large estimation error even if the function approximation class is sufficiently expressive. Moreover, none of the previous work have formally established the convergence guarantee to the ground truth GVFs under the function approximation settings. In this paper, we address both issues through the lens of a class of GVFs with causal filtering, which cover a wide range of RL applications such as reward variance, value gradient, cost in anomaly detection, stationary distribution gradient, etc. We propose a new algorithm called GenTD for off-policy GVFs evaluation and show that GenTD learns multiple interrelated multi-dimensional GVFs as efficiently as a single canonical scalar value function. We further show that unlike GTD, the learned GVFs by GenTD are guaranteed to converge to the ground truth GVFs as long as the function approximation power is sufficiently large. To our best knowledge, GenTD is the first off-policy GVF evaluation algorithm that has global optimality guarantee.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "stationary distribution gradient",
        "value gradient",
        "anomaly detection",
        "GVFs",
        "anomaly",
        "multiple interrelated multi-dimensional GVFs",
        "cost",
        "RL applications",
        "reward variance",
        "pre-collected offpolicy samples",
        "function approximation power",
        "single canonical scalar value function",
        "global optimality guarantee",
        "multiple interrelated GVFs",
        "off-policy GVFs evaluation",
        "large estimation error"
      ]
    },
    "org": {
      "title": "Bayesian Optimization for Probabilistic Programs",
      "url": "https://www.semanticscholar.org/paper/ae49bab4af8d994306204ca3586809b07681d74a",
      "abstract": "We present the first general purpose framework for marginal maximum a posteriori estimation of probabilistic program variables. By using a series of code transformations, the evidence of any probabilistic program, and therefore of any graphical model, can be optimized with respect to an arbitrary subset of its sampled variables. To carry out this optimization, we develop the first Bayesian optimization package to directly exploit the source code of its target, leading to innovations in problem-independent hyperpriors, unbounded optimization, and implicit constraint satisfaction; delivering significant performance improvements over prominent existing packages. We present applications of our method to a number of tasks including engineering design and parameter optimization.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "probabilistic program variables",
        "prominent existing packages",
        "unbounded optimization",
        "parameter optimization",
        "significant performance improvements",
        "implicit constraint satisfaction",
        "code transformations",
        "Bayesian optimization package",
        "innovations",
        "engineering design",
        "respect",
        "marginal maximum",
        "problem-independent hyperpriors",
        "sampled variables",
        "source code"
      ]
    }
  },
  {
    "sim": 0.5840959128839978,
    "gen": {
      "title": "Understanding and Improving Fast Adversarial Training",
      "url": "https://www.semanticscholar.org/paper/24cf86a418c9471e8001961c87697c825f0bba8f",
      "abstract": "A recent line of work focused on making adversarial training computationally efficient for deep learning models. In particular, Wong et al. (2020) showed that $\\ell_\\infty$-adversarial training with fast gradient sign method (FGSM) can fail due to a phenomenon called \"catastrophic overfitting\", when the model quickly loses its robustness over a single epoch of training. We show that adding a random step to FGSM, as proposed in Wong et al. (2020), does not prevent catastrophic overfitting, and that randomness is not important per se -- its main role being simply to reduce the magnitude of the perturbation. Moreover, we show that catastrophic overfitting is not inherent to deep and overparametrized networks, but can occur in a single-layer convolutional network with a few filters. In an extreme case, even a single filter can make the network highly non-linear locally, which is the main reason why FGSM training fails. Based on this observation, we propose a new regularization method, GradAlign, that prevents catastrophic overfitting by explicitly maximizing the gradient alignment inside the perturbation set and improves the quality of the FGSM solution. As a result, GradAlign allows to successfully apply FGSM training also for larger $\\ell_\\infty$-perturbations and reduce the gap to multi-step adversarial training. The code of our experiments is available at this https URL.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "FGSM training",
        "step adversarial training",
        "training",
        "deep learning models",
        "FGSM",
        "catastrophic overfitting",
        "fast gradient sign method",
        "Wong et al",
        "al",
        "deep and overparametrized networks",
        "$\\ell_\\infty$-adversarial training",
        "FGSM solution",
        "single-layer convolutional network",
        "single epoch",
        "multi-step adversarial training",
        "adversarial training",
        "\"catastrophic overfitting"
      ]
    },
    "org": {
      "title": "Computation on Sparse Neural Networks: an Inspiration for Future Hardware",
      "url": "https://www.semanticscholar.org/paper/0887156ff863fbea508d4c442898cf91c781b8d6",
      "abstract": "Neural network models are widely used in solving many challenging problems, such as computer vision, personalized recommendation, and natural language processing. Those models are very computationally intensive and reach the hardware limit of the existing server and IoT devices. Thus, finding better model architectures with much less amount of computation while maximally preserving the accuracy is a popular research topic. Among various mechanisms that aim to reduce the computation complexity, identifying the zero values in the model weights and in the activations to avoid computing them is a promising direction. \nIn this paper, we summarize the current status of the research on the computation of sparse neural networks, from the perspective of the sparse algorithms, the software frameworks, and the hardware accelerations. We observe that the search for the sparse structure can be a general methodology for high-quality model explorations, in addition to a strategy for high-efficiency model execution. We discuss the model accuracy influenced by the number of weight parameters and the structure of the model. The corresponding models are called to be located in the weight dominated and structure dominated regions, respectively. We show that for practically complicated problems, it is more beneficial to search large and sparse models in the weight dominated region. In order to achieve the goal, new approaches are required to search for proper sparse structures, and new sparse training hardware needs to be developed to facilitate fast iterations of sparse models.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "sparse models",
        "Neural network models",
        "proper sparse structures",
        "better model architectures",
        "natural language processing",
        "weight parameters",
        "high-efficiency model execution",
        "large and sparse models",
        "high-quality model explorations",
        "challenging problems",
        "fast iterations",
        "model weights",
        "regions",
        "sparse neural networks",
        "personalized recommendation",
        "new sparse training hardware"
      ]
    }
  },
  null,
  {
    "sim": 0.7716812202223974,
    "gen": {
      "title": "On the Capacity of the Two-User Symmetric Interference Channel With Transmitter Cooperation and Secrecy Constraints",
      "url": "https://www.semanticscholar.org/paper/e024f8d8adea19af6f0e125b4cb5557bdf4a863f",
      "abstract": "This paper studies the value of limited rate cooperation between the transmitters for managing interference and simultaneously ensuring secrecy, in the two-user Gaussian symmetric interference channel (IC). First, the problem is studied in the symmetric linear deterministic IC (SLDIC) setting, and achievable schemes are proposed, based on interference cancelation, relaying of the other user's data bits, and transmission of random bits. In the proposed achievable scheme, the limited rate cooperative link is used to share a combination of data bits and random bits depending on the model parameters. Outer bounds on the secrecy rate are also derived, using a novel partitioning of the encoded messages and outputs depending on the relative strength of the signal and the interference. The partitioning helps to bound certain negative entropy terms, leading to a tractable outer bound. The inner and outer bounds are derived under all possible parameter settings. It is found that, for some parameter settings, the inner and outer bounds match, yielding the capacity of the SLDIC under transmitter cooperation and secrecy constraints. In some other scenarios, the achievable rate matches with the capacity region of the two-user SLDIC without secrecy constraints derived by Wang and Tse; thus, the proposed scheme offers secrecy for free, in these cases. Inspired by the achievable schemes and outer bounds in the deterministic case, achievable schemes and outer bounds are derived in the Gaussian case. The proposed achievable scheme for the Gaussian case is based on Marton's coding scheme and stochastic encoding along with dummy message transmission. One of the key techniques used in the achievable scheme for both the models is interference cancelation, which simultaneously offers two seemingly conflicting benefits: it cancels interference and ensures secrecy. Many of the results derived in this paper extend to the asymmetric case also. The results show that limited transmitter cooperation can greatly facilitate secure communications over two-user ICs.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "achievable schemes",
        "random bits",
        "interference cancelation",
        "secrecy constraints",
        "data bits",
        "interference",
        "secrecy",
        "outer bounds",
        "dummy message transmission",
        "proposed achievable scheme",
        "transmission",
        "limited transmitter cooperation"
      ]
    },
    "org": {
      "title": "Interference Networks With Point-to-Point Codes",
      "url": "https://www.semanticscholar.org/paper/311c46c644c1d004b79df9802176cdeb14c43fab",
      "abstract": "The paper establishes the capacity region of the Gaussian interference channel with many transmitter-receiver pairs constrained to use point-to-point codes. The capacity region is shown to be strictly larger in general than the achievable rate regions when treating interference as noise, using successive interference cancellation decoding, and using joint decoding. The gains in coverage and achievable rate using the optimal decoder are analyzed in terms of ensemble averages using stochastic geometry. In a spatial network where the nodes are distributed according to a Poisson point process and the channel path loss exponent is \u03b2 >; 2, it is shown that the density of users that can be supported by treating interference as noise can scale no faster than B2/\u03b2 as the bandwidth B grows, while the density of users can scale linearly with B under optimal decoding.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "optimal decoding",
        "interference channel",
        "joint decoding",
        "stochastic geometry",
        "point",
        "interference",
        "ensemble averages",
        "users",
        "noise",
        "terms",
        "channel path loss exponent",
        "Poisson point process",
        "transmitter-receiver pairs",
        "B2",
        "successive interference cancellation decoding",
        "achievable rate",
        "Gaussian interference channel"
      ]
    }
  },
  {
    "sim": 0.6690739187129935,
    "gen": {
      "title": "New inner and outer bounds for the discrete memoryless cognitive interference channel and some capacity results",
      "url": "https://www.semanticscholar.org/paper/1c22f82f3ce06d44810747759bd3dd54ab60d030",
      "abstract": "The cognitive interference channel is an interference channel in which one transmitter is non-causally provided with the message of the other transmitter. This channel model has been extensively studied in the past years and capacity results for certain classes of channels have been proved. In this paper we present new inner and outer bounds for the capacity region of the cognitive interference channel as well as new capacity results. Previously proposed outer bounds are expressed in terms of auxiliary random variables for which no cardinality constraint is known. Consequently it is not possible to evaluate such outer bounds explicitly for a given channel model. The outer bound we derive is based on an idea originally devised by Sato for the broadcast channel and does not contain auxiliary random variables, allowing it to be more easily evaluated. The inner bound we derive is the largest known to date and is explicitly shown to include all previously proposed achievable rate regions. This comparison highlights which features of the transmission scheme - which includes rate-splitting, superposition coding, a broadcast channel-like binning scheme, and Gel'fand Pinsker coding - are most effective in approaching capacity. We next present new capacity results for a class of discrete memoryless channels that we term the \"better cognitive decoding regime\" which includes all previously known regimes in which capacity results have been derived as special cases. Finally, we determine the capacity region of the semi-deterministic cognitive interference channel, in which the signal at the cognitive receiver is a deterministic function of the channel inputs.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "channels",
        "discrete memoryless channels",
        "new capacity results",
        "approaching capacity",
        "semi-deterministic cognitive interference channel",
        "cognitive interference channel",
        "auxiliary random variables",
        "Gelfand Pinsker coding",
        "outer bounds",
        "certain classes",
        "interference channel",
        "given channel model",
        "broadcast channel",
        "capacity",
        "superposition coding",
        "transmitter"
      ]
    },
    "org": {
      "title": "Capacity-achieving iterative LMMSE detection for MIMO-NOMA systems",
      "url": "https://www.semanticscholar.org/paper/362e32ba45e49aa3a121428e65ca8339d2bbc738",
      "abstract": "This paper considers a iterative Linear Minimum Mean Square Error (LMMSE) detection for the uplink Multiuser Multiple-Input and Multiple-Output (MU-MIMO) systems with Non-Orthogonal Multiple Access (NOMA). The iterative LMMSE detection greatly reduces the system computational complexity by departing the overall processing into many low-complexity distributed calculations. However, it is generally considered to be sub-optimal and achieves relatively poor performance. In this paper, we firstly present the matching conditions and area theorems for the iterative detection of the MIMO-NOMA systems. Based on the proposed matching conditions and area theorems, the achievable rate region of the iterative LMMSE detection is analysed. We prove that by properly design the iterative LMMSE detection, it can achieve (i) the optimal sum capacity of MU-MIMO systems, (ii) all the maximal extreme points in the capacity region of MU-MIMO system, and (iii) the whole capacity region of two-user MIMO systems.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "Non-Orthogonal Multiple Access",
        "MU",
        "MU-MIMO systems",
        "system computational complexity",
        "low-complexity distributed calculations",
        "NOMA",
        "LMMSE",
        "area theorems",
        "capacity region",
        "iterative LMMSE detection",
        "two-user MIMO systems",
        "MU-MIMO",
        "MIMO-NOMA systems",
        "achievable rate region",
        "uplink Multiuser Multiple-Input and Multiple-Output (MU-MIMO) systems"
      ]
    }
  },
  {
    "sim": 0.5477424563855244,
    "gen": {
      "title": "GeoPrune: Efficiently Finding Shareable Vehicles Based on Geometric Properties",
      "url": "https://www.semanticscholar.org/paper/2151a3143a7e06ad5c95d1b7ff6bcf135ca3065e",
      "abstract": "On-demand ride-sharing is rapidly growing.Matching trip requests to vehicles efficiently is critical for the service quality of ride-sharing. To match trip requests with vehicles, a prune-and-select scheme is commonly used. The pruning stage identifies feasible vehicles that can satisfy the trip constraints (e.g., trip time). The selection stage selects the optimal one(s) from the feasible vehicles. The pruning stage is crucial to reduce the complexity of the selection stage and to achieve efficient matching. We propose an effective and efficient pruning algorithm called GeoPrune. GeoPrune represents the time constraints of trip requests using circles and ellipses, which can be computed and updated efficiently. Experiments on real-world datasets show that GeoPrune reduces the number of vehicle candidates in nearly all cases by an order of magnitude and the update cost by two to three orders of magnitude compared to the state-of-the-art.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "topics": [
        "trip requests",
        "trip time",
        "vehicle candidates",
        "vehicles",
        "GeoPrune",
        "magnitude",
        "efficient matching",
        "ellipses",
        "circles",
        "feasible vehicles",
        "time constraints",
        "ride-sharing",
        "update cost",
        "service quality"
      ]
    },
    "org": {
      "title": "New Error Measures and Methods for Realizing Protein Graphs from Distance Data",
      "url": "https://www.semanticscholar.org/paper/f27f8bcb1473e2544f328851c820b17c8f076856",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Biology"
      ]
    }
  },
  {
    "sim": 0.1567765441886223,
    "gen": {
      "title": "Institutional Knowledge at Singapore Management University Institutional Knowledge at Singapore Management University Efficient representative subset selection over sliding windows Efficient representative subset selection over sliding windows",
      "url": "https://www.semanticscholar.org/paper/e1a47c918f141dc49238c6581de9ea16a25dfa07",
      "abstract": "\u2014Representative subset selection (RSS) is an important tool for users to draw insights from massive datasets. Existing literature models RSS as the submodular maximization problem to capture the \u201cdiminishing returns\u201d property of the representativeness of selected subsets, but often only has a single constraint (e.g., cardinality), which limits its applications in many real-world problems. To capture the data recency issue and support different types of constraints, we formulate dynamic RSS in data streams as maximizing submodular functions subject to general d -knapsack constraints (SMDK) over sliding windows. We propose a K NAP W INDOW framework (KW) for SMDK. KW utilizes the K NAP S TREAM algorithm (KS) for SMDK in append-only streams as a subroutine. It maintains a sequence of checkpoints and KS instances over the sliding window. Theoretically, KW is 1 \u2212 \u03b5 1+ d -approximate for SMDK. Furthermore, we propose a K NAP W INDOW P LUS framework (KW + ) to improve upon KW. KW + builds an index S UB K NAP C HK to manage the checkpoints and KS instances. S UB K NAP C HK deletes a checkpoint whenever it can be approximated by its successors. By keeping much fewer checkpoints, KW + achieves higher ef\ufb01ciency than KW while still guaranteeing a 1 \u2212 \u03b5 (cid:48) 2+2 d -approximate solution for SMDK. Finally, we evaluate the ef\ufb01ciency and solution quality of KW and KW + in real-world datasets. The experimental results demonstrate that KW achieves more than two orders of magnitude speedups over the batch baseline and preserves high-quality solutions for SMDK over sliding windows. KW + further runs 5-10 times faster than KW while providing solutions with equivalent or even better utilities.",
      "fieldsOfStudy": null,
      "topics": [
        "sliding windows",
        "windows",
        "KW",
        "general d -knapsack constraints",
        "SMDK",
        "massive datasets",
        "constraints",
        "selected subsets",
        "submodular functions",
        "solutions",
        "S UB K NAP C HK",
        "KS instances",
        "dynamic RSS",
        "higher ef\ufb01ciency",
        "solution quality",
        "data streams"
      ]
    },
    "org": {
      "title": "Dispersive shallow water wave modelling. Part II: Numerical simulation on a globally flat space",
      "url": "https://www.semanticscholar.org/paper/72d4fb5204bdcbe5f4834fc9ccd2328dfa41206e",
      "abstract": "In this paper, we describe a numerical method to solve numerically the weakly dispersive fully nonlinear Serre-Green-Naghdi (SGN) celebrated model. Namely, our scheme is based on reliable finite volume methods, proven to be very effective for the hyperbolic part of equations. The particularity of our study is that we develop an adaptive numerical model using moving grids. Moreover, we use a special form of the SGN equations where non-hydrostatic part of pressure is found by solving a nonlinear elliptic equation. Moreover, this form of governing equations allows determining the natural form of boundary conditions to obtain a well-posed (numerical) problem.",
      "fieldsOfStudy": [
        "Physics",
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "non-hydrostatic part",
        "equations",
        "governing equations",
        "moving grids",
        "model",
        "boundary conditions",
        "nonlinear elliptic equation",
        "SGN",
        "reliable finite volume methods",
        "pressure",
        "SGN equations",
        "adaptive numerical model",
        "natural form",
        "hyperbolic part",
        "numerical method",
        "weakly dispersive fully nonlinear Serre-Green-Naghdi (SGN) celebrated model",
        "special form"
      ]
    }
  },
  {
    "sim": 0.6426044102113297,
    "gen": {
      "title": "Computer Vision - ACCV 2007, 8th Asian Conference on Computer Vision, Tokyo, Japan, November 18-22, 2007, Proceedings, Part I",
      "url": "https://www.semanticscholar.org/paper/ad7c28cf9fd1ff784add8712f8c5ab226a2815e4",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ]
    },
    "org": {
      "title": "DISC: Deep Image Saliency Computing via Progressive Representation Learning",
      "url": "https://www.semanticscholar.org/paper/a964ca2a17f53c254192d497e2a3a1bd33271307",
      "abstract": "Salient object detection increasingly receives attention as an important component or step in several pattern recognition and image processing tasks. Although a variety of powerful saliency models have been intensively proposed, they usually involve heavy feature (or model) engineering based on priors (or assumptions) about the properties of objects and backgrounds. Inspired by the effectiveness of recently developed feature learning, we provide a novel deep image saliency computing (DISC) framework for fine-grained image saliency computing. In particular, we model the image saliency from both the coarse-and fine-level observations, and utilize the deep convolutional neural network (CNN) to learn the saliency representation in a progressive manner. In particular, our saliency model is built upon two stacked CNNs. The first CNN generates a coarse-level saliency map by taking the overall image as the input, roughly identifying saliency regions in the global context. Furthermore, we integrate superpixel-based local context information in the first CNN to refine the coarse-level saliency map. Guided by the coarse saliency map, the second CNN focuses on the local context to produce fine-grained and accurate saliency map while preserving object details. For a testing image, the two CNNs collaboratively conduct the saliency computing in one shot. Our DISC framework is capable of uniformly highlighting the objects of interest from complex background while preserving well object details. Extensive experiments on several standard benchmarks suggest that DISC outperforms other state-of-the-art methods and it also generalizes well across data sets without additional training. The executable version of DISC is available online: <;uri xlink:type=\"simple\">http://vision.sysu.edu.cn/projects/DISC<;/uri>.",
      "fieldsOfStudy": [
        "Medicine",
        "Computer Science"
      ],
      "topics": [
        "saliency regions",
        "powerful saliency models",
        "object details",
        "image processing tasks",
        "objects",
        "Salient object detection",
        "additional training",
        "complex background",
        "coarse saliency map",
        "CNN",
        "pattern recognition",
        "image saliency",
        "saliency computing",
        "backgrounds",
        "fine-grained image saliency computing",
        "pattern recognition and image processing tasks",
        "data sets"
      ]
    }
  },
  {
    "sim": 0.5301650654206995,
    "gen": {
      "title": "A class of robust numerical methods for solving dynamical systems with multiple time scales",
      "url": "https://www.semanticscholar.org/paper/7067fe42c85829249d1ab0cef6c0a2beaffafdf5",
      "abstract": "In this paper, we develop a class of robust numerical methods for solving dynamical systems with multiple time scales. We first represent the solution of a multiscale dynamical system as a transformation of a slowly varying solution. Then, under the scale separation assumption, we provide a systematic way to construct the transformation map and derive the dynamic equation for the slowly varying solution. We also provide the convergence analysis of the proposed method. Finally, we present several numerical examples, including ODE system with three and four separated time scales to demonstrate the accuracy and efficiency of the proposed method. Numerical results verify that our method is robust in solving ODE systems with multiple time scale, where the time step does not depend on the multiscale parameters.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "multiple time scales",
        "dynamical systems",
        "ODE systems",
        "robust numerical methods",
        "multiscale dynamical system",
        "ODE",
        "proposed method",
        "time step",
        "efficiency",
        "scale separation assumption",
        "numerical examples",
        "multiscale parameters",
        "Numerical results",
        "ODE system",
        "slowly varying solution"
      ]
    },
    "org": {
      "title": "Modifying the Yamaguchi Four-Component Decomposition Scattering Powers Using a Stochastic Distance",
      "url": "https://www.semanticscholar.org/paper/e36e39a425c68b81e53123bacfc5b80f93d4301b",
      "abstract": "Model-based decompositions have gained considerable attention after the initial work of Freeman and Durden. This decomposition, which assumes the target to be reflectionsymmetric, was later relaxed in the Yamaguchi et al. decomposition with the addition of the helix parameter. Since then, many decomposition have been proposed where either the scattering model was modified to fit the data or the coherency matrix representing the second-order statistics of the full polarimetric data is rotated to fit the scattering model. In this paper, we propose to modify the Yamaguchi four-component decomposition (Y4O) scattering powers using the concept of statistical information theory for matrices. In order to achieve this modification, we propose a method to estimate the polarization orientation angle (OA) from full-polarimetric SAR images using the Hellinger distance. In this method, the OA is estimated by maximizing the Hellinger distance between the unrotated and the rotated T33 and the T22 components of the coherency matrix [T]. Then, the powers of the Yamaguchi four-component model-based decomposition (Y4O) are modified using the maximum relative stochastic distance between the T33 and the T22 components of the coherency matrix at the estimated OA. The results show that the overall double-bounce powers over rotated urban areas have significantly improved with the reduction of volume powers. The percentage of pixels with negative powers have also decreased from the Y4O decomposition. The proposed method is both qualitatively and quantitatively compared with the results obtained from the Y4O and the Y4R decompositions for a Radarsat-2 C-band San-Francisco dataset and an UAVSAR L-band Hayward dataset.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics",
        "Mathematics"
      ],
      "topics": [
        "matrices",
        "volume powers",
        "OA",
        "powers",
        "negative powers",
        "decomposition",
        "rotated urban areas",
        "statistical information theory",
        "T22",
        "T33",
        "Hellinger",
        "order",
        "coherency matrix",
        "full-polarimetric SAR images",
        "second",
        "UAVSAR L-band Hayward dataset",
        "UAVSAR",
        "Hayward",
        "Y4O",
        "Durden"
      ]
    }
  },
  {
    "sim": 0.6161913816733657,
    "gen": {
      "title": "Multi-label Classification using Labels as Hidden Nodes",
      "url": "https://www.semanticscholar.org/paper/57b5468d9a6d6b9b2ef7540afb0187a0a8dfee1f",
      "abstract": "Competitive methods for multi-label classification typically invest in learning labels together. To do so in a beneficial way, analysis of label dependence is often seen as a fundamental step, separate and prior to constructing a classifier. Some methods invest up to hundreds of times more computational effort in building dependency models, than training the final classifier itself. We extend some recent discussion in the literature and provide a deeper analysis, namely, developing the view that label dependence is often introduced by an inadequate base classifier, rather than being inherent to the data or underlying concept; showing how even an exhaustive analysis of label dependence may not lead to an optimal classification structure. Viewing labels as additional features (a transformation of the input), we create neural-network inspired novel methods that remove the emphasis of a prior dependency structure. Our methods have an important advantage particular to multi-label data: they leverage labels to create effective units in middle layers, rather than learning these units from scratch in an unsupervised fashion with gradient-based methods. Results are promising. The methods we propose perform competitively, and also have very important qualities of scalability.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "label dependence",
        "underlying concept",
        "multi-label data",
        "novel methods",
        "labels",
        "multi-label classification",
        "Competitive methods",
        "effective units",
        "dependency models",
        "analysis",
        "middle layers",
        "inadequate base classifier",
        "final classifier",
        "gradient-based methods",
        "prior dependency structure",
        "neural-network inspired novel methods"
      ]
    },
    "org": {
      "title": "Deep Neural Machine Translation with Weakly-Recurrent Units",
      "url": "https://www.semanticscholar.org/paper/a33b1e5c67be044005d5d48be4eb05c6da22aa77",
      "abstract": "Recurrent neural networks (RNNs) have represented for years the state of the art in neural machine translation. Recently, new architectures have been proposed, which can leverage parallel computation on GPUs better than classical RNNs. Faster training and inference combined with different sequence-to-sequence modeling also lead to performance improvements. While the new models completely depart from the original recurrent architecture, we decided to investigate how to make RNNs more efficient. In this work, we propose a new recurrent NMT architecture, called Simple Recurrent NMT, built on a class of fast and weakly-recurrent units that use layer normalization and multiple attentions. Our experiments on the WMT14 English-to-German and WMT16 English-Romanian benchmarks show that our model represents a valid alternative to LSTMs, as it can achieve better results at a significantly lower computational cost.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "multiple attentions",
        "neural machine translation",
        "classical RNNs",
        "Recurrent neural networks",
        "better results",
        "performance improvements",
        "RNNs",
        "layer normalization",
        "Simple Recurrent NMT",
        "new architectures",
        "sequence",
        "parallel computation",
        "new recurrent NMT architecture",
        "LSTMs",
        "English",
        "years",
        "Faster training"
      ]
    }
  },
  {
    "sim": 0.5440413602904107,
    "gen": {
      "title": "Incorporating Expert Prior in Bayesian Optimisation via Space Warping",
      "url": "https://www.semanticscholar.org/paper/5f24339f0e5b7a45279c291a3ac9e6b6b8679092",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ]
    },
    "org": {
      "title": "Model-based Behavioral Cloning with Future Image Similarity Learning",
      "url": "https://www.semanticscholar.org/paper/b8e35eb21a69178aba00205073d34ec9b2ee499c",
      "abstract": "We present a visual imitation learning framework that enables learning of robot action policies solely based on expert samples without any robot trials. Robot exploration and on-policy trials in a real-world environment could often be expensive/dangerous. We present a new approach to address this problem by learning a future scene prediction model solely on a collection of expert trajectories consisting of unlabeled example videos and actions, and by enabling generalized action cloning using future image similarity. The robot learns to visually predict the consequences of taking an action, and obtains the policy by evaluating how similar the predicted future image is to an expert image. We develop a stochastic action-conditioned convolutional autoencoder, and present how we take advantage of future images for robot learning. We conduct experiments in simulated and real-life environments using a ground mobility robot with and without obstacles, and compare our models to multiple baseline methods.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "robot action policies",
        "future image similarity",
        "future images",
        "robot learning",
        "generalized action cloning",
        "actions",
        "multiple baseline methods",
        "expert trajectories",
        "expert samples",
        "unlabeled example videos",
        "predicted future image",
        "policy",
        "future scene prediction model",
        "ground mobility robot",
        "expert image",
        "Robot exploration",
        "learning"
      ]
    }
  },
  {
    "sim": 0.8320243689061221,
    "gen": {
      "title": "DropBlock: A regularization method for convolutional networks",
      "url": "https://www.semanticscholar.org/paper/e4b64a75d321311447e11c363b45cc07bb74acc2",
      "abstract": "Deep neural networks often work well when they are over-parameterized and trained with a massive amount of noise and regularization, such as weight decay and dropout. Although dropout is widely used as a regularization technique for fully connected layers, it is often less effective for convolutional layers. This lack of success of dropout for convolutional layers is perhaps due to the fact that activation units in convolutional layers are spatially correlated so information can still flow through convolutional networks despite dropout. Thus a structured form of dropout is needed to regularize convolutional networks. In this paper, we introduce DropBlock, a form of structured dropout, where units in a contiguous region of a feature map are dropped together. We found that applying DropbBlock in skip connections in addition to the convolution layers increases the accuracy. Also, gradually increasing number of dropped units during training leads to better accuracy and more robust to hyperparameter choices. Extensive experiments show that DropBlock works better than dropout in regularizing convolutional networks. On ImageNet classification, ResNet-50 architecture with DropBlock achieves $78.13\\%$ accuracy, which is more than $1.6\\%$ improvement on the baseline. On COCO detection, DropBlock improves Average Precision of RetinaNet from $36.8\\%$ to $38.4\\%$.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "convolutional networks",
        "dropout",
        "structured dropout",
        "dropped units",
        "activation units",
        "better accuracy",
        "Deep neural networks",
        "units",
        "choices",
        "weight decay",
        "regularization",
        "noise",
        "fully connected layers",
        "information",
        "hyperparameter choices"
      ]
    },
    "org": {
      "title": "On the Regularization Properties of Structured Dropout",
      "url": "https://www.semanticscholar.org/paper/dc0a514d090e60d8cf776924a8bb37738333db85",
      "abstract": "Dropout and its extensions (e.g. DropBlock and DropConnect) are popular heuristics for training neural networks, which have been shown to improve generalization performance in practice. However, a theoretical understanding of their optimization and regularization properties remains elusive. Recent work shows that in the case of single hidden-layer linear networks, Dropout is a stochastic gradient descent method for minimizing a regularized loss, and that the regularizer induces solutions that are low-rank and balanced. In this work we show that for single hidden-layer linear networks, DropBlock induces spectral k-support norm regularization, and promotes solutions that are low-rank and have factors with equal norm. We also show that the global minimizer for DropBlock can be computed in closed form, and that DropConnect is equivalent to Dropout. We then show that some of these results can be extended to a general class of Dropout-strategies, and, with some assumptions, to deep non-linear networks when Dropout is applied to the last layer. We verify our theoretical claims and assumptions experimentally with commonly used network architectures.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "equal norm",
        "deep non-linear networks",
        "neural networks",
        "solutions",
        "Dropout",
        "single hidden-layer linear networks",
        "spectral k-support norm regularization",
        "linear",
        "factors",
        "practice",
        "DropBlock",
        "generalization performance",
        "popular heuristics",
        "closed form",
        "commonly used network architectures",
        "DropConnect"
      ]
    }
  },
  null,
  {
    "sim": 0.31853284665322357,
    "gen": {
      "title": "Online Convex Optimization Perspective for Learning from Dynamically Revealed Preferences",
      "url": "https://www.semanticscholar.org/paper/05722167576c4800697d4be060612856f7a33559",
      "abstract": "We study the problem of online learning (OL) from revealed preferences: a learner wishes to learn an agent's private utility function through observing the agent's utility-maximizing actions in a changing environment. We adopt an online inverse optimization setup, where the learner observes a stream of agent's actions in an online fashion and the learning performance is measured by regret associated with a loss function. Due to the inverse optimization component, attaining or proving convexity is difficult for all of the usual loss functions in the literature. We address this challenge by designing a new loss function that is convex under relatively mild assumptions. Moreover, we establish that the regret with respect to our new loss function also bounds the regret with respect to all other usual loss functions. This then allows us to design a flexible OL framework that enables a unified treatment of loss functions and supports a variety of online convex optimization algorithms. We demonstrate with theoretical and empirical evidence that our framework based on the new loss function (in particular online Mirror Descent) has significant advantages in terms of eliminating technical assumptions as well as regret performance and solution time over other OL algorithms from the literature.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "OL algorithms",
        "online convex optimization algorithms",
        "regret performance",
        "technical assumptions",
        "solution time",
        "usual loss functions",
        "new loss function",
        "online learning",
        "loss function",
        "OL",
        "significant advantages",
        "regret"
      ]
    },
    "org": {
      "title": "Relations such as Hypernymy: Identifying and Exploiting Hearst Patterns in Distributional Vectors for Lexical Entailment",
      "url": "https://www.semanticscholar.org/paper/c881d1989fa1a497b404c511a26bf7df9f12936e",
      "abstract": "We consider the task of predicting lexical entailment using distributional vectors. We perform a novel qualitative analysis of one existing model which was previously shown to only measure the prototypicality of word pairs. We find that the model strongly learns to identify hypernyms using Hearst patterns, which are well known to be predictive of lexical relations. We present a novel model which exploits this behavior as a method of feature extraction in an iterative procedure similar to Principal Component Analysis. Our model combines the extracted features with the strengths of other proposed models in the literature, and matches or outperforms prior work on multiple data sets.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "multiple data sets",
        "Principal Component Analysis",
        "lexical relations",
        "distributional vectors",
        "word pairs",
        "proposed models",
        "lexical entailment",
        "prior work",
        "feature extraction",
        "Hearst patterns",
        "Hearst",
        "matches",
        "hypernyms",
        "existing model",
        "novel model",
        "iterative procedure"
      ]
    }
  },
  null,
  {
    "sim": 0.524998866514733,
    "gen": {
      "title": "Selecting Subgoal for Social AGV Path Planning by Using Reinforcement Learning",
      "url": "https://www.semanticscholar.org/paper/ba4da267e182f41527593d4ff5a84d55b4adcf58",
      "abstract": "Automated Guided Vehicles (AGVs) can be widely used in many applications. In a dynamic environment where humans and machines coexist, it is expected to encounter traffic jams, queuing, overtaking, comity, and many other diverse, dynamic social interaction. However, capturing the characteristics of the social interactions among passages for path planning is a complex problem. It is crucial to realize the application of AGVs. Dealing with such a complex dynamic environment thus becomes a primary subject of navigation. However, in facing stop-and-go crowds in shopping malls or traffic jams, the past navigation methods cannot effectively cope with the navigation task. Therefore, we propose a hierarchical reinforcement learning framework named MTON, which collects historic environmental statistics to analyze social interactions and periodically selects a promising navigation subgoal to complete the navigation. Our model introduces the idea of interchanging between waiting and moving. Thus it can cope with stop-and-go dynamic obstacles and find a way to break through the barriers to the final goal.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "applications",
        "promising navigation subgoal",
        "past navigation methods",
        "traffic jams",
        "AGVs",
        "historic environmental statistics",
        "navigation",
        "path planning",
        "shopping malls",
        "social interactions",
        "passages",
        "dynamic environment",
        "diverse, dynamic social interaction",
        "comity"
      ]
    },
    "org": {
      "title": "Upper Bounding GED via Transformations to LSAPE Based on Rings and Machine Learning",
      "url": "https://www.semanticscholar.org/paper/6298cccf1c9c7b0a3ac65d63652ba7865169aed6",
      "abstract": "The graph edit distance (GED) is a flexible distance measure which is widely used for inexact graph matching. Since its exact computation is NP-hard, heuristics are used in practice. A popular approach is to obtain upper bounds for GED via transformations to the linear sum assignment problem with error-correction (LSAPE). Typically, local structures and distances between them are employed for carrying out this transformation, but recently also machine learning techniques have been used. In this paper, we formally define a unifying framework LSAPE-GED for transformations from GED to LSAPE. We introduce rings as a new kind of local structures that are able to capture a lot of information encoded in the input graphs at a low computational cost. Furthermore, we propose two new ring based heuristics RING and RING-ML, which instantiate LSAPE-GED using the traditional and the machine learning based approach for transforming GED to LSAPE, respectively. Extensive experiments show that using rings for upper bounding GED significantly improves the state of the art on datasets where most information resides in the graphs' topologies.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "upper bounding GED",
        "GED",
        "LSAPE",
        "inexact graph matching",
        "machine learning techniques",
        "learning based approach",
        "LSAPE-GED",
        "transformations",
        "unifying framework LSAPE-GED",
        "information",
        "upper bounds",
        "distances",
        "new ring based heuristics RING",
        "The graph edit distance",
        "machine learning based approach",
        "RING"
      ]
    }
  },
  {
    "sim": 0.8241935771733999,
    "gen": {
      "title": "Learning to Cache: Distributed Coded Caching in a Cellular Network With Correlated Demands",
      "url": "https://www.semanticscholar.org/paper/be0c40e5f01d8fe965ea722f04434fbde6830936",
      "abstract": "Design of distributed caching mechanisms is considered as an active area of research due to its promising solution in reducing data load in the backhaul link of a cellular network. In this paper, the problem of distributed content caching in a small-cell Base Stations (sBSs) wireless network that maximizes the cache hit performance is considered. Most of the existing works focus on static demands, however, here, data at each sBS is considered to be correlated across time and sBSs. The caching strategy is assumed to be a weighted combination of past caching strategies. A high probability generalization guarantees on the performance of the proposed caching strategy is derived. The theoretical guarantee provides following insights on obtaining the caching strategy: (i) run regret minimization at each sBS to obtain a sequence of caching strategies across time, and (ii) maximize an estimate of the bound to obtain a set of weights for the caching strategy which depends on the discrepancy. Also, theoretical guarantee on the performance of the LRFU caching strategy is derived. Further, federated learning based heuristic caching algorithm is also proposed. Finally, it is shown through simulations using Movie Lens dataset that the proposed algorithm significantly outperforms LRFU algorithm.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "past caching strategies",
        "distributed caching mechanisms",
        "federated learning based heuristic caching algorithm",
        "LRFU algorithm",
        "caching strategy",
        "data load",
        "sBSs",
        "time",
        "LRFU",
        "regret minimization",
        "cache hit performance",
        "distributed content caching",
        "The caching strategy",
        "data"
      ]
    },
    "org": {
      "title": "Energy Efficiency in Cache-Enabled Small Cell Networks With Adaptive User Clustering",
      "url": "https://www.semanticscholar.org/paper/9fdbdf6f3c6031cb9f153aeed70400a60910f8a7",
      "abstract": "Using a network of cache enabled small cells, traffic during peak hours can be reduced by proactively fetching the content that is most likely to be requested. In this paper, we aim to explore the impact of proactive caching on an important metric for future generation networks, namely, energy efficiency (EE). We argue that, exploiting the spatial repartitions of users in addition to the correlation in their content popularity profiles, can result in considerable improvement of the achievable EE. In this paper, the optimization of EE is decoupled into two related subproblems. The first one addresses the issue of content popularity modeling. While most existing works assume similar popularity profiles for all users, we consider an alternative framework in which, users are clustered according to their popularity profiles. In order to showcase the utility of the proposed clustering, we use a statistical model selection criterion, namely, Akaike information criterion. Using stochastic geometry, we derive a closed-form expression of the achievable EE and we find the optimal active small cell density vector that maximizes it. The second subproblem investigates the impact of exploiting the spatial repartitions of users. After considering a snapshot of the network, we formulate a combinatorial problem that optimizes content placement in order to minimize the transmission power. Numerical results show that the clustering scheme considerably improves the cache hit probability and consequently the EE, compared with an unclustered approach. Simulations also show that the small base station allocation algorithm improves the energy efficiency and hit probability.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "content popularity modeling",
        "similar popularity profiles",
        "EE",
        "content placement",
        "users",
        "small cells",
        "Akaike",
        "future generation networks",
        "statistical model selection criterion",
        "considerable improvement",
        "content popularity profiles",
        "optimal active small cell density vector",
        "probability",
        "namely, Akaike information criterion",
        "peak hours",
        "cache enabled small cells",
        "hit probability"
      ]
    }
  },
  {
    "sim": 0.6500073712059169,
    "gen": {
      "title": "Bilinear Attention Networks",
      "url": "https://www.semanticscholar.org/paper/a5d10341717c0519cf63151b496a6d2ed67aa05f",
      "abstract": "Attention networks in multimodal learning provide an efficient way to utilize given visual information selectively. However, the computational cost to learn attention distributions for every pair of multimodal input channels is prohibitively expensive. To solve this problem, co-attention builds two separate attention distributions for each modality neglecting the interaction between multimodal inputs. In this paper, we propose bilinear attention networks (BAN) that find bilinear attention distributions to utilize given vision-language information seamlessly. BAN considers bilinear interactions among two groups of input channels, while low-rank bilinear pooling extracts the joint representations for each pair of channels. Furthermore, we propose a variant of multimodal residual networks to exploit eight-attention maps of the BAN efficiently. We quantitatively and qualitatively evaluate our model on visual question answering (VQA 2.0) and Flickr30k Entities datasets, showing that BAN significantly outperforms previous methods and achieves new state-of-the-arts on both datasets.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "multimodal input channels",
        "input channels",
        "channels",
        "multimodal inputs",
        "bilinear interactions",
        "attention distributions",
        "BAN",
        "Attention networks",
        "visual information",
        "new state",
        "previous methods",
        "attention",
        "multimodal learning",
        "given visual information",
        "multimodal residual networks"
      ]
    },
    "org": {
      "title": "Training Variational Autoencoders with Buffered Stochastic Variational Inference",
      "url": "https://www.semanticscholar.org/paper/49694a3c8fddb0292641dc2cfaf346c79b76b72a",
      "abstract": "The recognition network in deep latent variable models such as variational autoencoders (VAEs) relies on amortized inference for efficient posterior approximation that can scale up to large datasets. However, this technique has also been demonstrated to select suboptimal variational parameters, often resulting in considerable additional error called the amortization gap. To close the amortization gap and improve the training of the generative model, recent works have introduced an additional refinement step that applies stochastic variational inference (SVI) to improve upon the variational parameters returned by the amortized inference model. In this paper, we propose the Buffered Stochastic Variational Inference (BSVI), a new refinement procedure that makes use of SVI\u2019s sequence of intermediate variational proposal distributions and their corresponding importance weights to construct a new generalized importance-weighted lower bound. We demonstrate empirically that training the variational autoencoders with BSVI consistently out-performs SVI, yielding an improved training procedure for VAEs.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "stochastic variational inference",
        "variational autoencoders",
        "intermediate variational proposal distributions",
        "amortized inference",
        "large datasets",
        "efficient posterior approximation",
        "considerable additional error",
        "SVI",
        "deep latent variable models",
        "recent works",
        "amortized inference model",
        "VAEs",
        "new refinement procedure",
        "variational parameters",
        "suboptimal variational parameters",
        "new generalized importance-weighted lower bound"
      ]
    }
  },
  null,
  {
    "sim": 0.5386940986350176,
    "gen": {
      "title": "Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs",
      "url": "https://www.semanticscholar.org/paper/cb6866b5fa62ae3cbe21bafd772bcce7d9668dd6",
      "abstract": "The driving force behind the recent success of LSTMs has been their ability to learn complex and non-linear relationships. Consequently, our inability to describe these relationships has led to LSTMs being characterized as black boxes. To this end, we introduce contextual decomposition (CD), an interpretation algorithm for analysing individual predictions made by standard LSTMs, without any changes to the underlying model. By decomposing the output of a LSTM, CD captures the contributions of combinations of words or variables to the final prediction of an LSTM. On the task of sentiment analysis with the Yelp and SST data sets, we show that CD is able to reliably identify words and phrases of contrasting sentiment, and how they are combined to yield the LSTM's final prediction. Using the phrase-level labels in SST, we also demonstrate that CD is able to successfully extract positive and negative negations from an LSTM, something which has not previously been done.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "individual predictions",
        "black boxes",
        "standard LSTMs",
        "CD",
        "LSTMs",
        "words",
        "complex and non-linear relationships",
        "contrasting sentiment",
        "LSTMs final prediction",
        "sentiment analysis",
        "variables",
        "SST",
        "underlying model",
        "combinations"
      ]
    },
    "org": {
      "title": "Transfer Learning for Speech Recognition on a Budget",
      "url": "https://www.semanticscholar.org/paper/62f8f676d90d8d5ea79a5f51bdc1430969285bdc",
      "abstract": "End-to-end training of automated speech recognition (ASR) systems requires massive data and compute resources. We explore transfer learning based on model adaptation as an approach for training ASR models under constrained GPU memory, throughput and training data. We conduct several systematic experiments adapting a Wav2Letter convolutional neural network originally trained for English ASR to the German language. We show that this technique allows faster training on consumer-grade resources while requiring less training data in order to achieve the same accuracy, thereby lowering the cost of training ASR models in other languages. Model introspection revealed that small adaptations to the network\u2019s weights were sufficient for good performance, especially for inner layers.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "training data",
        "ASR models",
        "English ASR",
        "languages",
        "faster training",
        "training",
        "ASR",
        "data",
        "model adaptation",
        "inner layers",
        "massive data and compute resources",
        "constrained GPU memory",
        "order",
        "good performance",
        "small adaptations",
        "compute resources",
        "massive data",
        "Model introspection",
        "consumer-grade resources"
      ]
    }
  },
  {
    "sim": 0.44581999973280206,
    "gen": {
      "title": "Optimal Algorithms for Ski Rental with Soft Machine-Learned Predictions",
      "url": "https://www.semanticscholar.org/paper/fecd5af17d2a403fbd432bc01a250cc513b02bc7",
      "abstract": "We consider a variant of the classic Ski Rental online algorithm with applications to machine learning. In our variant, we allow the skier access to a black-box machine-learning algorithm that provides an estimate of the probability that there will be at most a threshold number of ski-days. We derive a class of optimal randomized algorithms to determine the strategy that minimizes the worst-case expected competitive ratio for the skier given a prediction from the machine learning algorithm,and analyze the performance and robustness of these algorithms.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "optimal randomized algorithms",
        "machine learning",
        "machine learning algorithm",
        "competitive ratio",
        "classic Ski Rental online algorithm",
        "robustness",
        "black-box machine-learning algorithm",
        "algorithms",
        "ski-days",
        "applications",
        "Ski Rental",
        "a threshold number",
        "skier access",
        "skier",
        "worst-case",
        "worst-case expected competitive ratio",
        "access",
        "estimate",
        "probability"
      ]
    },
    "org": {
      "title": "Scheduling Observers Over a Shared Channel With Hard Delivery Deadlines",
      "url": "https://www.semanticscholar.org/paper/1eca8e44e5f623e48d95cafa40ec7033d9885fec",
      "abstract": "We abstract the core logical functions from applications that require ultra-low-latency wireless communications to provide a novel definition for reliability. Real-time applications \u2014 such as intelligent transportation, remote surgery, and industrial automation \u2014 involve a significant element of control and decision making. Such systems involve three logical components: observers (e.g. sensors) measuring the state of an environment or dynamical system, a centralized executive (e.g. controller) deciding on the state, and agents (e.g. actuators) that implement the executive\u2019s decisions. The executive harvests the observers\u2019 measurements and decides on the short-term trajectory of the system by instructing its agents to take appropriate actions. All observation packets (typically uplink) and action packets (typically downlink) must be delivered by hard deadlines to ensure the proper functioning of the controlled system. In-full on-time delivery cannot be guaranteed in wireless systems due to inherent uncertainties in the channel such as fading and unpredictable interference; accordingly, the executive will have to drop some packets. We develop a novel framework to formulate the Observer Selection Problem (OSP) through which the executive schedules a sequence of observations that maximize its knowledge about the current state of the system. To solve this problem efficiently yet optimally, we devise a branch-and-bound algorithm that systematically prunes the search space. Our work is different from existing work on real-time communications in that communication reliability is not conveyed by packet loss or error rate, but rather by the extent of the executive\u2019s knowledge about the state of the system it controls.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "Such systems",
        "wireless systems",
        "dynamical system",
        "action packets",
        "decision making",
        "appropriate actions",
        "hard deadlines",
        "controlled system",
        "agents",
        "packet loss or error rate",
        "inherent uncertainties",
        "system",
        "industrial automation",
        "reliability",
        "centralized executive",
        "packet loss",
        "communication reliability",
        "error rate",
        "unpredictable interference"
      ]
    }
  },
  {
    "sim": 0.49045043997145243,
    "gen": {
      "title": "Relay-Assisted and QoS Aware Scheduling to Overcome Blockage in mmWave Backhaul Networks",
      "url": "https://www.semanticscholar.org/paper/c5b41743e14a9e3bbf3fa60397128fcc82c5061b",
      "abstract": "In the scenario where small cells are densely deployed, the millimeter wave (mmWave) wireless backhaul network has been widely used. However, mmWave is easily blocked by obstacles, and how to forward the data of the blocked flows is still a significant challenge. To ensure backhauling capacity, the quality of service (QoS) requirements of flows should be satisfied. In this paper, we investigate the problem of optimal scheduling to maximize the number of flows satisfying their QoS requirements with relays exploited to overcome blockage. To achieve a practical solution, we propose a relay-assisted and QoS aware (RAQS) scheduling scheme for the backhaul networks, called RAQS. It consists of a relay selection algorithm and a transmission scheduling algorithm. The relay selection algorithm selects non-repeating relays with high link rates for the blocked flows, which helps to achieve the QoS requirements of flows as soon as possible. Then, according to the results of relay selection, the transmission scheduling algorithm exploits concurrent transmissions to satisfy the QoS requirements of flows as much as possible. Extensive simulations show RAQS can effectively overcome the blockage problem, and increase the number of completed flows and network throughput compared with other schemes. In particular, the impact of relay selection parameter is also investigated to further guide the relay selection.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "completed flows",
        "flows",
        "schemes",
        "network throughput",
        "RAQS",
        "relay selection",
        "relay selection parameter",
        "QoS",
        "non-repeating relays",
        "optimal scheduling",
        "relays",
        "concurrent transmissions",
        "blockage",
        "high link rates",
        "backhaul networks",
        "blocked flows",
        "The relay selection algorithm"
      ]
    },
    "org": {
      "title": "The Road Not Taken: Re-thinking the Feasibility of Voice Calling Over Tor",
      "url": "https://www.semanticscholar.org/paper/98f36c0a2a2c8227bddb409d907be45b6acb00f6",
      "abstract": "Abstract Anonymous VoIP calls over the Internet holds great significance for privacy-conscious users, whistle-blowers and political activists alike. Prior research deems popular anonymization systems like Tor unsuitable for providing the requisite performance guarantees that real-time applications like VoIP need. Their claims are backed by studies that may no longer be valid due to constant advancements in Tor. Moreover, we believe that these studies lacked the requisite diversity and comprehensiveness. Thus, conclusions from these studies, led them to propose novel and tailored solutions. However, no such system is available for immediate use. Additionally, operating such new systems would incur significant costs for recruiting users and volunteered relays, to provide the necessary anonymity guarantees. It thus becomes an imperative that the exact performance of VoIP over Tor be quantified and analyzed, so that the potential performance bottlenecks can be amended. We thus conducted an extensive empirical study across various in-lab and real world scenarios to shed light on VoIP performance over Tor. In over half a million calls spanning 12 months, across seven countries and covering about 6650 Tor relays, we observed that Tor supports good voice quality (Perceptual Evaluation of Speech Quality (PESQ) >3 and one-way delay <400 ms) in more than 85% of cases. Further analysis indicates that in general for most Tor relays, the contentions due to cross-traffic were low enough to support VoIP calls, that are anyways transmitted at low rates (<120 Kbps). Our findings are supported by concordant measurements using iperf that show more than the adequate available bandwidth for most cases. Hence, unlike prior efforts, our research reveals that Tor is suitable for supporting anonymous VoIP calls.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "Tor relays",
        "Tor",
        "VoIP performance",
        "cases",
        "anonymous VoIP calls",
        "VoIP calls",
        "cases",
        "political activists",
        "low rates",
        "relays",
        "VoIP",
        "good voice quality",
        "Speech Quality",
        "Abstract Anonymous VoIP",
        "Perceptual Evaluation",
        "volunteered relays"
      ]
    }
  },
  {
    "sim": 0.409655144527016,
    "gen": {
      "title": "Learning Graph Embeddings from WordNet-based Similarity Measures",
      "url": "https://www.semanticscholar.org/paper/e6ec0341b14a1391572421abfc8300862a8e1762",
      "abstract": "We present path2vec, a new approach for learning graph embeddings that relies on structural measures of pairwise node similarities. The model learns representations for nodes in a dense space that approximate a given user-defined graph distance measure, such as e.g. the shortest path distance or distance measures that take information beyond the graph structure into account. Evaluation of the proposed model on semantic similarity and word sense disambiguation tasks, using various WordNet-based similarity measures, show that our approach yields competitive results, outperforming strong graph embedding baselines. The model is computationally efficient, being orders of magnitude faster than the direct computation of graph-based distances.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "structural measures",
        "graph embeddings",
        "pairwise node similarities",
        "WordNet-based similarity measures",
        "semantic similarity",
        "graph-based distances",
        "word sense disambiguation tasks",
        "given user-defined graph distance measure",
        "account",
        "competitive results",
        "baselines",
        "e.g. the shortest path distance or distance measures",
        "nodes",
        "graph structure",
        "information",
        "strong graph embedding baselines",
        "semantic similarity and word sense disambiguation tasks",
        "WordNet"
      ]
    },
    "org": {
      "title": "Image Outpainting and Harmonization using Generative Adversarial Networks",
      "url": "https://www.semanticscholar.org/paper/15a0fea2ad8b8c85ea52323aac9fbcebba3faac3",
      "abstract": "Although the inherently ambiguous task of predicting what resides beyond all four edges of an image has rarely been explored before, we demonstrate that GANs hold powerful potential in producing reasonable extrapolations. Two outpainting methods are proposed that aim to instigate this line of research: the first approach uses a context encoder inspired by common inpainting architectures and paradigms, while the second approach adds an extra post-processing step using a single-image generative model. This way, the hallucinated details are integrated with the style of the original image, in an attempt to further boost the quality of the result and possibly allow for arbitrary output resolutions to be supported.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "reasonable extrapolations",
        "common inpainting architectures",
        "arbitrary output resolutions",
        "powerful potential",
        "extra post-processing step",
        "second",
        "paradigms",
        "single-image generative model",
        "GANs",
        "second approach",
        "research",
        "original image",
        "approach",
        "context encoder"
      ]
    }
  },
  {
    "sim": 0.6907480788654015,
    "gen": {
      "title": "Performance Analysis of Linear Codes under Maximum-Likelihood Decoding: A Tutorial",
      "url": "https://www.semanticscholar.org/paper/ede9e601e3070e8ff4ad9ff5687e43c930a293cb",
      "abstract": "This article is focused on the performance evaluation of linear codes under optimal maximum-likelihood (ML) decoding. Though the ML decoding algorithm is prohibitively complex for most practical codes, their performance analysis under ML decoding allows to predict their performance without resorting to computer simulations. It also provides a benchmark for testing the sub-optimality of iterative (or other practical) decoding algorithms. This analysis also establishes the goodness of linear codes (or ensembles), determined by the gap between their achievable rates under optimal ML decoding and information theoretical limits. In this article, upper and lower bounds on the error probability of linear codes under ML decoding are surveyed and applied to codes and ensembles of codes on graphs. For upper bounds, we discuss various bounds where focus is put on Gallager bounding techniques and their relation to a variety of other reported bounds. Within the class of lower bounds, we address de Caen's based bounds and their improvements, and also consider sphere-packing bounds with their recent improvements targeting codes of moderate block lengths.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "practical codes",
        "linear codes",
        "codes",
        "reported bounds",
        "optimal ML",
        "bounds",
        "lower bounds",
        "upper bounds",
        "ML",
        "moderate block lengths",
        "computer simulations",
        "theoretical limits",
        "algorithm",
        "Gallager bounding techniques",
        "practical) decoding algorithms",
        "optimal ML decoding",
        "ML decoding",
        "information theoretical limits",
        "ML decoding algorithm",
        "de Caens based bounds"
      ]
    },
    "org": {
      "title": "On the Performance of Transmit Antenna Selection Based on Shadowing Side Information",
      "url": "https://www.semanticscholar.org/paper/2834b6cddb4c0480d6f48fc02591fb7732e101c0",
      "abstract": "In this paper, a transmit antenna selection scheme, which is based on shadowing side information, is investigated. In this scheme, the selected single transmit antenna provides the highest shadowing coefficient between a transmitter and a receiver. By the proposed technique, the frequency of the usage of the feedback channel from the receiver to the transmitter and channel estimation complexity at the receiver can be reduced. We study the performance of our proposed technique, and in the analysis, we consider an independent but not identically distributed generalized-K composite fading model. More specifically, exact and closed-form expressions for the outage probability, the moment-generating function, the moments of signal-to-noise ratio, and the average symbol error probability (SEP) are derived. In addition, asymptotic outage probability and SP expressions are also presented to investigate the diversity order and the array gain. Finally, our theoretical performance results are validated by Monte Carlo simulations.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "asymptotic outage probability",
        "Monte Carlo simulations",
        "shadowing side information",
        "SP expressions",
        "generalized-K composite fading model",
        "average symbol error probability",
        "Monte Carlo",
        "array gain",
        "transmitter and channel estimation complexity",
        "SEP",
        "noise",
        "receiver",
        "receiver",
        "feedback channel",
        "outage probability",
        "channel estimation complexity",
        "transmit antenna selection scheme",
        "highest shadowing coefficient"
      ]
    }
  },
  {
    "sim": 0.6572239623524048,
    "gen": {
      "title": "Novel construction methods of quaternion orthogonal designs based on complex orthogonal designs",
      "url": "https://www.semanticscholar.org/paper/984b4df8bf05bc87af5686ef0a1f6117871acb6c",
      "abstract": "Quaternion orthogonal designs (QODs) are considered the foundation of orthogonal space time polarization block codes (OSTPBCs). OSTPBCs benefit from orthogonal polarizations and orthogonal space and time block coding simultaneously to enhance the capacity of wireless communication systems. To exploit these advantages of OSTPBCs, this paper explores two generalized construction techniques of QODs, where the first one is based on symmetric-paired designs while the second technique maps the complex orthogonal designs (CODs) to QODs directly. With these schemes, QODs for any number of transmit antennas can be constructed. Moreover, a low-complexity maximum-likelihood (ML) decoder for the proposed construction techniques has been presented that provides optimal decoupled decoding with phenomenal complexity reduction. Simulation results show that the diversity order of the first QOD construction is higher than the second design given the number of transmit antennas are same.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "orthogonal space time polarization block codes",
        "Quaternion orthogonal designs",
        "orthogonal space",
        "orthogonal polarizations",
        "wireless communication systems",
        "phenomenal complexity reduction",
        "transmit antennas",
        "QODs",
        "optimal decoupled",
        "second",
        "complex orthogonal designs",
        "OSTPBCs",
        "proposed construction techniques",
        "generalized construction techniques",
        "optimal decoupled decoding",
        "orthogonal space and time block coding"
      ]
    },
    "org": {
      "title": "A New Class of Multiple-Rate Codes Based on Block Markov Superposition Transmission",
      "url": "https://www.semanticscholar.org/paper/3d36664d578aed42de711b832138281031d6b600",
      "abstract": "The Hadamard transform (HT) over the binary field provides a natural way to implement multiple-rate codes (referred to as HT-coset codes), where the code length N=2p is fixed but the code dimension K can be varied from 1 to N-1 by adjusting the set of frozen bits. The HT-coset codes, including Reed-Muller (RM) codes and polar codes as typical examples, can share the same fundamental encoder/decoder architecture with the implementation complexity of order O(NlogN). However, to guarantee that all codes with designated rates perform well, HT-coset coding usually requires a sufficiently large code length, which, in turn, causes difficulties in the determination of which bits are better for being frozen. In this paper, we propose to transmit short HT-coset codes in the so-called block Markov superposition transmission (BMST) manner. At the transmitter, signals are spatially coupled via superposition, resulting in long codes. At the receiver, these coupled signals are recovered by a sliding-window iterative soft successive cancellation decoding algorithm. Most importantly, the performance around or below the bit-error-rate (BER) of 10-5 can be predicted by a simple genie-aided lower bound. Both these bounds and simulation results show that the BMST of short HT-coset codes performs well (within one dB away from the corresponding Shannon limits) in a wide range of code rates.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "code rates",
        "polar codes",
        "long codes",
        "frozen bits",
        "designated rates",
        "multiple-rate codes",
        "code length N=2p",
        "HT",
        "code dimension K",
        "O(NlogN",
        "The HT-coset codes",
        "codes",
        "typical examples",
        "order O(NlogN",
        "simulation results",
        "HT-coset coding",
        "BER"
      ]
    }
  },
  null,
  {
    "sim": 0.6711039483933261,
    "gen": {
      "title": "Residual Connections Encourage Iterative Inference",
      "url": "https://www.semanticscholar.org/paper/098b96b713aa8a324090662c7f35213512f4525e",
      "abstract": "Residual networks (Resnets) have become a prominent architecture in deep learning. However, a comprehensive understanding of Resnets is still a topic of ongoing research. \nA recent view argues that Resnets perform iterative refinement of features. We attempt to further expose properties of this aspect. To this end, we study Resnets both analytically and empirically. We formalize the notion of iterative refinement in Resnets by showing that residual connections naturally encourage features of residual blocks to move along the negative gradient of loss as we go from one block to the next. In addition, our empirical analysis suggests that Resnets are able to perform both representation learning and iterative refinement. In general, a Resnet block tends to concentrate representation learning behavior in the first few layers while higher layers perform iterative refinement of features. Finally we observe that sharing residual layers naively leads to representation explosion and counterintuitively, overfitting, and we show that simple existing strategies can help alleviating this problem.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "iterative refinement",
        "residual blocks",
        "residual layers",
        "residual connections",
        "representation learning behavior",
        "features",
        "higher layers",
        "Residual networks",
        "deep learning",
        "representation explosion",
        "simple existing strategies",
        "ongoing research",
        "Resnets",
        "loss",
        "few layers",
        "residual networks"
      ]
    },
    "org": {
      "title": "Adaptive Gradient Methods with Dynamic Bound of Learning Rate",
      "url": "https://www.semanticscholar.org/paper/03af562fb8e69677865dbe94910e464443dd4623",
      "abstract": "Adaptive optimization methods such as AdaGrad, RMSprop and Adam have been proposed to achieve a rapid training process with an element-wise scaling term on learning rates. Though prevailing, they are observed to generalize poorly compared with SGD or even fail to converge due to unstable and extreme learning rates. Recent work has put forward some algorithms such as AMSGrad to tackle this issue but they failed to achieve considerable improvement over existing methods. In our paper, we demonstrate that extreme learning rates can lead to poor performance. We provide new variants of Adam and AMSGrad, called AdaBound and AMSBound respectively, which employ dynamic bounds on learning rates to achieve a gradual and smooth transition from adaptive methods to SGD and give a theoretical proof of convergence. We further conduct experiments on various popular tasks and models, which is often insufficient in previous work. Experimental results show that new variants can eliminate the generalization gap between adaptive methods and SGD and maintain higher learning speed early in training at the same time. Moreover, they can bring significant improvement over their prototypes, especially on complex deep networks. The implementation of the algorithm can be found at this https URL .",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "extreme learning rates",
        "adaptive methods",
        "Adaptive optimization methods",
        "existing methods",
        "rates",
        "poor performance",
        "higher learning speed",
        "complex deep networks",
        "previous work",
        "SGD",
        "unstable and extreme learning rates",
        "convergence",
        "training",
        "considerable improvement",
        "dynamic bounds",
        "learning rates"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.5897528352097755,
    "gen": {
      "title": "Information diffusion modeling and analysis for socially interacting networks",
      "url": "https://www.semanticscholar.org/paper/1ab970057b1beea2fa10fc241843af230c729a3b",
      "abstract": null,
      "fieldsOfStudy": [
        "Medicine",
        "Computer Science"
      ]
    },
    "org": {
      "title": "Can human-like Bots control collective mood: agent-based simulations of online chats",
      "url": "https://www.semanticscholar.org/paper/c199c6ebafd7e654ae07c8409416c63403ee68a9",
      "abstract": "Using an agent-based modeling approach, in this paper, we study self-organized dynamics of interacting agents in the presence of chat Bots. Different Bots with tunable \u2018human-like\u2019 attributes, which exchange emotional messages with agents, are considered, and the collective emotional behavior of agents is quantitatively analyzed. In particular, using detrended fractal analysis we determine persistent fluctuations and temporal correlations in time series of agent activity and statistics of avalanches carrying emotional messages of agents when Bots favoring positive/negative affects are active. We determine the impact of Bots and identify parameters that can modulate that impact. Our analysis suggests that, by these measures, the emotional Bots induce collective emotion among interacting agents by suitably altering the fractal characteristics of the underlying stochastic process. Positive emotion Bots are slightly more effective than negative emotion Bots. Moreover, Bots which periodically alternate between positive and negative emotion can enhance fluctuations in the system, leading to avalanches of agent messages that are reminiscent of self-organized critical states.",
      "fieldsOfStudy": [
        "Physics",
        "Computer Science",
        "Psychology"
      ],
      "topics": [
        "agent messages",
        "interacting agents",
        "agent activity",
        "agents",
        "emotional messages",
        "Positive emotion Bots",
        "collective emotion",
        "Bots",
        "Different Bots",
        "parameters",
        "avalanches",
        "detrended fractal analysis",
        "persistent fluctuations",
        "self-organized critical states",
        "chat Bots",
        "emotional Bots"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.41881264405984253,
    "gen": {
      "title": "Community structure in the World Trade Network based on communicability distances",
      "url": "https://www.semanticscholar.org/paper/3f2d69c2742e7df396618999d6fab1fae8d0d015",
      "abstract": null,
      "fieldsOfStudy": [
        "Physics",
        "Computer Science",
        "Economics"
      ]
    },
    "org": {
      "title": "Instruments on large optical telescopes - A case study",
      "url": "https://www.semanticscholar.org/paper/06910dd8d35758bcf8875ef8d95923ccdbc04d29",
      "abstract": "In the distant past, telescopes were known, first and foremost, for the sizes of their apertures. However, the astronomical output of a telescope is determined by both the size of the aperture as well as the capabilities of the attached instruments. Advances in technology (not merely those related to astronomical detectors) are now enabling astronomers to build extremely powerful instruments to \nthe extent that instruments have now achieved importance comparable or even exceeding the usual importance accorded to the apertures of the telescopes. However, the cost of successive generations of instruments has risen at a rate noticeably above that of the rate of inflation. Indeed, the cost of instruments, when spread over their prime lifetime, can be a significant expense for observatories. Here, given the vast sums of money now being expended on optical telescopes and their instrumentation, I argue that astronomers must undertake \"cost-benefit\" analysis for future planning. I use the scientific output of the first two decades of the W. M. Keck Observatory as a laboratory for this purpose. I find, in the absence of upgrades, that the time to reach peak paper production for an instrument is \nabout six years. The prime lifetime of instruments (sans upgrades), as measured by citations returns, is about a decade. Well thought out and timely upgrades increase and sometimes even double the useful lifetime. Thus, upgrades are highly cost effective. I investigate how well instrument builders are rewarded (via citations by users of their instruments). I find acknowledgements ranging from \nalmost 100% to as low as 60%. Next, given the increasing cost of operating optical telescopes, the management of existing observatories continue to seek new partnerships. This naturally raises the question \"What is the cost of a single night of telescope time\". I provide a rational basis to compute this quantity. I then end the paper with some thoughts on the future of large ground-based optical \ntelescopes, bearing in mind the explosion of synoptic precision photometric, astrometric and imaging surveys across the electromagnetic spectrum, the increasing cost of instrumentation and the rise of mega instruments.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics"
      ],
      "topics": [
        "mega instruments",
        "optical telescopes",
        "operating optical telescopes",
        "telescope time",
        "new partnerships",
        "telescopes",
        "existing observatories",
        "attached instruments",
        "observatories",
        "sans upgrades",
        "synoptic precision photometric",
        "extremely powerful instruments",
        "future planning",
        "lifetime",
        "instrument builders",
        "citations returns",
        "importance",
        "peak paper production"
      ]
    }
  },
  {
    "sim": 0.7240987753562264,
    "gen": {
      "title": "Ergodic Capacity Analysis of Remote Radio Head Associations in Cloud Radio Access Networks",
      "url": "https://www.semanticscholar.org/paper/b9d5644f938d5e831afe412ccb214503c506401d",
      "abstract": "Characterizing user to remote radio head (RRH) association strategies in cloud radio access networks (C-RANs) is critical for performance optimization. In this letter, the single nearest and N-nearest RRH association strategies are presented, and the corresponding impact on the ergodic capacity of C-RANs is analyzed, where RRHs are distributed according to a stationary point process. Closed-form expressions for the ergodic capacity of the proposed RRH association strategies are derived. Simulation results demonstrate that the derived uplink closed-form capacity expressions are accurate. Furthermore, the analysis and simulation results show that the ergodic capacity gain is not linear with either the RRH density or the number of antennas per RRH. The ergodic capacity gain from the RRH density is larger than that from the number of antennas per RRH, which indicates that the association number of the RRH should not be bigger than 4 to balance the performance gain and the implementation cost.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "RRH",
        "performance optimization",
        "cloud radio access networks",
        "proposed RRH association strategies",
        "remote radio head (RRH) association strategies",
        "antennas",
        "RRH density",
        "association number",
        "single nearest and N-nearest RRH association strategies",
        "stationary point process",
        "derived uplink closed-form capacity expressions",
        "ergodic capacity",
        "performance gain",
        "(RRH"
      ]
    },
    "org": {
      "title": "Spectral and Energy Efficiency Trade-Off with Joint Power-Bandwidth Allocation in OFDMA Networks",
      "url": "https://www.semanticscholar.org/paper/6ade98a008960eccadb9fde0efe8acb3ea00f19b",
      "abstract": "The design of next generation wireless networks is strongly motivated by the need to improve network energy efficiency (EE), while ensuring that the provided performance, often expressed in terms of spectral efficiency (SE), satisfies the vastly increasing user demands. In this context, this paper discusses about the SE-EE trade-off in Orthogonal Frequency-Division Multiple Access (OFDMA) wireless networks, achieved by an optimal joint resource allocation of transmit power and bandwidth on the system downlink direction. A novel theoretical framework is presented initially for the study of a single cell scenario, where a traffic repartition scheme is proposed that simplifies the inherent optimization problem and reveals useful insights. Special attention is also given to the case of the low signal to noise ratio (SNR) and a way to easily evaluate the upper bound of EE in this regime is provided. Finally, by exploiting useful properties of stochastic geometry, this work is extended to a more challenging multi-cell environment, where interference is shown to play an essential role. For this reason, several potential interference reduction techniques are investigated in order to enhance the performance of the SE-EE trade-off curves.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "network energy efficiency",
        "wireless networks",
        "spectral efficiency",
        "EE",
        "SE",
        "useful insights",
        "transmit power",
        "potential interference reduction techniques",
        "useful properties",
        "terms",
        "Orthogonal Frequency-Division Multiple Access",
        "stochastic geometry",
        "interference",
        "OFDMA",
        "system downlink direction",
        "generation wireless networks",
        "bandwidth"
      ]
    }
  },
  {
    "sim": 0.620752553261478,
    "gen": {
      "title": "Distant Supervision for Relation Extraction with Linear Attenuation Simulation and Non-IID Relevance Embedding",
      "url": "https://www.semanticscholar.org/paper/8f7ff8e0106ba38986af25304e2f2527ef894487",
      "abstract": "Distant supervision for relation extraction is an efficient method to reduce labor costs and has been widely used to seek novel relational facts in large corpora, which can be identified as a multi-instance multi-label problem. However, existing distant supervision methods suffer from selecting important words in the sentence and extracting valid sentences in the bag. Towards this end, we propose a novel approach to address these problems in this paper. Firstly, we propose a linear attenuation simulation to reflect the importance of words in the sentence with respect to the distances between entities and words. Secondly, we propose a non-independent and identically distributed (non-IID) relevance embedding to capture the relevance of sentences in the bag. Our method can not only capture complex information of words about hidden relations, but also express the mutual information of instances in the bag. Extensive experiments on a benchmark dataset have well-validated the effectiveness of the proposed method.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "valid sentences",
        "important words",
        "words",
        "sentences",
        "non-IID",
        "multi-instance multi-label problem",
        "novel relational facts",
        "hidden relations",
        "complex information",
        "large corpora",
        "relation extraction",
        "entities",
        "existing distant supervision methods",
        "labor costs",
        "-IID) relevance",
        "respect",
        "instances"
      ]
    },
    "org": {
      "title": "Time-Series Snapshot Network as A New Model for Role Recommendation in OSS",
      "url": "https://www.semanticscholar.org/paper/61cd8f96a18394b475e9968615ed9cadc2a9f766",
      "abstract": "The last decade has witnessed the rapid growth of open source software~(OSS). Still, all contributors may find it difficult to assimilate into OSS community even they are enthusiastic to make contributions. We thus suggest that role recommendation may benefit both the users and developers, i.e., once we are able to make successful role recommendation for those in need, it may dramatically contribute to the productivity of developers and the enthusiasm of users, thus further boosting OSS projects' development. Motivated by this potential, we study the role recommendation from email data via network embedding methods. In this paper, we introduce time-series snapshot network~(TSSN) which is a mixture network to model the interactions among users and developers. Based on the established TSSN, we perform temporal biased walk~(TBW) to automatically capture both temporal and structural information of the email network, i.e., the behavioral similarity between individuals in the OSS email network. Experiments on ten Apache datasets demonstrate that the proposed TBW significantly outperforms a number of advanced random walk based embedding methods, leading to the state-of-the-art recommendation performance.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "network embedding methods",
        "successful role recommendation",
        "role recommendation",
        "advanced random walk based embedding methods",
        "developers",
        "OSS community",
        "users",
        "email data",
        "OSS",
        "temporal biased walk~(TBW",
        "open source software~(OSS",
        "OSS projects development",
        "email network",
        "contributions"
      ]
    }
  },
  {
    "sim": 0.569352599165143,
    "gen": {
      "title": "Fully Dynamic Algorithm for Constrained Submodular Optimization",
      "url": "https://www.semanticscholar.org/paper/e20c9af33843731fac53b2b42886b4cb00410b42",
      "abstract": "The task of maximizing a monotone submodular function under a cardinality constraint is at the core of many machine learning and data mining applications, including data summarization, sparse regression and coverage problems. We study this classic problem in the fully dynamic setting, where elements can be both inserted and removed. Our main result is a randomized algorithm that maintains an efficient data structure with a poly-logarithmic amortized update time and yields a $(1/2-\\epsilon)$-approximate solution. We complement our theoretical analysis with an empirical study of the performance of our algorithm.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "data summarization",
        "coverage problems",
        "sparse regression",
        "machine learning and data mining applications",
        "elements",
        "efficient data structure",
        "poly-logarithmic amortized update time",
        "classic problem",
        "randomized algorithm",
        "monotone submodular function",
        "cardinality constraint",
        "algorithm",
        "fully dynamic setting",
        "empirical study",
        "theoretical analysis",
        "$(1/2-\\epsilon)$-approximate solution"
      ]
    },
    "org": {
      "title": "DEMI: Discriminative Estimator of Mutual Information",
      "url": "https://www.semanticscholar.org/paper/4ba94e43c023cc7432e533d4b60b7ff2f72404d2",
      "abstract": "Estimating mutual information between continuous random variables is often intractable and extremely challenging for high-dimensional data. Recent progress has leveraged neural networks to optimize variational lower bounds on mutual information. Although showing promise for this difficult problem, the variational methods have been theoretically and empirically proven to have serious statistical limitations: 1) most of the approaches cannot make accurate estimates when the underlying mutual information is either low or high; 2) the resulting estimators may suffer from high variance. Our approach is based on training a classifier that provides the probability whether a data sample pair is drawn from the joint distribution or from the product of its marginal distributions. We use this probabilistic prediction to estimate mutual information. We show theoretically that our method and other variational approaches are equivalent when they achieve their optimum, while our approach does not optimize a variational bound. Empirical results demonstrate high accuracy and a good bias/variance tradeoff using our approach.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "high variance",
        "mutual information",
        "marginal distributions",
        "variational approaches",
        "high accuracy",
        "joint distribution",
        "variational lower bounds",
        "continuous random variables",
        "high-dimensional data",
        "accurate estimates",
        "underlying mutual information",
        "statistical limitations",
        "data sample pair",
        "product",
        "neural networks"
      ]
    }
  },
  {
    "sim": 0.6918630657538103,
    "gen": {
      "title": "Stochastic Gradient MCMC for Nonlinear State Space Models",
      "url": "https://www.semanticscholar.org/paper/26606fae70c808d82190801c710d16654da46f33",
      "abstract": "State space models (SSMs) provide a flexible framework for modeling complex time series via a latent stochastic process. Inference for nonlinear, non-Gaussian SSMs is often tackled with particle methods that do not scale well to long time series. The challenge is two-fold: not only do computations scale linearly with time, as in the linear case, but particle filters additionally suffer from increasing particle degeneracy with longer series. Stochastic gradient MCMC methods have been developed to scale inference for hidden Markov models (HMMs) and linear SSMs using buffered stochastic gradient estimates to account for temporal dependencies. We extend these stochastic gradient estimators to nonlinear SSMs using particle methods. We present error bounds that account for both buffering error and particle error in the case of nonlinear SSMs that are log-concave in the latent process. We evaluate our proposed particle buffered stochastic gradient using SGMCMC for inference on both long sequential synthetic and minute-resolution financial returns data, demonstrating the importance of this class of methods.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "particle methods",
        "long time series",
        "Stochastic gradient MCMC methods",
        "longer series",
        "complex time series",
        "buffered stochastic gradient estimates",
        "methods",
        "particle error",
        "increasing particle degeneracy",
        "particle filters",
        "stochastic gradient",
        "nonlinear SSMs",
        "non-Gaussian SSMs",
        "time",
        "particle degeneracy",
        "proposed particle buffered stochastic gradient",
        "hidden Markov models"
      ]
    },
    "org": {
      "title": "Faster Stochastic Variational Inference using Proximal-Gradient Methods with General Divergence Functions",
      "url": "https://www.semanticscholar.org/paper/d77df285ca51eb1088b15f2ded7c1034cadf4810",
      "abstract": "Several recent works have explored stochastic gradient methods for variational inference that exploit the geometry of the variational-parameter space. However, the theoretical properties of these methods are not well-understood and these methods typically only apply to conditionally-conjugate models. We present a new stochastic method for variational inference which exploits the geometry of the variational-parameter space and also yields simple closed-form updates even for non-conjugate models. We also give a convergence-rate analysis of our method and many other previous methods which exploit the geometry of the space. Our analysis generalizes existing convergence results for stochastic mirror-descent on non-convex objectives by using a more general class of divergence functions. Beyond giving a theoretical justification for a variety of recent methods, our experiments show that new algorithms derived in this framework lead to state of the art results on a variety of problems. Further, due to its generality, we expect that our theoretical analysis could also apply to other applications.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "non-conjugate models",
        "non-convex objectives",
        "divergence functions",
        "stochastic gradient methods",
        "recent methods",
        "previous methods",
        "variational inference",
        "existing convergence results",
        "simple closed-form updates",
        "applications",
        "new stochastic method",
        "conditionally-conjugate models",
        "Several recent works",
        "problems",
        "state",
        "new algorithms",
        "variational-parameter space"
      ]
    }
  },
  {
    "sim": 0.6902350092835584,
    "gen": {
      "title": "Deep reinforcement learning for portfolio management of markets with a dynamic number of assets",
      "url": "https://www.semanticscholar.org/paper/be791f2594a0df45341b99fe54634cc8d4dbc0fb",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    },
    "org": {
      "title": "Validating Weak-form Market Efficiency in United States Stock Markets with Trend Deterministic Price Data and Machine Learning",
      "url": "https://www.semanticscholar.org/paper/de4f8d990f4ab2db4529cddf029a48fa33c22107",
      "abstract": "The Efficient Market Hypothesis has been a staple of economics research for decades. In particular, weak-form market efficiency -- the notion that past prices cannot predict future performance -- is strongly supported by econometric evidence. In contrast, machine learning algorithms implemented to predict stock price have been touted, to varying degrees, as successful. Moreover, some data scientists boast the ability to garner above-market returns using price data alone. This study endeavors to connect existing econometric research on weak-form efficient markets with data science innovations in algorithmic trading. First, a traditional exploration of stationarity in stock index prices over the past decade is conducted with Augmented Dickey-Fuller and Variance Ratio tests. Then, an algorithmic trading platform is implemented with the use of five machine learning algorithms. Econometric findings identify potential stationarity, hinting technical evaluation may be possible, though algorithmic trading results find little predictive power in any machine learning model, even when using trend-specific metrics. Accounting for transaction costs and risk, no system achieved above-market returns consistently. Our findings reinforce the validity of weak-form market efficiency.",
      "fieldsOfStudy": [
        "Computer Science",
        "Economics"
      ],
      "topics": [
        "machine learning algorithms",
        "price data",
        "past prices",
        "stock price",
        "stock index prices",
        "algorithmic trading",
        "data science innovations",
        "little predictive power",
        "Variance Ratio",
        "econometric evidence",
        "existing econometric research",
        "market",
        "varying degrees",
        "future performance",
        "Econometric findings",
        "economics research"
      ]
    }
  },
  {
    "sim": 0.6423077643115426,
    "gen": {
      "title": "Improving the affordability of robustness training for DNNs",
      "url": "https://www.semanticscholar.org/paper/59f3d57a9821e07a73b4274b7a94867517414322",
      "abstract": "Projected Gradient Descent (PGD) based adversarial training has become one of the most prominent methods for building robust deep neural network models. However, the computational complexity associated with this approach, due to the maximization of the loss function when finding adversaries, is a longstanding problem and may be prohibitive when using larger and more complex models. In this paper we show that the initial phase of adversarial training is redundant and can be replaced with natural training which significantly improves the computational efficiency. We demonstrate that this efficiency gain can be achieved without any loss in accuracy on natural and adversarial test samples. We support our argument with insights on the nature of the adversaries and their relative strength during the training process. We show that our proposed method can reduce the training time by a factor of up to 2.5 with comparable or better model test accuracy and generalization on various strengths of adversarial attacks.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "adversarial training",
        "natural training",
        "robust deep neural network models",
        "adversarial attacks",
        "strengths",
        "comparable or better model test accuracy",
        "accuracy",
        "natural and adversarial test samples",
        "generalization",
        "adversaries",
        "training process",
        "training time",
        "larger and more complex models",
        "relative strength",
        "Projected Gradient Descent",
        "loss function"
      ]
    },
    "org": {
      "title": "Regularizing Neural Networks by Penalizing Confident Output Distributions",
      "url": "https://www.semanticscholar.org/paper/6ce1922802169f757bbafc6e087cc274a867c763",
      "abstract": "We systematically explore regularizing neural networks by penalizing low entropy output distributions. We show that penalizing low entropy output distributions, which has been shown to improve exploration in reinforcement learning, acts as a strong regularizer in supervised learning. Furthermore, we connect a maximum entropy based confidence penalty to label smoothing through the direction of the KL divergence. We exhaustively evaluate the proposed confidence penalty and label smoothing on 6 common benchmarks: image classification (MNIST and Cifar-10), language modeling (Penn Treebank), machine translation (WMT'14 English-to-German), and speech recognition (TIMIT and WSJ). We find that both label smoothing and the confidence penalty improve state-of-the-art models across benchmarks without modifying existing hyperparameters, suggesting the wide applicability of these regularizers.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "supervised learning",
        "reinforcement learning",
        "strong regularizer",
        "low entropy output distributions",
        "WSJ",
        "speech recognition",
        "WMT14 English",
        "machine translation",
        "Penn Treebank",
        "language modeling",
        "existing hyperparameters",
        "TIMIT",
        "regularizers",
        "German",
        "English",
        "label smoothing",
        "image classification"
      ]
    }
  },
  null,
  {
    "sim": 0.33768419197518196,
    "gen": {
      "title": "An Adaptive Differential Evolution Algorithm With Novel Mutation and Crossover Strategies for Global Numerical Optimization",
      "url": "https://www.semanticscholar.org/paper/067624898c070c2ed7304751610b03afbe88139b",
      "abstract": "Differential evolution (DE) is one of the most powerful stochastic real parameter optimizers of current interest. In this paper, we propose a new mutation strategy, a fitness- induced parent selection scheme for the binomial crossover of DE, and a simple but effective scheme of adapting two of its most important control parameters with an objective of achieving improved performance. The new mutation operator, which we call DE/current-to-gr_best/1, js a variant of the classical DE/current-to-best/1 scheme. It uses the best of a group (whose size is q% of the population size) of randomly selected solutions from current generation to perturb the parent (target) vector, unlike DE/current-to-best/1 that always picks the best vector of the entire population to perturb the target vector. In our modified framework of recombination, a biased parent selection scheme has been incorporated by letting each mutant undergo the usual binomial crossover with one of the p top-ranked individuals from the current population and not with the target vector with the same index as used in all variants of DE. A DE variant obtained by integrating the proposed mutation, crossover, and parameter adaptation strategies with the classical DE framework (developed in 1995) is compared with two classical and four state-of-the-art adaptive DE variants over 25 standard numerical benchmarks taken from the IEEE Congress on Evolutionary Computation 2005 competition and special session on real parameter optimization. Our comparative study indicates that the proposed schemes improve the performance of DE by a large magnitude such that it becomes capable of enjoying statistical superiority over the state-of-the-art DE variants for a wide variety of test problems. Finally, we experimentally demonstrate that, if one or more of our proposed strategies are integrated with existing powerful DE variants such as jDE and JADE, their performances can also be enhanced.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science",
        "Medicine"
      ],
      "topics": [
        "existing powerful DE variants",
        "DE",
        "current interest",
        "current generation",
        "real parameter optimization",
        "improved performance",
        "A DE variant",
        "classical DE framework",
        "target",
        "test problems",
        "statistical superiority",
        "special session",
        "crossover",
        "fitness- induced parent selection scheme",
        "current population",
        "Evolutionary Computation",
        "biased parent selection scheme"
      ]
    },
    "org": {
      "title": "Denoising based on wavelets and deblurring via self-organizing map for Synthetic Aperture Radar images",
      "url": "https://www.semanticscholar.org/paper/6d6b0bbc430d94c05220f3741754782520117065",
      "abstract": "This work deals with unsupervised image deblurring. We present a new deblurring procedure on images provided by low-resolution synthetic aperture radar (SAR) or simply by multimedia in presence of multiplicative (speckle) or additive noise, respectively. The method we propose is defined as a two-step process. First, we use an original technique for noise reduction in wavelet domain. Then, the learning of a Kohonen self-organizing map (SOM) is performed directly on the denoised image to take out it the blur. This technique has been successfully applied to real SAR images, and the simulation results are presented to demonstrate the effectiveness of the proposed algorithms.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "wavelet domain",
        "noise reduction",
        "real SAR images",
        "images",
        "SAR",
        "low-resolution synthetic aperture radar",
        "multimedia",
        "presence",
        "denoised image",
        "SOM",
        "new deblurring procedure",
        "proposed algorithms",
        "simulation results",
        "Kohonen",
        "blur",
        "additive noise",
        "unsupervised image deblurring",
        "multiplicative (speckle"
      ]
    }
  },
  {
    "sim": 0.40493718878695617,
    "gen": {
      "title": "Efficient Neural Network Training via Forward and Backward Propagation Sparsification",
      "url": "https://www.semanticscholar.org/paper/ed1b1acd7a36b22397f052d10426f1531cfc18ce",
      "abstract": "Sparse training is a natural idea to accelerate the training speed of deep neural networks and save the memory usage, especially since large modern neural networks are signi\ufb01cantly over-parameterized. However, most of the existing methods cannot achieve this goal in practice because the chain rule based gradient (w.r.t. structure parameters) estimators adopted by previous methods require dense computation at least in the backward propagation step. This paper solves this problem by proposing an ef\ufb01cient sparse training method with completely sparse forward and backward passes. We \ufb01rst formulate the training process as a continuous minimization problem under global sparsity constraint. We then separate the optimization process into two steps, corresponding to weight update and structure parameter update. For the former step, we use the conventional chain rule, which can be sparse via exploiting the sparse structure. For the latter step, instead of using the chain rule based gradient estimators as in existing methods, we propose a variance reduced policy gradient estimator, which only requires two forward passes without backward propagation, thus achieving completely sparse training. We prove that the variance of our gradient estimator is bounded. Extensive experimental results on real-world datasets demonstrate that compared to previous methods, our algorithm is much more effective in accelerating the training process, up to an order of magnitude faster.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "Sparse training",
        "large modern neural networks",
        "previous methods",
        "deep neural networks",
        "existing methods",
        "ef\ufb01cient sparse training method",
        "weight update",
        "global sparsity constraint",
        "chain rule based gradient estimators",
        "completely sparse training",
        "(w.r.t. structure parameters",
        "backward propagation step",
        "dense computation",
        "structure parameter update",
        "variance reduced policy gradient estimator"
      ]
    },
    "org": {
      "title": "Bounded Regret for Finite-Armed Structured Bandits",
      "url": "https://www.semanticscholar.org/paper/7f0a7d9f708774c4cb1808df616b9423f67385c2",
      "abstract": "We study a new type of K-armed bandit problem where the expected return of one arm may depend on the returns of other arms. We present a new algorithm for this general class of problems and show that under certain circumstances it is possible to achieve finite expected cumulative regret. We also give problem-dependent lower bounds on the cumulative regret showing that at least in special cases the new algorithm is nearly optimal.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "arms",
        "special cases",
        "problems",
        "certain circumstances",
        "expected return",
        "arm",
        "finite",
        "K-armed bandit problem",
        "problem-dependent lower bounds",
        "cumulative regret",
        "returns",
        "new algorithm",
        "new type",
        "finite expected cumulative regret",
        "general class"
      ]
    }
  },
  {
    "sim": 0.6307894868405753,
    "gen": {
      "title": "Energy Efficiency Optimization for MIMO Broadcast Channels",
      "url": "https://www.semanticscholar.org/paper/122392f068636570a8df620ee6488ea3ef92950f",
      "abstract": "Characterizing the fundamental energy efficiency (EE) limits of MIMO broadcast channels (BC) is significant for the development of green wireless communications. We address the EE optimization problem for MIMO-BC in this paper and consider a practical power model, i.e., taking into account a transmit independent power which is related to the number of active transmit antennas. Under this setup, we propose a new optimization approach, in which the transmit covariance is optimized under fixed active transmit antenna sets, and then active transmit antenna selection (ATAS) is utilized. During the transmit covariance optimization, we propose a globally optimal energy efficient iterative water-filling scheme through solving a series of concave-convex fractional programs based on the block-coordinate ascent algorithm. After that, ATAS is employed to determine the active transmit antenna set. Since activating more transmit antennas can achieve higher sum-rate but at the cost of larger transmit independent power consumption, there exists a tradeoff between the sum-rate gain and the power consumption. Here ATAS can explore the optimal tradeoff curve and thus further improve the EE. Optimal exhaustive search and low-complexity norm based ATAS schemes are developed. Through simulations, we discuss the effect of different parameters on the EE of the MIMO-BC.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "independent power consumption",
        "transmit antennas",
        "green wireless communications",
        "antenna selection",
        "antenna sets",
        "transmit independent power",
        "active transmit antenna",
        "ATAS schemes",
        "BC",
        "MIMO broadcast channels",
        "practical power model",
        "larger transmit independent power consumption",
        "active transmit antenna set",
        "transmit covariance optimization",
        "ATAS",
        "transmit covariance",
        "low-complexity norm based ATAS schemes"
      ]
    },
    "org": {
      "title": "On the effects of battery imperfections in an energy harvesting device",
      "url": "https://www.semanticscholar.org/paper/c0165aff23b5bc065335fab85c3b7cf13ef6de55",
      "abstract": "Energy Harvesting allows the devices in a Wireless Sensor Network to recharge their batteries through environmental energy sources. While in the literature the main focus is on devices with ideal batteries, in reality several inefficiencies have to be considered to correctly design the operating regimes of an Energy Harvesting Device (EHD). In this work we describe how the throughput optimization problem changes under real battery constraints in an EHD. In particular, we consider imperfect knowledge of the state of charge of the battery and storage inefficiencies, i.e., part of the harvested energy is wasted in the battery recharging process. We formulate the problem as a Markov Decision Process, basing our model on some realistic observations about transmission, consumption and harvesting power. We find the performance upper bound with a real battery and numerically discuss the novelty introduced by the real battery effects. We show that using the old policies obtained without considering the real battery effects is strongly suboptimal and may even result in zero throughput.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "real battery constraints",
        "ideal batteries",
        "environmental energy sources",
        "EHD",
        "Energy Harvesting",
        "real battery effects",
        "inefficiencies",
        "battery recharging process",
        "real battery",
        "devices",
        "batteries",
        "battery and storage inefficiencies",
        "imperfect knowledge",
        "Energy Harvesting Device",
        "transmission, consumption and harvesting power",
        "harvesting power",
        "throughput optimization problem",
        "consumption",
        "transmission"
      ]
    }
  },
  null,
  {
    "sim": 0.6108363961457707,
    "gen": {
      "title": "A Multilevel Monte Carlo Asymptotic-Preserving Particle Method for Kinetic Equations in the Diffusion Limit",
      "url": "https://www.semanticscholar.org/paper/c9e91ce340436c68db8c33d9ebb73e9edfddd0e6",
      "abstract": null,
      "fieldsOfStudy": [
        "Mathematics",
        "Physics"
      ]
    },
    "org": {
      "title": "Numerical Simulation of Multi-phase Flow in Porous Media on Parallel Computers",
      "url": "https://www.semanticscholar.org/paper/a4a5c8311ffdb361b89085ec108d834dd55c29d6",
      "abstract": "A parallel reservoir simulator has been developed, which is designed for large-scale black oil simulations. It handles three phases, including water, oil and gas, and three components, including water, oil and gas. This simulator can calculate traditional reservoir models and naturally fractured models. Various well operations are supported, such as water flooding, gas flooding and polymer flooding. The operation constraints can be fixed bottom-hole pressure, a fixed fluid rate, and combinations of them. The simulator is based on our in-house platform, which provides grids, cell-centred data, linear solvers, preconditioners and well modeling. The simulator and the platform use MPI for communications among computation nodes. Our simulator is capable of simulating giant reservoir models with hundreds of millions of grid cells. Numerical simulations show that our simulator matches with commercial simulators and it has excellent scalability.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics",
        "Mathematics"
      ],
      "topics": [
        "gas flooding",
        "polymer flooding",
        "water flooding",
        "gas",
        "grid cells",
        "linear solvers",
        "giant reservoir models",
        "traditional reservoir models",
        "oil",
        "water",
        "commercial simulators",
        "excellent scalability",
        "computation nodes",
        "preconditioners",
        "grids",
        "modeling",
        "Various well operations"
      ]
    }
  },
  {
    "sim": 0.41257121371910377,
    "gen": {
      "title": "A hybrid graphical model for rhythmic parsing",
      "url": "https://www.semanticscholar.org/paper/4c8727ee7820c00a37bbebebbd3dbfc660ea1dea",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    },
    "org": {
      "title": "A Proximity Measure using Blink Model",
      "url": "https://www.semanticscholar.org/paper/811078c1ce6bb8688fcc5dde76b58600fbc366f7",
      "abstract": "This paper proposes a new graph proximity measure. This measure is a derivative of network reliability. By analyzing its properties and comparing it against other proximity measures through graph examples, we demonstrate that it is more consistent with human intuition than competitors. A new deterministic algorithm is developed to approximate this measure with practical complexity. Empirical evaluation by two link prediction benchmarks, one in coauthorship networks and one in Wikipedia, shows promising results. For example, a single parameterization of this measure achieves accuracies that are 14-35% above the best accuracy for each graph of all predictors reported in the 2007 Liben-Nowell and Kleinberg survey.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "promising results",
        "proximity measures",
        "graph examples",
        "network reliability",
        "practical complexity",
        "competitors",
        "coauthorship networks",
        "human intuition",
        "accuracies",
        "new graph proximity measure",
        "Kleinberg",
        "Wikipedia",
        "example",
        "best accuracy",
        "Empirical evaluation",
        "Liben-Nowell and Kleinberg"
      ]
    }
  },
  {
    "sim": 0.4028608386547531,
    "gen": {
      "title": "Nonlocal Self-Similarity-Based Hyperspectral Remote Sensing Image Denoising With 3-D Convolutional Neural Network",
      "url": "https://www.semanticscholar.org/paper/ae93a4b2ec6f424ded6d89487c27761ae59ffc66",
      "abstract": "Recently, deep-learning-based denoising methods for hyperspectral images (HSIs) have been comprehensively studied and achieved impressive performance because they can effectively extract complex and nonlinear image features. Compared with deep-learning-based methods, the nonlocal similarity-based denoising methods are more suitable for images containing edges or regular textures. We propose a powerful HSI denoising method, termed non-local 3-D convolutional neural network (NL-3DCNN), combining traditional machine learning and deep learning techniques. NL-3DCNN exploits the high spectral correlation of an HSI using subspace representation, and the corresponding representation coefficients are termed eigenimages. The high spatial correlation in eigenimages is exploited by grouping nonlocal similar patches, which are denoised by a 3-D convolutional neural network. The numerical and graphical denoising results of the simulated and real data show that the proposed method is superior to the state-of-the-art methods.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "deep learning techniques",
        "traditional machine learning",
        "regular textures",
        "hyperspectral images",
        "images",
        "nonlocal similar patches",
        "impressive performance",
        "subspace representation",
        "powerful HSI denoising method",
        "complex and nonlinear image features",
        "non-local 3-D convolutional neural network",
        "NL-3DCNN",
        "deep-learning-based denoising methods",
        "nonlocal similarity-based denoising methods",
        "eigenimages",
        "traditional machine learning and deep learning techniques",
        "deep-learning-based methods"
      ]
    },
    "org": {
      "title": "Effective Feature Learning with Unsupervised Learning for Improving the Predictive Models in Massive Open Online Courses",
      "url": "https://www.semanticscholar.org/paper/9922bdc027c53395b8b13e591625e099a76a54a2",
      "abstract": "The effectiveness of learning in massive open online courses (MOOCs) can be significantly enhanced by introducing personalized intervention schemes which rely on building predictive models of student learning behaviors such as some engagement or performance indicators. A major challenge that has to be addressed when building such models is to design handcrafted features that are effective for the prediction task at hand. In this paper, we make the first attempt to solve the feature learning problem by taking the unsupervised learning approach to learn a compact representation of the raw features with a large degree of redundancy. Specifically, in order to capture the underlying learning patterns in the content domain and the temporal nature of the clickstream data, we train a modified auto-encoder (AE) combined with the long short-term memory (LSTM) network to obtain a fixed-length embedding for each input sequence. When compared with the original features, the new features that correspond to the embedding obtained by the modified LSTM-AE are not only more parsimonious but also more discriminative for our prediction task. Using simple supervised learning models, the learned features can improve the prediction accuracy by up to 17% compared with the supervised neural networks and reduce overfitting to the dominant low-performing group of students, specifically in the task of predicting students' performance. Our approach is generic in the sense that it is not restricted to a specific supervised learning model nor a specific prediction task for MOOC learning analytics.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "student learning behaviors",
        "MOOC learning analytics",
        "models",
        "handcrafted features",
        "predictive models",
        "students",
        "personalized intervention schemes",
        "specific supervised learning model",
        "specific prediction task",
        "AE",
        "feature learning problem",
        "prediction task",
        "prediction task",
        "massive open online courses",
        "unsupervised learning approach"
      ]
    }
  },
  {
    "sim": 0.6799180093011464,
    "gen": {
      "title": "Structure preserving algorithms for simulation of linearly damped acoustic systems",
      "url": "https://www.semanticscholar.org/paper/b90e43595a0f427f5d27383546de512e6bfcaf64",
      "abstract": "Energy methods for constructing time-stepping algorithms are of increased interest in application to nonlinear problems, since numerical stability can be inferred from the conservation of the system energy. Alternatively, symplectic integrators may be constructed that preserve the symplectic form of the system. This methodology has been established for Hamiltonian systems, with numerous applications in engineering problems. In this paper an extension of such methods to non-conservative acoustic systems is presented. Discrete conservation laws, equivalent to that of energy-conserving schemes, are derived for systems with linear damping, incorporating the action of external forces. Furthermore the evolution of the symplectic structure is analysed in the continuous and the discrete case. Existing methods are examined and novel methods are designed using a lumped oscillator as an elemental model. The proposed methodology is extended to the case of distributed systems and exemplified through a case study of a vibrating string bouncing against a rigid obstacle.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics",
        "Mathematics"
      ],
      "topics": [
        "distributed systems",
        "systems",
        "Hamiltonian systems",
        "non-conservative acoustic systems",
        "external forces",
        "engineering problems",
        "nonlinear problems",
        "Energy methods",
        "numerical stability",
        "Discrete conservation laws",
        "numerous applications",
        "system energy",
        "application",
        "novel methods",
        "increased interest",
        "linear damping"
      ]
    },
    "org": {
      "title": "Structure-preserving reduced-order modelling of Korteweg de Vries equation",
      "url": "https://www.semanticscholar.org/paper/4f572fd3baad1be120828985ed39a9ef0c4292d0",
      "abstract": null,
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ]
    }
  },
  {
    "sim": 0.4439042721617975,
    "gen": {
      "title": "An SVM\u2013AdaBoost-based face detection system",
      "url": "https://www.semanticscholar.org/paper/6dc3275e660a1a28af1a10aab8205f775bd8a9c2",
      "abstract": "Face detection is the first significant step in face recognition and many computer vision applications. The goal of this work was to improve detection accuracy as well as reducing the execution time. Images are pre-processed, scaled and normalised with the discrete cosine transform. Gabor feature extraction techniques were employed to extract thousands of facial vectors. An AdaBoost-based feature selection tool was formulated to select a few hundreds of the Gabor wavelets. These vectors representing significant salient local features are used as input vectors to a support vector machine classifier. The classifier is trained and becomes capable of detecting faces. A detection rate of 97.6% with acceptable false positives was registered with a test set of 507 faces. The execution time of a pixel of size 320 \u00d7 240 is 0.0285 s, which is very promising. A comparative evaluation of receiver operating characteristic (ROC) curves of different detectors on FDDB set shows that the proposed method is very effective.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "face recognition",
        "computer vision applications",
        "Face detection",
        "faces",
        "facial vectors",
        "input vectors",
        "significant salient local features",
        "support vector machine classifier",
        "FDDB set",
        "Gabor feature extraction techniques",
        "detection accuracy",
        "different detectors",
        "acceptable false positives",
        "Gabor",
        "thousands"
      ]
    },
    "org": {
      "title": "Adversarial Perturbations Against Real-Time Video Classification Systems",
      "url": "https://www.semanticscholar.org/paper/119a62a685aed7e94234a2ac4b16636c744b04a6",
      "abstract": "Recent research has demonstrated the brittleness of machine learning systems to adversarial perturbations. However, the studies have been mostly limited to perturbations on images and more generally, classification that does not deal with temporally varying inputs. In this paper we ask \"Are adversarial perturbations possible in real-time video classification systems and if so, what properties must they satisfy?\" Such systems find application in surveillance applications, smart vehicles, and smart elderly care and thus, misclassification could be particularly harmful (e.g., a mishap at an elderly care facility may be missed). We show that accounting for temporal structure is key to generating adversarial examples in such systems. We exploit recent advances in generative adversarial network (GAN) architectures to account for temporal correlations and generate adversarial samples that can cause misclassification rates of over 80% for targeted activities. More importantly, the samples also leave other activities largely unaffected making them extremely stealthy. Finally, we also surprisingly find that in many scenarios, the same perturbation can be applied to every frame in a video clip that makes the adversary's ability to achieve misclassification relatively easy.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "smart elderly care",
        "adversarial perturbations",
        "targeted activities",
        "misclassification",
        "adversarial examples",
        "systems",
        "machine learning systems",
        "activities",
        "smart vehicles",
        "surveillance applications",
        "perturbations",
        "temporal correlations",
        "real-time video classification systems"
      ]
    }
  },
  {
    "sim": 0.4880190170504657,
    "gen": {
      "title": "Blockchain and Trusted Computing: Problems, Pitfalls, and a Solution for Hyperledger Fabric",
      "url": "https://www.semanticscholar.org/paper/771cdb96a4ad2fe52c81ec0d4129fff7ff9d4aa2",
      "abstract": "A smart contract on a blockchain cannot keep a secret because its data is replicated on all nodes in a network. To remedy this problem, it has been suggested to combine blockchains with trusted execution environments (TEEs), such as Intel SGX, for executing applications that demand privacy. Untrusted blockchain nodes cannot get access to the data and computations inside the TEE. \nThis paper first explores some pitfalls that arise from the combination of TEEs with blockchains. Since TEEs are, in principle, stateless they are susceptible to rollback attacks, which should be prevented to maintain privacy for the application. However, in blockchains with non-final consensus protocols, such as the proof-of-work in Ethereum and others, the contract execution must handle rollbacks by design. This implies that TEEs for securing blockchain execution cannot be directly used for such blockchains; this approach works only when the consensus decisions are final. \nSecond, this work introduces an architecture and a prototype for smart-contract execution within Intel SGX technology for Hyperledger Fabric, a prominent platform for enterprise blockchain applications. Our system resolves difficulties posed by the execute-order-validate architecture of Fabric and prevents rollback attacks on TEE-based execution as far as possible. For increasing security, our design encapsulates each application on the blockchain within its own enclave that shields it from the host system. An evaluation shows that the overhead moving execution into SGX is within 10%-20% for a sealed-bid auction application.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "enterprise blockchain applications",
        "applications",
        "blockchains",
        "Untrusted blockchain nodes",
        "privacy",
        "trusted execution environments",
        "blockchain execution",
        "execution",
        "non-final consensus protocols",
        "rollback attacks",
        "Intel SGX technology",
        "Intel SGX",
        "TEEs",
        "Hyperledger Fabric",
        "rollbacks"
      ]
    },
    "org": {
      "title": "LANC: Locality-aware network coding for better P2P traffic localization",
      "url": "https://www.semanticscholar.org/paper/4323cc82ba7ffdb2065bb847c33c4ed4b2774e6a",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  {
    "sim": 0.5365561428215683,
    "gen": {
      "title": "On the Performance of RF-FSO Links With and Without Hybrid ARQ",
      "url": "https://www.semanticscholar.org/paper/d7d22715dadf0522a037966dd14269fd0e436078",
      "abstract": "This paper studies the performance of hybrid radio-frequency (RF) and free-space optical (FSO) links assuming perfect channel state information (CSI) at the receiver. Considering the cases with and without hybrid automatic repeat request (HARQ), we derive closed-form expressions for the message decoding probabilities as well as the throughput and the outage probability of the RF-FSO setups. We also evaluate the effect of adaptive power allocation and different channel conditions on the throughput and the outage probability. The results show the efficiency of the RF-FSO links in different conditions.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "perfect channel state information",
        "different conditions",
        "FSO",
        "RF",
        "outage probability",
        "message decoding probabilities",
        "hybrid automatic repeat request",
        "CSI",
        "adaptive power allocation",
        "RF-FSO links",
        "RF-FSO setups",
        "HARQ",
        "closed-form expressions",
        "hybrid radio-frequency (RF",
        "throughput",
        "hybrid radio-frequency (RF) and free-space optical (FSO) links",
        "receiver"
      ]
    },
    "org": {
      "title": "Asymptotic Maximum Order Statistic for SIR in ${\\kappa} -{\\mu}$ Shadowed Fading",
      "url": "https://www.semanticscholar.org/paper/030cd0e28f7a51666438ace123b900d845f3e795",
      "abstract": "Using tools from extreme value theory (EVT), it is proved that when the user signal and the interferer signals undergo independent and non-identically distributed (i.n.i.d.) <inline-formula> <tex-math notation=\"LaTeX\">$\\kappa -\\mu $ </tex-math></inline-formula> shadowed fading, the limiting distribution of the maximum of <inline-formula> <tex-math notation=\"LaTeX\">$L$ </tex-math></inline-formula> independent and identically distributed (i.i.d.) signal-to-interference ratio (SIR) random variables (RVs) is a Frechet distribution. It is observed that this limiting distribution is close to the true distribution of maximum for maximum SIR evaluated over moderate <inline-formula> <tex-math notation=\"LaTeX\">$L$ </tex-math></inline-formula>. Furthermore, moments of the maximum RV is shown to converge to the moments of the Frechet RV. In addition, the rate of convergence of the actual distribution of the maximum to the Frechet distribution is derived and analyzed for different <inline-formula> <tex-math notation=\"LaTeX\">$\\kappa $ </tex-math></inline-formula> and <inline-formula> <tex-math notation=\"LaTeX\">$\\mu $ </tex-math></inline-formula> parameters. Finally, results from the stochastic ordering are used to analyze the variation in the limiting distribution with respect to the variation in source fading parameters. These results are then used to derive upper bound for the rate in full array selection (FAS) schemes for the antenna selection and the asymptotic outage probability and the ergodic rate in maximum-sum-capacity (MSC) scheduling systems.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "maximum SIR",
        "source fading parameters",
        "Frechet",
        "math></inline",
        "i.n.i.d.",
        "array selection",
        "inline-formula",
        "maximum",
        "RV",
        "limiting distribution",
        "moments",
        "true distribution",
        "formula",
        "RVs",
        "actual distribution",
        "extreme value theory",
        "interference"
      ]
    }
  },
  {
    "sim": 0.7250781112299222,
    "gen": {
      "title": "A Tractable Model for Noncoherent Joint-Transmission Base Station Cooperation",
      "url": "https://www.semanticscholar.org/paper/528f52e09e516c84163f9ab24f9e25442c79c250",
      "abstract": "This paper presents a tractable model for analyzing noncoherent joint-transmission base station (BS) cooperation, taking into account the irregular BS deployment typically encountered in practice. In addition to cellular-network specific aspects, such as BS density, channel fading, average path loss, and interference, the model also captures relevant cooperation mechanisms, including user-centric BS clustering and channel-dependent cooperation activation. The locations of all BSs are modeled by a Poisson point process. Using tools from stochastic geometry, the signal-to-interference-plus-noise ratio (SINR) distribution with cooperation is precisely characterized in a generality-preserving form. The result is then applied to practical design problems of recent interest. We find that increasing the network-wide BS density improves the SINR, while the gains increase with the path loss exponent. For pilot-based channel estimation, the average spectral efficiency saturates at cluster sizes of around seven BSs for typical values, irrespective of backhaul quality. Finally, it is shown that intra-cluster frequency reuse is favorable in moderately loaded cells with generous cooperation activation, while intra-cluster coordinated scheduling may be better in lightly loaded cells with conservative cooperation activation.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "conservative cooperation activation",
        "generous cooperation activation",
        "relevant cooperation mechanisms",
        "cooperation",
        "intra-cluster coordinated scheduling",
        "intra-cluster frequency reuse",
        "BS density",
        "average path loss",
        "BS",
        "backhaul quality",
        "channel fading",
        "practice",
        "user-centric BS clustering and channel-dependent cooperation activation",
        "recent interest",
        "cluster sizes",
        "channel-dependent cooperation activation",
        "typical values",
        "user-centric BS clustering"
      ]
    },
    "org": {
      "title": "Time Varying Channel Tracking With Spatial and Temporal BEM for Massive MIMO Systems",
      "url": "https://www.semanticscholar.org/paper/c9855385e3f5398a97c5417851fc9efbbe9acd05",
      "abstract": "In this paper, we design a channel tracking method for massive multiple-input multiple-output systems under both time-varying and spatial-varying circumstances. By exploiting the characteristics of massive antenna array, a spatial-temporal basis expansion model is proposed to reduce the effective dimension of uplink/downlink channel, which decomposes channel state information into time-varying spatial information and gain information. We first model the user\u2019s movement as the one-order unknown Markov process, whose parameters are blindly obtained by expectation and maximization learning. Then, the uplink time-varying spatial information can also be blindly tracked by unscented Kalman filter and Taylor series expansion of the steering vector, while the rest of uplink channel gain information can be trained by only a few pilot symbols. Due to physical angle reciprocity, the spatial information of the downlink channel can be immediately computed from the uplink counterpart, which greatly reduces the complexity of downlink channel tracking. Various numerical results are provided to demonstrate the effectiveness of the proposed method.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "topics": [
        "information",
        "uplink channel",
        "maximization learning",
        "uplink time-varying spatial information",
        "massive antenna array",
        "spatial information",
        "unscented Kalman filter and Taylor series expansion",
        "channel tracking method",
        "massive multiple-input multiple-output systems",
        "downlink channel",
        "uplink/downlink channel",
        "Taylor",
        "uplink channel gain information",
        "channel state information",
        "gain information",
        "spatial-temporal basis expansion model"
      ]
    }
  },
  null,
  {
    "sim": 0.7110773913576249,
    "gen": {
      "title": "Energy-Efficient Resource Allocation in OFDMA Systems with Hybrid Energy Harvesting Base Station",
      "url": "https://www.semanticscholar.org/paper/56275d68f89cf98e4c97ce0397a06dcfca7f2fbb",
      "abstract": "We study resource allocation algorithm design for energy-efficient communication in an orthogonal frequency division multiple access (OFDMA) downlink network with hybrid energy harvesting base station (BS). Specifically, an energy harvester and a constant energy source driven by a non-renewable resource are used for supplying the energy required for system operation. We first consider a deterministic offline system setting. In particular, assuming availability of non-causal knowledge about energy arrivals and channel gains, an offline resource allocation problem is formulated as a non-convex optimization problem over a finite horizon taking into account the circuit energy consumption, a finite energy storage capacity, and a minimum required data rate. We transform this non-convex optimization problem into a convex optimization problem by applying time-sharing and exploiting the properties of non-linear fractional programming which results in an efficient asymptotically optimal offline iterative resource allocation algorithm for a sufficiently large number of subcarriers. In each iteration, the transformed problem is solved by using Lagrange dual decomposition. The obtained resource allocation policy maximizes the weighted energy efficiency of data transmission (weighted bit/Joule delivered to the receiver). Subsequently, we focus on online algorithm design. A conventional stochastic dynamic programming approach is employed to obtain the optimal online resource allocation algorithm which entails a prohibitively high complexity. To strike a balance between system performance and computational complexity, we propose a low complexity suboptimal online iterative algorithm which is motivated by the offline algorithm. Simulation results illustrate that the proposed suboptimal online iterative resource allocation algorithm does not only converge in a small number of iterations, but also achieves a close-to-optimal system energy efficiency by utilizing only causal channel state and energy arrival information.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "energy arrivals",
        "hybrid energy harvesting base station",
        "resource allocation algorithm design",
        "non-causal knowledge",
        "non-linear fractional programming",
        "proposed suboptimal online iterative resource allocation algorithm",
        "computational complexity",
        "offline resource allocation problem",
        "low complexity suboptimal online iterative algorithm",
        "system operation",
        "optimal online resource allocation algorithm",
        "online algorithm design",
        "efficient asymptotically optimal offline iterative resource allocation algorithm",
        "system performance",
        "finite energy storage capacity",
        "causal channel state and energy arrival information"
      ]
    },
    "org": {
      "title": "A Minorization-Maximization Method for Optimizing Sum Rate in the Downlink of Non-Orthogonal Multiple Access Systems",
      "url": "https://www.semanticscholar.org/paper/5dc111a3299ab5363972270052e7921fd94a9767",
      "abstract": "Non-orthogonal multiple access (NOMA) systems have the potential to deliver higher system throughput, compared with contemporary orthogonal multiple access techniques. For a linearly precoded multiple-input single-output (MISO) system, we study the downlink sum rate maximization problem, when the NOMA principle is applied. Being a non-convex and intractable optimization problem, we resort to approximate it with a minorization-maximization algorithm (MMA), which is a widely used tool in statistics. In each step of the MMA, we solve a second-order cone program, such that the feasibility set in each step contains that of the previous one, and is always guaranteed to be a subset of the feasibility set of the original problem. It should be noted that the algorithm takes a few iterations to converge. Furthermore, we study the conditions under which the achievable rates maximization can be further simplified to a low complexity design problem, and we compute the probability of occurrence of this event. Numerical examples are conducted to show a comparison of the proposed approach against conventional multiple access systems.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "conventional multiple access systems",
        "higher system throughput",
        "contemporary orthogonal multiple access techniques",
        "downlink sum rate maximization problem",
        "maximization",
        "NOMA",
        "Non-orthogonal multiple access (NOMA) systems",
        "low complexity design problem",
        "statistics",
        "occurrence",
        "original problem",
        "MMA",
        "feasibility set",
        "NOMA principle",
        "second",
        "achievable rates maximization",
        "non-convex and intractable optimization problem"
      ]
    }
  },
  null,
  null,
  null,
  {
    "sim": 0.6916817593348751,
    "gen": {
      "title": "Gaussian Universality of Linear Classifiers with Random Labels in High-Dimension",
      "url": "https://www.semanticscholar.org/paper/d231266716c3e4e976db0bd8ca0193a740f7a3a0",
      "abstract": "While classical in many theoretical settings, the assumption of Gaussian i.i.d. inputs is often perceived as a strong limitation in the analysis of high-dimensional learning. In this study, we redeem this line of work in the case of generalized linear classification with random labels. Our main contribution is a rigorous proof that data coming from a range of generative models in high-dimensions have the same minimum training loss as Gaussian data with corresponding data covariance. In particular, our theorem covers data created by an arbitrary mixture of homogeneous Gaussian clouds, as well as multi-modal generative neural networks. In the limit of vanishing regularization, we further demonstrate that the training loss is independent of the data covariance. Finally, we show that this universality property is observed in practice with real datasets and random labels.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Physics"
      ],
      "topics": [
        "corresponding data covariance",
        "random labels",
        "multi-modal generative neural networks",
        "Gaussian data",
        "homogeneous Gaussian clouds",
        "generative models",
        "data",
        "Gaussian i.i.d",
        "Gaussian",
        "generalized linear classification",
        "minimum training loss",
        "real datasets",
        "high-dimensional learning",
        "theoretical settings",
        "data covariance",
        "Gaussian i.i.d. inputs"
      ]
    },
    "org": {
      "title": "Relative Comparison Kernel Learning with Auxiliary Kernels",
      "url": "https://www.semanticscholar.org/paper/b3b2814a3aab03b8129860803dd83e77c602db6a",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ]
    }
  },
  null,
  {
    "sim": 0.5693170585204476,
    "gen": {
      "title": "Sequence Labeling and Transduction with Output-Adjusted Actor-Critic Training of RNNs",
      "url": "https://www.semanticscholar.org/paper/9389fa4d8572cea298ef6531dbd08447140029a4",
      "abstract": "Neural approaches to sequence labeling often use a Conditional Random Field (CRF) to model their output dependencies, while Recurrent Neural Networks (RNN) are used for the same purpose in other tasks. We set out to establish RNNs as an attractive alternative to CRFs for sequence labeling. To do so, we address one of the RNN\u2019s most prominent shortcomings, the fact that it is not exposed to its own errors with the maximum-likelihood training. We frame the prediction of the output sequence as a sequential decision-making process, where the RNN takes a series of actions without being conditioned on the ground-truth labels. We then train the network with an output-adjusted actorcritic algorithm (AC-RNN). We comprehensively compare this strategy with maximum-likelihood training for both RNNs and CRFs on three structuredoutput tasks. The proposed AC-RNN efficiently matches the performance of the CRF on NER and CCG tagging, and outperforms it on machine transliteration. We show that the output-adjusted actor-critic training is significantly better than other techniques for addressing RNN\u2019s exposure bias, such as Scheduled Sampling, and Self-Critical policy training.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "tasks",
        "techniques",
        "machine transliteration",
        "sequence labeling",
        "Self-Critical policy training",
        "Scheduled Sampling",
        "Recurrent Neural Networks",
        "CRF",
        "CCG tagging",
        "maximum-likelihood training",
        "RNN\u2019s exposure bias",
        "RNNs",
        "labeling",
        "CRFs",
        "structuredoutput tasks",
        "AC-RNN"
      ]
    },
    "org": {
      "title": "PL-NMF: Parallel Locality-Optimized Non-negative Matrix Factorization",
      "url": "https://www.semanticscholar.org/paper/43dd2fbe391125be476b32e055ee0e184e7b0fe3",
      "abstract": "Non-negative Matrix Factorization (NMF) is a key kernel for unsupervised dimension reduction used in a wide range of applications, including topic modeling, recommender systems and bioinformatics. Due to the compute-intensive nature of applications that must perform repeated NMF, several parallel implementations have been developed in the past. However, existing parallel NMF algorithms have not addressed data locality optimizations, which are critical for high performance since data movement costs greatly exceed the cost of arithmetic/logic operations on current computer systems. In this paper, we devise a parallel NMF algorithm based on the HALS (Hierarchical Alternating Least Squares) scheme that incorporates algorithmic transformations to enhance data locality. Efficient realizations of the algorithm on multi-core CPUs and GPUs are developed, demonstrating significant performance improvement over existing state-of-the-art parallel NMF algorithms.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "data movement costs",
        "data locality optimizations",
        "current computer systems",
        "data locality",
        "existing parallel NMF algorithms",
        "recommender systems",
        "bioinformatics",
        "high performance",
        "significant performance improvement",
        "repeated NMF",
        "parallel implementations",
        "NMF",
        "algorithmic transformations",
        "unsupervised dimension reduction",
        "topic modeling",
        "Hierarchical Alternating Least Squares"
      ]
    }
  },
  {
    "sim": 0.4849295849361417,
    "gen": {
      "title": "Distributed inference in the presence of eavesdroppers: a survey",
      "url": "https://www.semanticscholar.org/paper/0dc093d83e6a735bb914b8a42bdcea460f468779",
      "abstract": "The distributed inference framework comprises a group of spatially distributed nodes that acquire observations about a POI and transmit computed summary statistics to the fusion center. Based on the messages received from the nodes, the FC makes a global inference about the POI. The distributed and broadcast nature of such systems makes them quite vulnerable to different types of attacks. This article focuses on efficient mitigation schemes to mitigate the impact of eavesdropping on distributed inference and surveys the currently available approaches along with avenues for future research.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "distributed inference",
        "future research",
        "computed summary statistics",
        "attacks",
        "different types",
        "efficient mitigation schemes",
        "systems",
        "avenues",
        "The distributed inference framework",
        "POI",
        "eavesdropping",
        "fusion center",
        "observations",
        "spatially distributed nodes",
        "FC",
        "global inference"
      ]
    },
    "org": {
      "title": "Online Multivariate Anomaly Detection and Localization for High-Dimensional Settings",
      "url": "https://www.semanticscholar.org/paper/46378c131df382af12cb7da8f29b8f895cc53a0a",
      "abstract": "This paper considers the real-time detection of abrupt and persistent anomalies in high-dimensional data streams. The goal is to detect anomalies quickly and accurately so that the appropriate countermeasures could be taken in time before the system possibly gets harmed. We propose a sequential and multivariate anomaly detection method that scales well to high-dimensional datasets. The proposed method follows a nonparametric, i.e., data-driven, and semi-supervised approach, i.e., trains only on nominal data. Thus, it is applicable to a wide range of applications and data types. Thanks to its multivariate nature, it can quickly and accurately detect challenging anomalies, such as changes in the correlation structure. Its asymptotic optimality and computational complexity are comprehensively analyzed. In conjunction with the detection method, an effective technique for localizing the anomalous data dimensions is also proposed. The practical use of proposed algorithms are demonstrated using synthetic and real data, and in variety of applications including seizure detection, DDoS attack detection, and video surveillance.",
      "fieldsOfStudy": [
        "Computer Science",
        "Medicine",
        "Mathematics"
      ],
      "topics": [
        "nominal data",
        "data types",
        "DDoS attack detection",
        "seizure detection",
        "video surveillance",
        "proposed algorithms",
        "high-dimensional data streams",
        "anomalous data dimensions",
        "synthetic and real data",
        "challenging anomalies",
        "applications",
        "anomalies",
        "variety",
        "time",
        "high-dimensional datasets",
        "sequential and multivariate anomaly detection method"
      ]
    }
  },
  {
    "sim": 0.8194940510962655,
    "gen": {
      "title": "Beamforming and Power Splitting Designs for AN-Aided Secure Multi-User MIMO SWIPT Systems",
      "url": "https://www.semanticscholar.org/paper/c3ec9650c54879c8e58beb27b29dedd6f0b842c2",
      "abstract": "In this paper, an energy harvesting scheme for a multi-user multiple-input-multiple-output secrecy channel with artificial noise (AN) transmission is investigated. Joint optimization of the transmit beamforming matrix, the AN covariance matrix, and the power splitting ratio is conducted to minimize the transmit power under the target secrecy rate, the total transmit power, and the harvested energy constraints. The original problem is shown to be non-convex, which is tackled by a two-layer decomposition approach. The inner layer problem is solved through semi-definite relaxation, and the outer problem, on the other hand, is shown to be a single-variable optimization that can be solved by 1-D line search. To reduce computational complexity, a sequential parametric convex approximation method is proposed to find a near-optimal solution. This paper is then extended to the imperfect channel state information case with norm-bounded channel errors. Furthermore, tightness of the relaxation for the proposed schemes is validated by showing that the optimal solution of the relaxed problem is rank-one. Simulation results demonstrate that the proposed SPCA method achieves the same performance as the scheme based on 1-D but with much lower complexity.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "semi-definite relaxation",
        "computational complexity",
        "artificial noise",
        "sequential parametric convex approximation method",
        "norm-bounded channel errors",
        "imperfect channel state information case",
        "transmit power",
        "Joint optimization",
        "power splitting ratio",
        "transmit beamforming matrix",
        "proposed SPCA method",
        "multi-user multiple-input-multiple-output secrecy channel",
        "The inner layer problem",
        "relaxed problem",
        "rank",
        "AN covariance matrix",
        "target secrecy rate"
      ]
    },
    "org": {
      "title": "Semidefinite Relaxation and Approximation Analysis of a Beamformed Alamouti Scheme for Relay Beamforming Networks",
      "url": "https://www.semanticscholar.org/paper/cbdb02ca42a411729b53f69758d2c4dc9e78d6e1",
      "abstract": "In this paper, we study amplify-and-forward (AF) schemes in two-hop one-way relay networks. In particular, we consider multigroup multicast transmission between long-distance users. Assuming that perfect channel state information is perceived, our goal is to design the AF process so that the max-min-fair signal-to-interference-plus-noise ratio (SINR) is optimized while generalized power constraints are satisfied. We propose a beamformed Alamouti (BFA) AF scheme and formulate the corresponding AF design problem as a two-block  fractional quadratically constrained quadratic program (QCQP). We then tackle the two-block fractional QCQP using the semidefinite relaxation (SDR) technique and analyze the approximation accuracy of the proposed SDR. From a theoretical perspective, our results are fundamentally new and reveal that the proposed BFA AF scheme can outperform the traditional BF AF scheme, especially when there are many users in the system or many generalized power constraints in the problem formulation. From a practical perspective, our proposed BFA AF scheme improves the receivers\u2019 SINR by offering two degrees of freedom (DoFs) in beamformer design, as opposed to only one DoF offered by the BF AF scheme. In the latter part of this paper, we demonstrate how this extra DoF leads to provable performance gain by considering two special relay scenarios, in which the AF process is shown to possess a special structure. Numerical simulations further confirm that the proposed BFA AF scheme outperforms the BF AF scheme and works well for large-scale relay systems.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "AF",
        "generalized power constraints",
        "users",
        "proposed BFA AF scheme",
        "traditional BF AF scheme",
        "SDR",
        "BF AF scheme",
        "corresponding AF design problem",
        "QCQP",
        "beamformer design",
        "BFA",
        "AF process",
        "provable performance gain",
        "large-scale relay systems",
        "special relay scenarios",
        "beamformed Alamouti (BFA) AF scheme"
      ]
    }
  },
  {
    "sim": 0.5862580148881463,
    "gen": {
      "title": "AmbiSep: Ambisonic-to-Ambisonic Reverberant Speech Separation Using Transformer Networks",
      "url": "https://www.semanticscholar.org/paper/7e5226e6dd6ddd2191e793c690c15f314430d6a9",
      "abstract": "Consider a multichannel Ambisonic recording containing a mixture of several reverberant speech signals. Retrieving the reverberant Ambisonic signals corresponding to the individual speech sources blindly from the mixture is a challenging task as it requires estimating multiple signal channels for each source. In this work, we propose AmbiSep, a deep neural network-based plane-wave domain masking approach to solve this task. The masking network uses learned feature representations and transformers in a triple-path processing configuration. We train and evaluate the proposed network architecture on a spatialized WSJ0-2mix dataset and show that the method achieves a multichannel scale-invariant signal-to-distortion ratio improvement of 17.7 dB on the blind test set while preserving the spatial characteristics of the separated sounds.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "topics": [
        "multiple signal channels",
        "reverberant speech signals",
        "individual speech sources",
        "reverberant Ambisonic signals",
        "challenging task",
        "distortion",
        "feature representations",
        "separated sounds",
        "source",
        "task",
        "transformers",
        "spatial characteristics",
        "blind test",
        "triple-path processing configuration",
        "deep neural network-based plane-wave domain masking approach",
        "learned feature representations",
        "blind test set"
      ]
    },
    "org": {
      "title": "VFNet: A Convolutional Architecture for Accent Classification",
      "url": "https://www.semanticscholar.org/paper/b94d63a95506ac23d22a078ede74ba97e6611aa1",
      "abstract": "Understanding accent is an issue which can derail any human-machine interaction. Accent classification makes this task easier by identifying the accent being spoken by a person so that the correct words being spoken can be identified by further processing, since same noises can mean entirely different words in different accents of the same language. In this paper, we present VFNet (Variable Filter Net), a convolutional neural network (CNN) based architecture which captures a hierarchy of features to beat the previous benchmarks of accent classification, through a novel and elegant technique of applying variable filter sizes along the frequency band of the audio utterances.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ],
      "topics": [
        "different accents",
        "noises",
        "accent classification",
        "processing",
        "accent",
        "Variable Filter Net",
        "entirely different words",
        "features",
        "architecture",
        "CNN",
        "audio utterances",
        "language",
        "correct words"
      ]
    }
  },
  null,
  {
    "sim": 0.501195781741377,
    "gen": {
      "title": "Using Bayesian Inference for Linear Phase Log FIR Filter Design",
      "url": "https://www.semanticscholar.org/paper/e3ca459b706f28a2fba3b4cf2efa34f5fa25b7c4",
      "abstract": "This article presents the use of the Bayesian inference framework in the design of linear\u2010phase finite impulse\u2010response (FIR) filter. Given a desired frequency magnitude response in dB scale and a prescribed maximum number of taps allowed in a design, the developed method automatically determines the specific taps (and their corresponding non\u2010zero valued coefficients) required to meet the design requirements. Since the taps to be used are automatically determined, it follows that the length of the filter is also automatically determined as the filter length corresponds to the order of the last tap used. The length of the filter and the number of taps used determine the complexity of the designed filter, and the ability to design filters of complexity appropriate to the requirements is the primary advantage of using the Bayesian inference framework for filter design. To demonstrate the method, two FIR lowpass filter design problems taken from the literature are presented as examples. In these examples, the...",
      "fieldsOfStudy": [
        "Mathematics"
      ],
      "topics": [
        "filters",
        "FIR lowpass filter design problems",
        "taps",
        "designed filter",
        "Bayesian",
        "complexity",
        "FIR",
        "design requirements",
        "finite impulse\u2010response (FIR) filter",
        "Bayesian inference framework",
        "examples",
        "filter",
        "dB scale",
        "corresponding non\u2010zero valued coefficients",
        "filter length",
        "linear\u2010phase finite impulse\u2010response (FIR) filter",
        "specific taps"
      ]
    },
    "org": {
      "title": "A Deep Neural Network for Finger Counting and Numerosity Estimation",
      "url": "https://www.semanticscholar.org/paper/db744f089702ca18f93b86e5360a286e8e8ddd7d",
      "abstract": "In this paper, we present neuro-robotics models with a deep artificial neural network capable of generating finger counting positions and number estimation. We first train the model in an unsupervised manner where each layer is treated as a Restricted Boltzmann Machine or an autoencoder. Such a model is further trained in a supervised way. This type of pre-training is tested on our baseline model and two methods of pre-training are compared. The network is extended to produce finger counting positions. The performance in number estimation of such an extended model is evaluated. We test the hypothesis if the subitizing process can be obtained by one single model used also for estimation of higher numerosities. The results confirm the importance of unsupervised training in our enumeration task and show some similarities to human behaviour in the case of subitizing.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "number estimation",
        "finger counting positions",
        "higher numerosities",
        "estimation",
        "subitizing",
        "Restricted Boltzmann Machine",
        "unsupervised training",
        "human behaviour",
        "training",
        "single model",
        "neuro-robotics models",
        "baseline model",
        "deep artificial neural network",
        "subitizing process",
        "pre"
      ]
    }
  },
  {
    "sim": 0.8174261713232471,
    "gen": {
      "title": "Training Generative Adversarial Networks with Limited Data",
      "url": "https://www.semanticscholar.org/paper/29858b40a15704398aecdca6bd2820f2fcc99891",
      "abstract": "Training generative adversarial networks (GAN) using too little data typically leads to discriminator overfitting, causing training to diverge. We propose an adaptive discriminator augmentation mechanism that significantly stabilizes training in limited data regimes. The approach does not require changes to loss functions or network architectures, and is applicable both when training from scratch and when fine-tuning an existing GAN on another dataset. We demonstrate, on several datasets, that good results are now possible using only a few thousand training images, often matching StyleGAN2 results with an order of magnitude fewer images. We expect this to open up new application domains for GANs. We also find that the widely used CIFAR-10 is, in fact, a limited data benchmark, and improve the record FID from 5.59 to 2.42.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "fewer images",
        "StyleGAN2 results",
        "training",
        "good results",
        "limited data regimes",
        "discriminator overfitting",
        "magnitude",
        "datasets",
        "network architectures",
        "generative adversarial networks",
        "new application domains",
        "GANs",
        "loss functions",
        "scratch",
        "StyleGAN2",
        "limited data benchmark"
      ]
    },
    "org": {
      "title": "Label Smoothing and Logit Squeezing: A Replacement for Adversarial Training?",
      "url": "https://www.semanticscholar.org/paper/176875a416ff1b1a259e0efc7a03c5e2fa43126f",
      "abstract": "Adversarial training is one of the strongest defenses against adversarial attacks, but it requires adversarial examples to be generated for every mini-batch during optimization. The expense of producing these examples during training often precludes adversarial training from use on complex image datasets. In this study, we explore the mechanisms by which adversarial training improves classifier robustness, and show that these mechanisms can be effectively mimicked using simple regularization methods, including label smoothing and logit squeezing. Remarkably, using these simple regularization methods in combination with Gaussian noise injection, we are able to achieve strong adversarial robustness -- often exceeding that of adversarial training -- using no adversarial examples.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "adversarial training",
        "strong adversarial robustness",
        "adversarial attacks",
        "complex image datasets",
        "classifier robustness",
        "optimization",
        "Gaussian noise injection",
        "label smoothing",
        "adversarial examples",
        "batch",
        "simple regularization methods",
        "logit squeezing",
        "training"
      ]
    }
  },
  null,
  {
    "sim": 0.5617234092689571,
    "gen": {
      "title": "Behavior of solutions to the 1D focusing stochastic L2-critical and supercritical nonlinear Schr\u00f6dinger equation with space-time white noise",
      "url": "https://www.semanticscholar.org/paper/86926035396967bad54bdade18f3ff2bc778ae0a",
      "abstract": "\n We study the focusing stochastic nonlinear Schr\u00f6dinger equation in 1D in the $L^2$-critical and supercritical cases with an additive or multiplicative perturbation driven by space-time white noise. Unlike the deterministic case, the Hamiltonian (or energy) is not conserved in the stochastic setting nor is the mass (or the $L^2$-norm) conserved in the additive case. Therefore, we investigate the time evolution of these quantities. After that, we study the influence of noise on the global behaviour of solutions. In particular, we show that the noise may induce blow up, thus ceasing the global existence of the solution, which otherwise would be global in the deterministic setting. Furthermore, we study the effect of the noise on the blow-up dynamics in both multiplicative and additive noise settings and obtain profiles and rates of the blow-up solutions. Our findings conclude that the blow-up parameters (rate and profile) are insensitive to the type or strength of the noise: if blow up happens, it has the same dynamics as in the deterministic setting; however, there is a (random) shift of the blow-up centre, which can be described as a random variable normally distributed.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "noise",
        "blow",
        "solutions",
        "space-time white noise",
        "multiplicative and additive noise settings",
        "profiles",
        "deterministic setting",
        "rates",
        "stochastic setting",
        "L^2$-norm",
        "additive case",
        "deterministic case",
        "energy",
        "blow up"
      ]
    },
    "org": {
      "title": "Shape of Traveling Densities with Extremum Statistical Complexity",
      "url": "https://www.semanticscholar.org/paper/1b878f7b671795401ceee38a772cd9135d93b761",
      "abstract": "In this paper, we analyze the behavior of statistical complexity in several systems where two identical densities that travel in opposite direction cross each other. Besides the crossing between two Gaussian, rectangular and triangular densities studied in a previous work, we also investigate in detail the crossing between two exponential and two gamma distributions. For all these cases, the shape of the total density presenting an extreme value in complexity is found.",
      "fieldsOfStudy": [
        "Mathematics",
        "Physics",
        "Computer Science"
      ],
      "topics": [
        "opposite direction",
        "statistical complexity",
        "systems",
        "complexity",
        "detail",
        "gamma distributions",
        "identical densities",
        "total density",
        "previous work",
        "extreme value",
        "Gaussian, rectangular and triangular densities",
        "crossing",
        "exponential",
        "behavior",
        "shape",
        "Gaussian",
        "exponential and two gamma distributions"
      ]
    }
  },
  {
    "sim": 0.5476660650660626,
    "gen": {
      "title": "A Survey of Numerical Methods Utilizing Mixed Precision Arithmetic",
      "url": "https://www.semanticscholar.org/paper/52990ce6963e8189b4768eacba4281d96f6e49d4",
      "abstract": "Within the past years, hardware vendors have started designing low precision special function units in response to the demand of the Machine Learning community and their demand for high compute power in low precision formats. Also the server-line products are increasingly featuring low-precision special function units, such as the NVIDIA tensor cores in ORNL's Summit supercomputer providing more than an order of magnitude higher performance than what is available in IEEE double precision. At the same time, the gap between the compute power on the one hand and the memory bandwidth on the other hand keeps increasing, making data access and communication prohibitively expensive compared to arithmetic operations. To start the multiprecision focus effort, we survey the numerical linear algebra community and summarize all existing multiprecision knowledge, expertise, and software capabilities in this landscape analysis report. We also include current efforts and preliminary results that may not yet be considered \"mature technology,\" but have the potential to grow into production quality within the multiprecision focus effort. As we expect the reader to be familiar with the basics of numerical linear algebra, we refrain from providing a detailed background on the algorithms themselves but focus on how mixed- and multiprecision technology can help improving the performance of these methods and present highlights of application significantly outperforming the traditional fixed precision methods.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "low precision formats",
        "IEEE double precision",
        "magnitude higher performance",
        "high compute power",
        "low-precision special function units",
        "numerical linear algebra",
        "arithmetic operations",
        "traditional fixed precision methods",
        "present highlights",
        "application",
        "production quality",
        "data access",
        "current efforts",
        "software capabilities",
        "Machine Learning",
        "highlights"
      ]
    },
    "org": {
      "title": "A Data Driven Approach to Learning The Hamiltonian Matrix in Quantum Mechanics",
      "url": "https://www.semanticscholar.org/paper/a25a02ab7ee0d2969b3c8824a04a3d28a9064131",
      "abstract": "We present a new machine learning technique which calculates a real-valued, time independent, finite dimensional Hamiltonian matrix from only experimental data. A novel cost function is given along with a proof that the cost function has the theoretically correct Hamiltonian as a global minimum. We present results based on data simulated on a classical computer and results based on simulations of quantum systems on IBM's ibmqx2 quantum computer. We conclude with a discussion on the limitations of this data driven framework, as well as several possible extensions of this work. We also note that algorithm presented in this article not only serves as an example of using domain knowledge to design a machine learning framework, but also as an example of using domain knowledge to improve the speed of such algorithm.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics"
      ],
      "topics": [
        "quantum systems",
        "quantum",
        "IBMs ibmqx2 quantum computer",
        "data",
        "results",
        "domain knowledge",
        "algorithm",
        "IBM",
        "ibmqx2",
        "simulations",
        "algorithm",
        "possible extensions",
        "classical computer",
        "experimental data",
        "machine learning framework",
        "new machine learning technique"
      ]
    }
  },
  {
    "sim": 0.5297132282847519,
    "gen": {
      "title": "Differentially Private Confidence Intervals",
      "url": "https://www.semanticscholar.org/paper/517bd7656447163a901fbd78597b2484a95583d0",
      "abstract": "Confidence intervals for the population mean of normally distributed data are some of the most standard statistical outputs one might want from a database. In this work we give practical differentially private algorithms for this task. We provide five algorithms and then compare them to each other and to prior work. We give concrete, experimental analysis of their accuracy and find that our algorithms provide much more accurate confidence intervals than prior work. For example, in one setting (with {\\epsilon} = 0.1 and n = 2782) our algorithm yields an interval that is only 1/15th the size of the standard set by prior work.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "prior work",
        "Confidence intervals",
        "practical differentially private algorithms",
        "experimental analysis",
        "work",
        "algorithms",
        "algorithms",
        "accurate confidence intervals",
        "concrete",
        "database",
        "\\epsilon",
        "standard statistical outputs",
        "normally distributed data",
        "task",
        "concrete, experimental analysis",
        "interval"
      ]
    },
    "org": {
      "title": "Aggregating Votes with Local Differential Privacy: Usefulness, Soundness vs. Indistinguishability",
      "url": "https://www.semanticscholar.org/paper/aadb68f0e87801ce3845f3f2a0f4eb9c401847df",
      "abstract": "Voting plays a central role in bringing crowd wisdom to collective decision making, meanwhile data privacy has been a common ethical/legal issue in eliciting preferences from individuals. This work studies the problem of aggregating individual's voting data under the local differential privacy setting, where usefulness and soundness of the aggregated scores are of major concern. One naive approach to the problem is adding Laplace random noises, however, it makes aggregated scores extremely fragile to new types of strategic behaviors tailored to the local privacy setting: data amplification attack and view disguise attack. The data amplification attack means an attacker's manipulation power is amplified by the privacy-preserving procedure when contributing a fraud vote. The view disguise attack happens when an attacker could disguise malicious data as valid private views to manipulate the voting result. \nIn this work, after theoretically quantifying the estimation error bound and the manipulating risk bound of the Laplace mechanism, we propose two mechanisms improving the usefulness and soundness simultaneously: the weighted sampling mechanism and the additive mechanism. The former one interprets the score vector as probabilistic data. Compared to the Laplace mechanism for Borda voting rule with $d$ candidates, it reduces the mean squared error bound by half and lowers the maximum magnitude risk bound from $+\\infty$ to $O(\\frac{d^3}{n\\epsilon})$. The latter one randomly outputs a subset of candidates according to their total scores. Its mean squared error bound is optimized from $O(\\frac{d^5}{n\\epsilon^2})$ to $O(\\frac{d^4}{n\\epsilon^2})$, and its maximum magnitude risk bound is reduced to $O(\\frac{d^2}{n\\epsilon})$. Experimental results validate that our proposed approaches averagely reduce estimation error by $50\\%$ and are more robust to adversarial attacks.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "data privacy",
        "disguise attack",
        "malicious data",
        "probabilistic data",
        "adversarial attacks",
        "aggregated scores",
        "Borda voting rule",
        "valid private views",
        "The data amplification attack",
        "Voting",
        "local differential privacy setting",
        "individuals voting data",
        "major concern",
        "individuals",
        "view disguise attack",
        "estimation error"
      ]
    }
  },
  {
    "sim": 0.36467201485279355,
    "gen": {
      "title": "Complexity and Stochastic Synchronization in Coupled Map Lattices and Cellular Automata",
      "url": "https://www.semanticscholar.org/paper/e0e2381e14583fe70a3cf688bd2b6cc99516f268",
      "abstract": "Nowadays the question `what is complexity?' is a challenge to be answered. This question is triggering a great quantity of works in the frontier of physics, biology, mathematics and computer science. Even more when this century has been told to be the century of Complexity. Although there seems to be no urgency to answer the above question, many different proposals that have been developed to this respect can be found in the literature. In this context, several articles concerning statistical complexity and stochastic processes are collected in this chapter.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics",
        "Mathematics"
      ],
      "topics": [
        "computer science",
        "different proposals",
        "stochastic processes",
        "statistical complexity",
        "mathematics",
        "biology",
        "physics",
        "articles",
        "Complexity",
        "works",
        "literature",
        "question",
        "chapter",
        "great quantity"
      ]
    },
    "org": {
      "title": "CONVECTION IN OBLATE SOLAR-TYPE STARS",
      "url": "https://www.semanticscholar.org/paper/6702cc217444f69d396befea89abd1e8d75b80b8",
      "abstract": "We present the first global 3D simulations of thermal convection in the oblate envelopes of rapidly rotating solar-type stars. This has been achieved by exploiting the capabilities of the new compressible high-order unstructured spectral difference (CHORUS) code. We consider rotation rates up to 85% of the critical (breakup) rotation rate, which yields an equatorial radius that is up to 17% larger than the polar radius. This substantial oblateness enhances the disparity between polar and equatorial modes of convection. We find that the convection redistributes the heat flux emitted from the outer surface, leading to an enhancement of the heat flux in the polar and equatorial regions. This finding implies that lower-mass stars with convective envelopes may not have darker equators as predicted by classical gravity darkening arguments. The vigorous high-latitude convection also establishes elongated axisymmetric circulation cells and zonal jets in the polar regions. Though the overall amplitude of the surface differential rotation, \u0394\u03a9, is insensitive to the oblateness, the oblateness does limit the fractional kinetic energy contained in the differential rotation to no more than 61%. Furthermore, we argue that this level of differential rotation is not enough to have a significant impact on the oblateness of the star.",
      "fieldsOfStudy": [
        "Physics",
        "Computer Science"
      ],
      "topics": [
        "classical gravity darkening arguments",
        "rotation rates",
        "differential rotation",
        "convective envelopes",
        "thermal convection",
        "convection",
        "elongated axisymmetric circulation cells",
        "darker equators",
        "polar and equatorial modes",
        "zonal jets",
        "polar radius",
        "polar regions",
        "polar and equatorial regions",
        "equatorial radius",
        "surface differential rotation"
      ]
    }
  },
  {
    "sim": 0.7158396588266438,
    "gen": {
      "title": "Google\u2019s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation",
      "url": "https://www.semanticscholar.org/paper/a486e2839291111bb44fa1f07731ada123539f75",
      "abstract": "We propose a simple solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages. Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language. Using a shared wordpiece vocabulary, our approach enables Multilingual NMT systems using a single model. On the WMT\u201914 benchmarks, a single multilingual model achieves comparable performance for English\u2192French and surpasses state-of-theart results for English\u2192German. Similarly, a single multilingual model surpasses state-of-the-art results for French\u2192English and German\u2192English on WMT\u201914 and WMT\u201915 benchmarks, respectively. On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs. Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation. Finally, we show analyses that hints at a universal interlingua representation in our models and also show some interesting examples when mixing languages.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "language pairs",
        "individual pairs",
        "better translation",
        "multiple languages",
        "languages",
        "multilingual models",
        "training",
        "Multilingual NMT",
        "required target language",
        "single multilingual model",
        "Neural Machine Translation",
        "single model",
        "comparable performance",
        "neural translation",
        "Multilingual NMT systems",
        "transfer learning",
        "zero-shot translation"
      ]
    },
    "org": {
      "title": "Word Ordering Without Syntax",
      "url": "https://www.semanticscholar.org/paper/7b5af1758963babf3740a39615b469b70513a413",
      "abstract": "Recent work on word ordering has argued that syntactic structure is important, or even required, for effectively recovering the order of a sentence. We find that, in fact, an n-gram language model with a simple heuristic gives strong results on this task. Furthermore, we show that a long short-term memory (LSTM) language model is even more effective at recovering order, with our basic model outperforming a state-of-the-art syntactic model by 11.5 BLEU points. Additional data and larger beams yield further gains, at the expense of training and search time.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "recovering order",
        "search time",
        "syntactic structure",
        "strong results",
        "gains",
        "basic model",
        "BLEU",
        "training",
        "larger beams",
        "word ordering",
        "n-gram language model",
        "11.5 BLEU points",
        "Additional data",
        "Recent work",
        "task",
        "order",
        "training and search time",
        "LSTM",
        "simple heuristic"
      ]
    }
  },
  {
    "sim": 0.6503303277165665,
    "gen": {
      "title": "A convergent evolving finite element algorithm for mean curvature flow of closed surfaces",
      "url": "https://www.semanticscholar.org/paper/d814154797d8a34eb85e02006c50167e89ceff34",
      "abstract": null,
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ]
    },
    "org": {
      "title": "A Hybrid High-Order method for creeping flows of non-Newtonian fluids",
      "url": "https://www.semanticscholar.org/paper/620c84af8a40e71dda7a23abb0bf7b0088c4c836",
      "abstract": "In this paper, we design and analyze a Hybrid High-Order discretization method for the steady motion of non-Newtonian, incompressible fluids in the Stokes approximation of small velocities. The proposed method has several appealing features including the support of general meshes and high-order, unconditional inf-sup stability, and orders of convergence that match those obtained for scalar Leray\u2013Lions problems. A complete well-posedness and convergence analysis of the method is carried out under new, general assumptions on the strain rate-shear stress law, which encompass several common examples such as the power-law and Carreau\u2013Yasuda models. Numerical examples complete the exposition.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "small velocities",
        "common examples",
        "general meshes",
        "appealing features",
        "orders",
        "non-Newtonian",
        "convergence",
        "non-Newtonian, incompressible fluids",
        "Numerical examples",
        "Stokes",
        "Carreau",
        "Leray",
        "unconditional inf-sup stability",
        "Hybrid High-Order discretization method",
        "strain rate-shear stress law",
        "Yasuda models",
        "Lions problems"
      ]
    }
  },
  {
    "sim": 0.5924206965112312,
    "gen": {
      "title": "Bayesian approach with prior models which enforce sparsity in signal and image processing",
      "url": "https://www.semanticscholar.org/paper/7f282222c98619ba6bed58eb0856494dc7b7809d",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ]
    },
    "org": {
      "title": "Robust 3D Reconstruction of Dynamic Scenes From Single-Photon Lidar Using Beta-Divergences",
      "url": "https://www.semanticscholar.org/paper/19c3796656490c07db453f3a7b5cde52becc069b",
      "abstract": "In this article, we present a new algorithm for fast, online 3D reconstruction of dynamic scenes using times of arrival of photons recorded by single-photon detector arrays. One of the main challenges in 3D imaging using single-photon lidar in practical applications is the presence of strong ambient illumination which corrupts the data and can jeopardize the detection of peaks/surface in the signals. This background noise not only complicates the observation model classically used for 3D reconstruction but also the estimation procedure which requires iterative methods. In this work, we consider a new similarity measure for robust depth estimation, which allows us to use a simple observation model and a non-iterative estimation procedure while being robust to mis-specification of the background illumination model. This choice leads to a computationally attractive depth estimation procedure without significant degradation of the reconstruction performance. This new depth estimation procedure is coupled with a spatio-temporal model to capture the natural correlation between neighboring pixels and successive frames for dynamic scene analysis. The resulting online inference process is scalable and well suited for parallel implementation. The benefits of the proposed method are demonstrated through a series of experiments conducted with simulated and real single-photon lidar videos, allowing the analysis of dynamic scenes at 325 m observed under extreme ambient illumination conditions.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics",
        "Medicine",
        "Engineering"
      ],
      "topics": [
        "dynamic scene analysis",
        "extreme ambient illumination conditions",
        "dynamic scenes",
        "strong ambient illumination",
        "robust depth estimation",
        "photons",
        "3D reconstruction",
        "iterative methods",
        "successive frames",
        "non-iterative estimation procedure",
        "parallel implementation",
        "neighboring pixels",
        "single-photon lidar",
        "single-photon detector",
        "practical applications",
        "single-photon detector arrays"
      ]
    }
  },
  null,
  {
    "sim": 0.4179182237329072,
    "gen": {
      "title": "Explaining Deep Convolutional Neural Networks on Music Classification",
      "url": "https://www.semanticscholar.org/paper/ab5492458cf4e75106f35f8cdee3cfe54dec7872",
      "abstract": "Deep convolutional neural networks (CNNs) have been actively adopted in the field of music information retrieval, e.g. genre classification, mood detection, and chord recognition. However, the process of learning and prediction is little understood, particularly when it is applied to spectrograms. We introduce auralisation of a CNN to understand its underlying mechanism, which is based on a deconvolution procedure introduced in [2]. Auralisation of a CNN is converting the learned convolutional features that are obtained from deconvolution into audio signals. In the experiments and discussions, we explain trained features of a 5-layer CNN based on the deconvolved spectrograms and auralised signals. The pairwise correlations per layers with varying different musical attributes are also investigated to understand the evolution of the learnt features. It is shown that in the deep layers, the features are learnt to capture textures, the patterns of continuous distributions, rather than shapes of lines.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "audio signals",
        "signals",
        "chord recognition",
        "trained features",
        "e.g. genre classification",
        "mood detection",
        "music information retrieval",
        "lines",
        "continuous distributions",
        "spectrograms",
        "different musical attributes",
        "deconvolution",
        "CNN",
        "Deep convolutional neural networks",
        "shapes",
        "auralised signals",
        "varying different musical attributes",
        "learned convolutional features",
        "layers"
      ]
    },
    "org": {
      "title": "Learning Individualized Cardiovascular Responses from Large-scale Wearable Sensors Data",
      "url": "https://www.semanticscholar.org/paper/dcc2af6735a52f6360d6abcec836d3bed28968ee",
      "abstract": "We consider the problem of modeling cardiovascular responses to physical activity and sleep changes captured by wearable sensors in free living conditions. We use an attentional convolutional neural network to learn parsimonious signatures of individual cardiovascular response from data recorded at the minute level resolution over several months on a cohort of 80k people. We demonstrate internal validity by showing that signatures generated on an individual's 2017 data generalize to predict minute-level heart rate from physical activity and sleep for the same individual in 2018, outperforming several time-series forecasting baselines. We also show external validity demonstrating that signatures outperform plain resting heart rate (RHR) in predicting variables associated with cardiovascular functions, such as age and Body Mass Index (BMI). We believe that the computed cardiovascular signatures have utility in monitoring cardiovascular health over time, including detecting abnormalities and quantifying recovery from acute events.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "individual cardiovascular response",
        "cardiovascular responses",
        "free living conditions",
        "cardiovascular functions",
        "cardiovascular health",
        "acute events",
        "80k people",
        "plain resting heart rate",
        "Body Mass Index",
        "physical activity",
        "parsimonious signatures",
        "months",
        "BMI",
        "sleep changes",
        "quantifying recovery",
        "wearable sensors",
        "signatures"
      ]
    }
  },
  {
    "sim": 0.34923593104646233,
    "gen": {
      "title": "Many hard examples for resolution",
      "url": "https://www.semanticscholar.org/paper/9507f4ab47833b61d3b2cfca436245c4608ffebd",
      "abstract": "For every choice of positive integers <italic>c</italic> and <italic>k</italic> such that <italic>k</italic> \u2265 3 and <italic>c</italic>2<supscrpt>-<italic>k</italic></supscrpt> \u2265 0.7, there is a positive number \u03b5 such that, with probability tending to 1 as <italic>n</italic> tends to \u221e, a randomly chosen family of <italic>cn</italic> clauses of size <italic>k</italic> over <italic>n</italic> variables is unsatisfiable, but every resolution proof of its unsatisfiability must generate at least (1 + \u03b5)<supscrpt><italic>n</italic></supscrpt> clauses.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "italic>n</italic> variables",
        "n</italic",
        "size",
        "positive integers",
        "<italic>cn</italic> clauses",
        "k</italic></supscrpt",
        "<italic>c</italic",
        "probability",
        "positive number \u03b5",
        "resolution proof",
        "unsatisfiability",
        "positive number",
        "(1 + \u03b5)<supscrpt><italic>n</italic></supscrpt> clauses",
        "randomly chosen family",
        "<italic>n</italic> variables",
        "choice",
        "0.7"
      ]
    },
    "org": {
      "title": "Verified Uncertainty Calibration",
      "url": "https://www.semanticscholar.org/paper/b8333963567e9ef65c059466c03b0fbee3eaec6a",
      "abstract": "Applications such as weather forecasting and personalized medicine demand models that output calibrated probability estimates---those representative of the true likelihood of a prediction. Most models are not calibrated out of the box but are recalibrated by post-processing model outputs. We find in this work that popular recalibration methods like Platt scaling and temperature scaling are (i) less calibrated than reported, and (ii) current techniques cannot estimate how miscalibrated they are. An alternative method, histogram binning, has measurable calibration error but is sample inefficient---it requires $O(B/\\epsilon^2)$ samples, compared to $O(1/\\epsilon^2)$ for scaling methods, where $B$ is the number of distinct probabilities the model can output. To get the best of both worlds, we introduce the scaling-binning calibrator, which first fits a parametric function to reduce variance and then bins the function values to actually ensure calibration. This requires only $O(1/\\epsilon^2 + B)$ samples. Next, we show that we can estimate a model's calibration error more accurately using an estimator from the meteorological community---or equivalently measure its calibration error with fewer samples ($O(\\sqrt{B})$ instead of $O(B)$). We validate our approach with multiclass calibration experiments on CIFAR-10 and ImageNet, where we obtain a 35% lower calibration error than histogram binning and, unlike scaling methods, guarantees on true calibration. In these experiments, we also estimate the calibration error and ECE more accurately than the commonly used plugin estimators. We implement all these methods in a Python library: this https URL",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "measurable calibration error",
        "calibration",
        "multiclass calibration experiments",
        "fewer samples",
        "scaling methods",
        "post-processing model outputs",
        "temperature scaling",
        "Platt scaling",
        "personalized medicine demand models",
        "calibration error",
        "probability estimates",
        "Most models",
        "distinct probabilities",
        "calibrated probability estimates",
        "models",
        "popular recalibration methods",
        "histogram binning"
      ]
    }
  },
  null,
  {
    "sim": 0.35658138501134606,
    "gen": {
      "title": "A Quantitative Approach to Understanding Online Antisemitism",
      "url": "https://www.semanticscholar.org/paper/eb904ebf1ef099059cde665e421031d76623403b",
      "abstract": "A new wave of growing antisemitism, driven by fringe Web communities, is an increasingly worrying presence in the socio-political realm. The ubiquitous and global nature of the Web has provided tools used by these groups to spread their ideology to the rest of the Internet. Although the study of antisemitism and hate is not new, the scale and rate of change of online data has impacted the efficacy of traditional approaches to measure and understand these troubling trends.In this paper, we present a large-scale, quantitative study of online antisemitism. We collect hundreds of million posts and images from alt-right Web communities like 4chan's Politically Incorrect board (/pol/) and Gab. Using scientifically grounded methods, we quantify the escalation and spread of antisemitic memes and rhetoric across the Web. We find the frequency of antisemitic content greatly increases (in some cases more than doubling) after major political events such as the 2016 US Presidential Election and the \u201cUnite the Right\u201d rally in Charlottesville. We extract semantic embeddings from our corpus of posts and demonstrate how automated techniques can discover and categorize the use of antisemitic terminology. We additionally examine the prevalence and spread of the antisemitic \u201cHappy Merchant\u201d meme, and in particular how these fringe communities influence its propagation to more mainstream communities like Twitter and Reddit. Taken together, our results provide a data-driven, quantitative framework for understanding online antisemitism. Our methods serve as a framework to augment current qualitative efforts by anti-hate groups, providing new insights into the growth and spread of hate online.",
      "fieldsOfStudy": [
        "Computer Science",
        "Sociology"
      ],
      "topics": [
        "major political events",
        "antisemitic memes",
        "US Presidential Election",
        "antisemitic terminology",
        "online data",
        "anti-hate groups",
        "growing antisemitism",
        "antisemitic content",
        "antisemitism",
        "alt-right Web communities",
        "traditional approaches",
        "Gab",
        "new insights",
        "fringe Web communities",
        "mainstream communities",
        "Charlottesville",
        "Politically Incorrect board"
      ]
    },
    "org": {
      "title": "Spatial Indexing of Large Multidimensional Databases",
      "url": "https://www.semanticscholar.org/paper/48240f84da39c6a4a10b91a51436f7ccc1d3a4b7",
      "abstract": "Scientific endeavors such as large astronomical surveys generate databases on the terabyte scale. These, usually multidimensional databases must be visualized and mined in order to find interesting objects or to extract meaningful and qualitatively new relationships. Many statistical algorithms required for these tasks run reasonably fast when operating on small sets of in-memory data, but take noticeable performance hits when operating on large databases that do not fit into memory. We utilize new software technologies to develop and evaluate fast multidimensional indexing schemes that inherently follow the underlying, highly non-uniform distribution of the data: they are layered uniform grid indices, hierarchical binary space partitioning, and sampled flat Voronoi tessellation of the data. Our working database is the 5-dimensional magnitude space of the Sloan Digital Sky Survey with more than 270 million data points, where we show that these techniques can dramatically speed up data mining operations such as finding similar objects by example, classifying objects or comparing extensive simulation sets with observations. We are also developing tools to interact with the multidimensional database and visualize the data at multiple resolutions in an adaptive manner.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "data mining operations",
        "large databases",
        "similar objects",
        "noticeable performance hits",
        "interesting objects",
        "extensive simulation sets",
        "layered uniform grid indices",
        "hierarchical binary space partitioning",
        "objects",
        "large astronomical surveys",
        "flat Voronoi tessellation",
        "small sets",
        "databases",
        "memory",
        "fast multidimensional indexing schemes",
        "sampled flat Voronoi tessellation"
      ]
    }
  },
  {
    "sim": 0.3791953525860614,
    "gen": {
      "title": "Deep Learning: An Introduction for Applied Mathematicians",
      "url": "https://www.semanticscholar.org/paper/0f435828343b61570aec9de1473db13f9985bcac",
      "abstract": "Multilayered artificial neural networks are becoming a pervasive tool in a host of application fields. At the heart of this deep learning revolution are familiar concepts from applied and computational mathematics; notably, in calculus, approximation theory, optimization and linear algebra. This article provides a very brief introduction to the basic ideas that underlie deep learning from an applied mathematics perspective. Our target audience includes postgraduate and final year undergraduate students in mathematics who are keen to learn about the area. The article may also be useful for instructors in mathematics who wish to enliven their classes with references to the application of deep learning techniques. We focus on three fundamental questions: what is a deep neural network? how is a network trained? what is the stochastic gradient method? We illustrate the ideas with a short MATLAB code that sets up and trains a network. We also show the use of state-of-the art software on a large scale image classification problem. We finish with references to the current literature.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "deep learning techniques",
        "application fields",
        "deep learning",
        "mathematics",
        "Multilayered artificial neural networks",
        "approximation theory",
        "familiar concepts",
        "deep neural network",
        "linear",
        "large scale image classification problem",
        "optimization and linear algebra",
        "applied and computational mathematics",
        "applied mathematics perspective",
        "deep learning revolution",
        "calculus",
        "linear algebra",
        "optimization"
      ]
    },
    "org": {
      "title": "Possibility results for graph clustering: A novel consistency axiom",
      "url": "https://www.semanticscholar.org/paper/4264babefd357712fcca9895278da949a97dd95d",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ]
    }
  },
  {
    "sim": 0.4802354711308001,
    "gen": {
      "title": "ALE moving mesh generation and high performance implementation using OpenMP and MPI Libraries for FSI and Darcy flow problems",
      "url": "https://www.semanticscholar.org/paper/7efe80d868b5538962b0cc0742a5b5da8998d36b",
      "abstract": "A high performance algorithm for the implementation of Arbitrary Lagrangian and Eulerian (ALE) moving mesh scheme for both 2D and 3D Fluid Structure Interaction (FSI) problems for the shared and distributed memory systems is discussed in the thesis. OpenMP library is used to implement parallel programs on shared memory systems whereas message passing interface (MPI) is employed to write parallel programs on distributed memory systems.Moving mesh techniques are the integral part of a wider class of fluid mechanics problems that involve moving and deforming spatial domains, namely, free-surface flows and FSI.The moving mesh technique adopted in this work is based on the notion of nodes relocation, subjected to certain evolution as well as constraint conditions.A conjugate gradient method augmented with a preconditioning is employed for the solution of the resulting system of equations.The proposed algorithm, firstly, reorders and partitions the mesh using an efficient divide and conquer approach and then parallelizes the ALE moving mesh.Different mesh partitioning algorithms are discussed, which include the octree method, and k-way graph partitioning technique using Parmetis library.Numerical simulations are conducted on AMD Opteron and Intel Xeon processors, and unstructured triangular and tetrahedral meshes are used for the 2D and 3D problems. The better results, in terms of the speedup, are obtained for the shared memory system than the distributed memory system for both the 2D and 3D problems.The quality of meshes is checked by comparing the element Jacobians in the reference and current meshes, and by keeping track of the change in the interior angles in triangles and tetrahedrons.The proposed parallel mesh reordering algorithm using sampling approach for work load re-distribution concluded 51% of average efficiency in term of the speedup for shared memory systems.The overall maximum speedup of 6.37, for the shared memory system, is achieved using eight processing elements (PEs) as compared to 4.11 for the distributed memory system including twelve PEs. As a case study, the thesis also discusses the high performance implementation of a stabilized mixed finite element method for Darcy flow using MPI library. It has a lot of practical applications in the field of petroleum engineering and earth sciences especially, where the flow of fluid is of interest in a permeable porous medium. The maximum speedup of 12.24 is achieved using 28 PEs by incorporating the proposed mesh partitioning algorithm.Outline Chapter 1 defines and introduces the problem statement and Chapter 2 gives the general introduction of the thesis.Chapter 3 presents the literature review of ALE moving mesh generation, stabilized mixed finite element methods, k-way graph partitioning algorithm and tree based spatial data structures.Chapter 4 mathematically formulates the ALE mesh generation problem and presents the serial algorithm for optimization using the preconditioned conjugate gradient method.Chapter 5 presents a mesh reordering algorithm based on quadtree/octree and quick sort techniques.Chapter 6 discusses the parallelization part of mesh reordering algorithm based on a sampling approach and also discusses the experimental results for the shared memory systems.Detailed discussion about the mesh partitioning and experimental results using MPI are given in Chapter 7. Chapter 8 briefly describes the stabilized finite element method for Darcy Flow and discusses the results of 2D problems for a distributed memory system. Finally, conclusions are drawn in Chapter 9 and future work is presented in Chapter 10. iii",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "distributed memory systems",
        "shared memory systems",
        "FSI.The moving mesh technique",
        "mesh techniques",
        "Different mesh partitioning algorithms",
        "mesh generation",
        "tetrahedral meshes",
        "meshes",
        "current meshes",
        "mesh scheme",
        "2D problems",
        "fluid mechanics problems",
        "mixed finite element methods",
        "reordering algorithm",
        "moving mesh technique",
        "mesh reordering algorithm",
        "ALE moving mesh generation",
        "stabilized mixed finite element methods",
        "distributed memory system"
      ]
    },
    "org": {
      "title": "Best practices for HPM-assisted performance engineering on modern multicore processors",
      "url": "https://www.semanticscholar.org/paper/1b2bdbae8451cbb56be2649aba3c818b6d0eb16a",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  {
    "sim": 0.6534674647907719,
    "gen": {
      "title": "Forecasting Future Action Sequences with Neural Memory Networks",
      "url": "https://www.semanticscholar.org/paper/ac1fb5af794f4fbe32c2ce2975706876aff9f194",
      "abstract": "We propose a novel neural memory network based framework for future action sequence forecasting. This is a challenging task where we have to consider short-term, within sequence relationships as well as relationships in between sequences, to understand how sequences of actions evolve over time. To capture these relationships effectively, we introduce neural memory networks to our modelling scheme. We show the significance of using two input streams, the observed frames and the corresponding action labels, which provide different information cues for our prediction task. Furthermore, through the proposed method we effectively map the long-term relationships among individual input sequences through separate memory modules, which enables better fusion of the salient features. Our method outperforms the state-of-the-art approaches by a large margin on two publicly available datasets: Breakfast and 50 Salads.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "sequence relationships",
        "future action sequence forecasting",
        "individual input sequences",
        "sequences",
        "different information cues",
        "separate memory modules",
        "neural memory networks",
        "relationships",
        "actions",
        "better fusion",
        "time",
        "novel neural memory network based framework",
        "corresponding action labels",
        "Breakfast",
        "prediction task"
      ]
    },
    "org": {
      "title": "A Causal View on Robustness of Neural Networks",
      "url": "https://www.semanticscholar.org/paper/1a6adb28532afd81b32bf5b9e0af23bb3a4f0dc8",
      "abstract": "We present a causal view on the robustness of neural networks against input manipulations, which applies not only to traditional classification tasks but also to general measurement data. Based on this view, we design a deep causal manipulation augmented model (deep CAMA) which explicitly models possible manipulations on certain causes leading to changes in the observed effect. We further develop data augmentation and test-time fine-tuning methods to improve deep CAMA's robustness. When compared with discriminative deep neural networks, our proposed model shows superior robustness against unseen manipulations. As a by-product, our model achieves disentangled representation which separates the representation of manipulations from those of other latent causes.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "unseen manipulations",
        "possible manipulations",
        "manipulations",
        "general measurement data",
        "latent causes",
        "certain causes",
        "discriminative deep neural networks",
        "traditional classification tasks",
        "superior robustness",
        "deep causal manipulation augmented model",
        "neural networks",
        "changes",
        "disentangled representation",
        "CAMA",
        "deep CAMA"
      ]
    }
  },
  {
    "sim": 0.45318632762054123,
    "gen": {
      "title": "Manifold-Constrained Geometric Optimization via Local Parameterizations",
      "url": "https://www.semanticscholar.org/paper/3711fdb446c1dd2c36a9a1c6fd7877ee2021f318",
      "abstract": "Many geometric optimization problems contain manifold constraints that restrict the optimized vertices on some specified manifold surface. The constraints are highly nonlinear and non-convex, therefore existing methods usually suffer from a breach of condition or low optimization quality. In this article, we present a novel divide-and-conquer methodology for manifold-constrained geometric optimization problems. Central to our methodology is to use local parameterizations to decouple the optimization with hard constraints, which transforms nonlinear constraints into linear constraints. We decompose the input mesh into a set of developable or nearly-developable overlapping patches with disc topology, then flatten each patch into the planar domain with very low isometric distortion, optimize vertices with linear constraints and recover the patch. Finally, we project it onto the constrained manifold surface. We demonstrate the applicability and robustness of our methodology through a variety of geometric optimization tasks. Experimental results show that our method performs much better than existing methods.",
      "fieldsOfStudy": [
        "Medicine"
      ],
      "topics": [
        "manifold constraints",
        "nonlinear constraints",
        "low optimization quality",
        "hard constraints",
        "manifold surface",
        "existing methods",
        "geometric optimization tasks",
        "vertices",
        "manifold-constrained geometric optimization problems",
        "linear",
        "disc topology",
        "specified manifold surface",
        "constrained manifold surface",
        "low isometric distortion",
        "condition"
      ]
    },
    "org": {
      "title": "Monolithic Multigrid for Magnetohydrodynamics",
      "url": "https://www.semanticscholar.org/paper/4aab10e736392cdb82429d2693955f367d81bcae",
      "abstract": "The magnetohydrodynamics (MHD) equations model a wide range of plasma physics applications and are characterized by a nonlinear system of partial differential equations that strongly couples a charged fluid with the evolution of electromagnetic fields. After discretization and linearization, the resulting system of equations is generally difficult to solve due to the coupling between variables, and the heterogeneous coefficients induced by the linearization process. In this paper, we investigate multigrid preconditioners for this system based on specialized relaxation schemes that properly address the system structure and coupling. Three extensions of Vanka relaxation are proposed and applied to problems with up to 170 million degrees of freedom and fluid and magnetic Reynolds numbers up to 400 for stationary problems and up to 20,000 for time-dependent problems.",
      "fieldsOfStudy": [
        "Physics",
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "stationary problems",
        "problems",
        "Reynolds numbers",
        "partial differential equations",
        "electromagnetic fields",
        "time-dependent problems",
        "coupling",
        "plasma physics applications",
        "equations",
        "specialized relaxation schemes",
        "linearization",
        "Reynolds",
        "freedom",
        "plasma physics",
        "variables",
        "fluid and magnetic Reynolds numbers",
        "Vanka relaxation",
        "nonlinear system"
      ]
    }
  },
  null,
  {
    "sim": 0.7753120370382159,
    "gen": {
      "title": "Repairing Multiple Failures with Coordinated and Adaptive Regenerating Codes",
      "url": "https://www.semanticscholar.org/paper/a654577eba049385d7c9dba6cac4b243476c2803",
      "abstract": "Erasure correcting codes are widely used to ensure data persistence in distributed storage systems. This paper addresses the simultaneous repair of multiple failure in such codes. We go beyond existing work (i.e., regenerating codes by Dimakis et al.) and propose coordinated regenerating codes allowing devices to coordinate during simultaneous repairs thus further reducing the costs. We define optimal coordinated regenerating codes outperforming existing codes for simultaneous repairs with respect to both storage and repair costs. We prove that deliberately delaying repairs does not bring additional gains (i.e., regenerating codes are optimal as long as each failure can be repaired before a second one occurs). Finally, we propose adaptive regenerating codes that self-adapt to the system state and prove they are optimal.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "coordinated regenerating codes",
        "codes",
        "existing codes",
        "correcting codes",
        "simultaneous repairs",
        "distributed storage systems",
        "repairs",
        "multiple failure",
        "additional gains",
        ", regenerating codes",
        "data persistence",
        "second",
        "existing work",
        "adaptive regenerating codes",
        "Erasure correcting codes"
      ]
    },
    "org": {
      "title": "High-rate regenerating codes through layering",
      "url": "https://www.semanticscholar.org/paper/01a2aea9a1a35cd77b8aeb298d7e0fbdc57474e0",
      "abstract": "In this paper, we provide explicit constructions for a class of exact-repair regenerating codes that possess a layered structure. These regenerating codes correspond to interior points on the storage-repair-bandwidth tradeoff where the cut-set bound of network coding is known to be not achievable under exact repair. The codes presented in this paper compare very well in comparison to schemes that employ space-sharing between MSR and MBR points, and come closest of all-known explicit constructions to interior points of the tradeoff. The codes can be constructed for a wide range of parameters, are high-rate, can repair multiple nodes simultaneously and no computation at helper nodes is required to repair a failed node. We also construct optimal codes with locality in which the local codes are layered regenerating codes.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "helper nodes",
        "multiple nodes",
        "exact repair",
        "optimal codes",
        "interior points",
        "network coding",
        "exact-repair regenerating codes",
        "explicit constructions",
        "failed node",
        "MSR and MBR points",
        "MBR",
        "local codes",
        "MSR",
        "layered structure",
        "These regenerating codes",
        "layered regenerating codes",
        "storage-repair-bandwidth tradeoff",
        "all-known explicit constructions"
      ]
    }
  },
  {
    "sim": 0.5514498682910387,
    "gen": {
      "title": "Unsupervised Neural Universal Denoiser for Finite-Input General-Output Noisy Channel",
      "url": "https://www.semanticscholar.org/paper/0b3e4e7de1387178590a89e424c20062acc86b90",
      "abstract": "We devise a novel neural network-based universal denoiser for the finite-input, general-output (FIGO) channel. Based on the assumption of known noisy channel densities, which is realistic in many practical scenarios, we train the network such that it can denoise as well as the best sliding window denoiser for any given underlying clean source data. Our algorithm, dubbed as Generalized CUDE (Gen-CUDE), enjoys several desirable properties; it can be trained in an unsupervised manner (solely based on the noisy observation data), has much smaller computational complexity compared to the previously developed universal denoiser for the same setting, and has much tighter upper bound on the denoising performance, which is obtained by a theoretical analysis. In our experiments, we show such tighter upper bound is also realized in practice by showing that Gen-CUDE achieves much better denoising results compared to other strong baselines for both synthetic and real underlying clean sequences.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "known noisy channel densities",
        "practical scenarios",
        "given underlying clean source data",
        "strong baselines",
        "desirable properties",
        "Generalized CUDE",
        "noisy observation data",
        "smaller computational complexity",
        "novel neural network-based universal denoiser",
        "synthetic and real underlying clean sequences",
        "practice",
        "previously developed universal denoiser",
        "better denoising results",
        "theoretical analysis",
        "Gen-CUDE",
        "tighter upper bound"
      ]
    },
    "org": {
      "title": "Adaptive Mixture Regression Network with Local Counting Map for Crowd Counting",
      "url": "https://www.semanticscholar.org/paper/f11578d0b2010186da6dd4eebc164594a57ce602",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  {
    "sim": 0.3474285768059733,
    "gen": {
      "title": "Composing Inference Algorithms as Program Transformations",
      "url": "https://www.semanticscholar.org/paper/f0e14eeadd6aa44ca73020a0a8ac442b05f737e2",
      "abstract": "Probabilistic inference procedures are usually coded painstakingly from scratch, for each target model and each inference algorithm. We reduce this effort by generating inference procedures from models automatically. We make this code generation modular by decomposing inference algorithms into reusable program-to-program transformations. These transformations perform exact inference as well as generate probabilistic programs that compute expectations, densities, and MCMC samples. The resulting inference procedures are about as accurate and fast as other probabilistic programming systems on real-world problems.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "Probabilistic inference procedures",
        "inference algorithms",
        "probabilistic programs",
        "inference procedures",
        "exact inference",
        "MCMC samples",
        "program",
        "probabilistic programming systems",
        "models",
        "MCMC",
        "densities",
        "The resulting inference procedures",
        "expectations",
        "real-world problems",
        "scratch",
        "inference algorithm"
      ]
    },
    "org": {
      "title": "View selection in multi-view stacking: Choosing the meta-learner",
      "url": "https://www.semanticscholar.org/paper/f1c8106672cb452429ec03d1617b39bca9916ec5",
      "abstract": "Multi-view stacking is a framework for combining information from different views (i.e. different feature sets) describing the same set of objects. In this framework, a base-learner algorithm is trained on each view separately, and their predictions are then combined by a meta-learner algorithm. In a previous study, stacked penalized logistic regression, a special case of multi-view stacking, has been shown to be useful in identifying which views are most important for prediction. In this article we expand this research by considering seven different algorithms to use as the meta-learner, and evaluating their view selection and classification performance in simulations and two applications on real gene-expression data sets. Our results suggest that if both view selection and classification accuracy are important to the research at hand, then the nonnegative lasso, nonnegative adaptive lasso and nonnegative elastic net are suitable meta-learners. Exactly which among these three is to be preferred depends on the research context. The remaining four meta-learners, namely nonnegative ridge regression, nonnegative forward selection, stability selection and the interpolating predictor, show little advantages in order to be preferred over the other three.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "nonnegative forward selection",
        "different views",
        "nonnegative adaptive lasso",
        "nonnegative elastic net",
        "stability selection",
        "objects",
        "multi-view stacking",
        "real gene-expression data sets",
        "prediction",
        "stacked penalized logistic regression",
        "suitable meta-learners",
        "set",
        "little advantages",
        "nonnegative ridge regression",
        "lasso",
        "suitable meta",
        "learners",
        "meta-learner algorithm",
        "classification accuracy"
      ]
    }
  },
  null,
  {
    "sim": 0.5996482239440614,
    "gen": {
      "title": "Dynamic Compressive Sensing of Time-Varying Signals Via Approximate Message Passing",
      "url": "https://www.semanticscholar.org/paper/cacc16a8ca7a4487ed532eddfd5a3c28413ed9aa",
      "abstract": "In this work the dynamic compressive sensing (CS) problem of recovering sparse, correlated, time-varying signals from sub-Nyquist, non-adaptive, linear measurements is explored from a Bayesian perspective. While there has been a handful of previously proposed Bayesian dynamic CS algorithms in the literature, the ability to perform inference on high-dimensional problems in a computationally efficient manner remains elusive. In response, we propose a probabilistic dynamic CS signal model that captures both amplitude and support correlation structure, and describe an approximate message passing algorithm that performs soft signal estimation and support detection with a computational complexity that is linear in all problem dimensions. The algorithm, DCS-AMP, can perform either causal filtering or non-causal smoothing, and is capable of learning model parameters adaptively from the data through an expectation-maximization learning procedure. We provide numerical evidence that DCS-AMP performs within 3 dB of oracle bounds on synthetic data under a variety of operating conditions. We further describe the result of applying DCS-AMP to two real dynamic CS datasets, as well as a frequency estimation task, to bolster our claim that DCS-AMP is capable of offering state-of-the-art performance and speed on real-world high-dimensional problems.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "sub-Nyquist",
        "soft signal estimation",
        "operating conditions",
        "synthetic data",
        "support detection",
        "model parameters",
        "probabilistic dynamic CS signal model",
        "CS",
        "linear",
        "previously proposed Bayesian dynamic CS algorithms",
        "high-dimensional problems",
        "algorithm",
        "Bayesian",
        "real dynamic CS datasets",
        "oracle bounds",
        "non-causal smoothing",
        "support correlation structure",
        "sub-Nyquist, non-adaptive, linear measurements",
        "real-world high-dimensional problems"
      ]
    },
    "org": {
      "title": "Super Fast Beam Tracking in Phased Antenna Arrays",
      "url": "https://www.semanticscholar.org/paper/2c71bf763bbce559cce945b1bd88eb856a8df3a3",
      "abstract": "The directionality of millimeter-wave (mmWave) communications creates a significant challenge in serving fast-moving mobile terminals on, e.g., high-speed vehicles, trains, and UAVs. This challenge is exacerbated in mmWave systems using analog antenna arrays, because of the inherent non-convexity in the control of the phase shifters. In this paper, we develop a recursive beam tracking algorithm which can simultaneously achieve fast tracking speed, high tracking accuracy, low complexity, and low pilot overhead. In static scenarios, this algorithm converges to the minimum Cram\\'er-Rao lower bound (CRLB) of beam tracking with high probability. In dynamic scenarios, even at SNRs as low as 0dB, our algorithm is capable of tracking a mobile moving at an angular velocity of 10-20 degrees per second, using only 5 pilot symbols per second. If combining with a simple TDMA pilot pattern, this algorithm can track hundreds of high-speed mobiles in 5G configurations. Our simulations show that the tracking performance of this algorithm is much better than several state-of-the-art algorithms. The key analytical tools used in our algorithm design are stochastic approximation and recursive estimation with a control parameter.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "high tracking accuracy",
        "fast tracking speed",
        "low pilot overhead",
        "beam tracking",
        "high probability",
        "second",
        "recursive beam tracking algorithm",
        "low complexity",
        "UAVs",
        "high-speed mobiles",
        "recursive estimation",
        "high-speed vehicles",
        "stochastic approximation",
        "analog antenna",
        "trains",
        "analog antenna arrays",
        "configurations"
      ]
    }
  },
  {
    "sim": 0.5767810649926839,
    "gen": {
      "title": "Fast In-Memory SQL Analytics on Graphs",
      "url": "https://www.semanticscholar.org/paper/4d17f0edabdc932bf2e166e2c44ec7d88506153b",
      "abstract": "We study a class of graph analytics SQL queries, which we call relationship queries. Relationship queries are a wide superset of fixed-length graph reachability queries and of tree pattern queries. Intuitively, it discovers target entities that are reachable from source entities specified by the query. It usually also finds aggregated scores, which correspond to the target entities and are calculated by applying aggregation functions on measure attributes, which are found on the target entities, the source entities and the paths from the sources to the targets. We present real-world OLAP scenarios, where efficient relationship queries are needed. However, row stores, column stores and graph databases are unacceptably slow in such OLAP scenarios. We briefly comment on the straightforward extension of relationship queries that allows accessing arbitrary schemas. \nThe GQ-Fast in-memory analytics engine utilizes a bottom-up fully pipelined query execution model running on a novel data organization that combines salient features of column-based organization, indexing and compression. Furthermore, GQ-Fast compiles its query plans into executable C++ source codes. Besides achieving runtime efficiency, GQ-Fast also reduces main memory requirements because, unlike column databases, GQ-Fast selectively allows more dense forms of compression including heavy-weighted compressions, which do not support random access. \nWe used GQ-Fast to accelerate queries for two OLAP dashboards in the biomedical field. It outperforms Postgres by 2-4 orders of magnitude and outperforms MonetDB and Neo4j by 1-3 orders of magnitude when all of them are running on RAM. In addition, it generally saves space due to the appropriate use of compression methods.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "efficient relationship queries",
        "queries",
        "source entities",
        "target entities",
        "compression methods",
        "random access",
        "executable C++ source codes",
        "compression",
        "column databases",
        "fixed-length graph reachability queries",
        "OLAP scenarios",
        "graph databases",
        "salient features",
        "tree pattern queries",
        "graph analytics SQL queries"
      ]
    },
    "org": {
      "title": "A Zero Attention Model for Personalized Product Search",
      "url": "https://www.semanticscholar.org/paper/fa5d51838022fc8b8a305c78efbc5f61fda90fd3",
      "abstract": "Product search is one of the most popular methods for people to discover and purchase products on e-commerce websites. Because personal preferences often have an important influence on the purchase decision of each customer, it is intuitive that personalization should be beneficial for product search engines. While synthetic experiments from previous studies show that purchase histories are useful for identifying the individual intent of each product search session, the effect of personalization on product search in practice, however, remains mostly unknown. In this paper, we formulate the problem of personalized product search and conduct large-scale experiments with search logs sampled from a commercial e-commerce search engine. Results from our preliminary analysis show that the potential of personalization depends on query characteristics, interactions between queries, and user purchase histories. Based on these observations, we propose a Zero Attention Model for product search that automatically determines when and how to personalize a user-query pair via a novel attention mechanism. Empirical results on commercial product search logs show that the proposed model not only significantly outperforms state-of-the-art personalized product retrieval models, but also provides important information on the potential of personalization in each product search session.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "product search",
        "product search engines",
        "personalized product search",
        "commercial product search logs",
        "search logs",
        "products",
        "product search session",
        "e-commerce websites",
        "commercial e-commerce search engine",
        "purchase histories",
        "personalization",
        "query characteristics",
        "queries",
        "important information"
      ]
    }
  },
  {
    "sim": 0.5564157221493198,
    "gen": {
      "title": "Workshop on Stochastic Optimization in Networks and Related Topics February 23 \u2013 February 24 , 2018",
      "url": "https://www.semanticscholar.org/paper/f51f29550da8bcc4e10eebd15109c1b51ee1f9fc",
      "abstract": "Prof. Chandra Murthy (ECE, IISc Bengaluru) (Tutorial) Title: The surprising effectiveness of hierarchical Bayesian methods for sparse signal recovery Abstract: Hierarchical Bayesian methods have been empirically shown to significantly outperform their more conventional convex relaxation and greedy optimization based counterparts in several scenarios. In this talk, we will focus on the multiple measurement model, and discuss fundamental results that explain the surprising effectiveness of hierarchical Bayesian methods for sparse signal recovery. Inspired by the results, we discuss several new algorithms based on the principle underlying the hierarchical Bayesian methods, namely, that of covariance matching. These algorithms offer multi-fold improvement in performance and use far lower working memory, without compromising on the performance. Time permitting, we will discuss some applications in wireless communications. Hierarchical Bayesian methods have been empirically shown to significantly outperform their more conventional convex relaxation and greedy optimization based counterparts in several scenarios. In this talk, we will focus on the multiple measurement model, and discuss fundamental results that explain the surprising effectiveness of hierarchical Bayesian methods for sparse signal recovery. Inspired by the results, we discuss several new algorithms based on the principle underlying the hierarchical Bayesian methods, namely, that of covariance matching. These algorithms offer multi-fold improvement in performance and use far lower working memory, without compromising on the performance. Time permitting, we will discuss some applications in wireless communications. Prof. Aditya Gopalan (ECE, IISc Bengaluru) Title: Black-box Optimization Abstract: How would you maximize an unknown function if you could only query it at chosen inputs and observe the corresponding (noisy) function values? The talk will provide a gentle introduction to the Bayesian optimization paradigm for solving this widely encountered problem. We will also present algorithms for multi-armed bandit problems with continuous action spaces, based on nonparametric Gaussian process models for inference and decisionmaking under uncertainty (joint work with Sayak Ray Chowdhury). How would you maximize an unknown function if you could only query it at chosen inputs and observe the corresponding (noisy) function values? The talk will provide a gentle introduction to the Bayesian optimization paradigm for solving this widely encountered problem. We will also present algorithms for multi-armed bandit problems with continuous action spaces, based on nonparametric Gaussian process models for inference and decisionmaking under uncertainty (joint work with Sayak Ray Chowdhury). Prof. Amitabha Bagchi (CSE, IIT Delhi) Title: Decentralized random walk-based data collection in networks Abstract: We analyze a decentralized random walk-based algorithm for data collection at the sink in a multi-hop sensor network. Our algorithm, Random-Collect, which involves data packets being passed to random neighbors in the network according to a random walk mechanism, requires no configuration and incurs no routing overhead. To analyze this method, we model the data generation process as independent Bernoulli arrivals at the source nodes. We analyze both latency and throughput in this setting, providing a theoretical lower bound for the throughput and a theoretical upper bound for the latency. The main contribution of our paper, however, is the throughput result: we show that the rate at which our algorithm can collect data depends on the spectral gap of the given random walk's transition matrix. In particular, for We analyze a decentralized random walk-based algorithm for data collection at the sink in a multi-hop sensor network. Our algorithm, Random-Collect, which involves data packets being passed to random neighbors in the network according to a random walk mechanism, requires no configuration and incurs no routing overhead. To analyze this method, we model the data generation process as independent Bernoulli arrivals at the source nodes. We analyze both latency and throughput in this setting, providing a theoretical lower bound for the throughput and a theoretical upper bound for the latency. The main contribution of our paper, however, is the throughput result: we show that the rate at which our algorithm can collect data depends on the spectral gap of the given random walk's transition matrix. In particular, for the simple random walk, we show that the rate also depends on the maximum and minimum degrees of the graph modelling the network. For latency, we show that the time taken to collect data not only depends on the worst-case hitting time of the given random walk, but also depends on the data arrival rate. In fact, our latency bound reflects the data rate-latency tradeoff, i.e., in order to achieve a higher data rate we need to compromise on latency and vice-versa. We also discuss some examples that demonstrate that our lower bound on the data rate is optimal up to constant factors, i.e., there exists a network topology and sink placement for which the maximum stable data rate is just a constant factor above our lower bound. Prof. Anand Louis (CSA, IISc Bengaluru) Title: Algorithms for graph partitioning problems Abstract: Graph-partitioning problems are a central topic of research in study of algorithms and complexity theory. They are of interest to theoreticians with connections to error correcting codes, sampling algorithms, metric embeddings, among others, and to practitioners, as algorithms for graph partitioning can be used as fundamental building blocks in many applications. One of the central problems studied in this field is the sparsest cut problem, where we want to compute the cut which has the least ratio of number of edges cut to size of smaller side of the cut. This ratio is known as the expansion of the cut. In this talk, I shall survey some recent results and connections for graph expansion problems. Graph-partitioning problems are a central topic of research in study of algorithms and complexity theory. They are of interest to theoreticians with connections to error correcting codes, sampling algorithms, metric embeddings, among others, and to practitioners, as algorithms for graph partitioning can be used as fundamental building blocks in many applications. One of the central problems studied in this field is the sparsest cut problem, where we want to compute the cut which has the least ratio of number of edges cut to size of smaller side of the cut. This ratio is known as the expansion of the cut. In this talk, I shall survey some recent results and connections for graph expansion problems. Prof. Avhishek Chatterjee (EE, IIT Madras) Title: Energy-Reliability Limits in Nanoscale Boolean Trees and Feed forward Neural Networks Abstract: Nanoscale semiconductor devices are often unreliable, with reliability as a function of energy. We study energy-reliability limits for boolean tree circuits and deep feedforward neural networks (multilayer perceptrons) built using such devices. Pippenger had developed a mutual information propagation technique to characterize the complexity of noisy circuits. Since small circuit complexity need not imply low energy, however, we extend mutual information propagation to obtain energy lower bounds for boolean tree-structured circuits and for deep Nanoscale semiconductor devices are often unreliable, with reliability as a function of energy. We study energy-reliability limits for boolean tree circuits and deep feedforward neural networks (multilayer perceptrons) built using such devices. Pippenger had developed a mutual information propagation technique to characterize the complexity of noisy circuits. Since small circuit complexity need not imply low energy, however, we extend mutual information propagation to obtain energy lower bounds for boolean tree-structured circuits and for deep feedforward neural networks. Many device technologies require all gates to have the same electrical operating point; in circuits of such uniform gates, we show that the minimum energy required to achieve any non-trivial reliability scales superlinearly with the number of inputs. Circuits implemented in emerging device technologies like spin electronics can, however, have gates operate at different electrical points; in circuits of such heterogenous gates, we show energy scaling can be linear in the number of inputs. Building on our extended mutual information propagation technique and using insights from convex optimization theory, we develop an algorithm to compute energy lower bounds for any given boolean tree under heterogeneous gates. This algorithm runs in linear time in number of gates and is therefore useful for designing modern circuits with numerous gates. As part of our development we find a simple procedure for energy allocation across circuit gates with different operating points and neural networks with differently-operating layers. Prof. Bruce Hajek (ECE, UIUC) Title: On the challenge of gene regulatory network reconstruction from high throughput sequencing data Abstract: Gene regulatory networks are central to the functioning of biological organisms. High throughput genetic sequencing technology has enabled the production of massive amounts of data pertaining to activation levels of genes, which has the potential to help scientists reverse engineer gene regulatory networks. In this talk I will briefly explain the steps from data collection to network modelling and analysis that go into the process for a particular study examining soybean plants. Gene regulatory networks are central to the functioning of biological organisms. High throughput genetic sequencing technology has enabled the production of massive amounts of data pertaining to activation levels of genes, which has the potential to help scientists reverse e",
      "fieldsOfStudy": null,
      "topics": [
        "circuit gates",
        "neural networks",
        "deep feedforward neural networks",
        "engineer gene regulatory networks",
        "low energy",
        "gene regulatory network reconstruction",
        "boolean tree circuits",
        "energy lower bounds",
        "networks",
        "network modelling",
        "small circuit complexity",
        "graph partitioning problems",
        "graph expansion problems",
        "heterogenous gates",
        "gene regulatory networks",
        "noisy circuits",
        "Feed forward Neural Networks"
      ]
    },
    "org": {
      "title": "A passivation algorithm for linear time-invariant systems",
      "url": "https://www.semanticscholar.org/paper/6bc6301937b496f14a60defe390c456e19da9c97",
      "abstract": "We propose and study an algorithm for computing a nearest passive system to a given non-passive linear time-invariant system (with much freedom in the choice of the metric defining `nearest'), and also a closely related algorithm for computing the structured distance of a given passive system to non-passivity. Both problems are addressed by solving eigenvalue optimization problems for Hamiltonian matrices that are constructed from perturbed system matrices. The proposed algorithms are two-level methods that optimize the Hamiltonian eigenvalue of smallest positive real part over perturbations of a fixed size in the inner iteration, using a constrained gradient flow, and optimize over the perturbation size in the outer iteration. For large systems, we propose a variant of the algorithm that takes advantage of the inherent low-rank structure of the problem. Numerical experiments illustrate the behavior of the proposed algorithms.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "perturbed system matrices",
        "large systems",
        "Hamiltonian matrices",
        "eigenvalue optimization problems",
        "smallest positive real part",
        "perturbations",
        "nearest passive system",
        "given passive system",
        "given non-passive linear time-invariant system",
        "freedom",
        "constrained gradient flow",
        "passivity",
        "perturbation size",
        "outer iteration",
        "inner iteration"
      ]
    }
  },
  {
    "sim": 0.552395940532873,
    "gen": {
      "title": "Dynamic Channel Pruning: Feature Boosting and Suppression",
      "url": "https://www.semanticscholar.org/paper/a055b9917759dd75811edbc8500ca247b457c5b2",
      "abstract": "Making deep convolutional neural networks more accurate typically comes at the cost of increased computational and memory resources. In this paper, we reduce this cost by exploiting the fact that the importance of features computed by convolutional layers is highly input-dependent, and propose feature boosting and suppression (FBS), a new method to predictively amplify salient convolutional channels and skip unimportant ones at run-time. FBS introduces small auxiliary connections to existing convolutional layers. In contrast to channel pruning methods which permanently remove channels, it preserves the full network structures and accelerates convolution by dynamically skipping unimportant input and output channels. FBS-augmented networks are trained with conventional stochastic gradient descent, making it readily available for many state-of-the-art CNNs. We compare FBS to a range of existing channel pruning and dynamic execution schemes and demonstrate large improvements on ImageNet classification. Experiments show that FBS can respectively provide $5\\times$ and $2\\times$ savings in compute on VGG-16 and ResNet-18, both with less than $0.6\\%$ top-5 accuracy loss.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "salient convolutional channels",
        "output channels",
        "existing channel",
        "convolutional layers",
        "deep convolutional neural networks",
        "channels",
        "unimportant input",
        "ImageNet classification",
        "unimportant ones",
        "conventional stochastic gradient descent",
        "dynamic execution schemes",
        "pruning methods",
        "large improvements",
        "feature",
        "channel pruning methods",
        "feature boosting",
        "unimportant input and output channels",
        "existing channel pruning and dynamic execution schemes",
        "features",
        "FBS"
      ]
    },
    "org": {
      "title": "Target-Specific Action Classification for Automated Assessment of Human Motor Behavior from Video",
      "url": "https://www.semanticscholar.org/paper/84b5e88e319346385bbedb5d6c8d539693a3397f",
      "abstract": "Objective monitoring and assessment of human motor behavior can improve the diagnosis and management of several medical conditions. Over the past decade, significant advances have been made in the use of wearable technology for continuously monitoring human motor behavior in free-living conditions. However, wearable technology remains ill-suited for applications which require monitoring and interpretation of complex motor behaviors (e.g., involving interactions with the environment). Recent advances in computer vision and deep learning have opened up new possibilities for extracting information from video recordings. In this paper, we present a hierarchical vision-based behavior phenotyping method for classification of basic human actions in video recordings performed using a single RGB camera. Our method addresses challenges associated with tracking multiple human actors and classification of actions in videos recorded in changing environments with different fields of view. We implement a cascaded pose tracker that uses temporal relationships between detections for short-term tracking and appearance based tracklet fusion for long-term tracking. Furthermore, for action classification, we use pose evolution maps derived from the cascaded pose tracker as low-dimensional and interpretable representations of the movement sequences for training a convolutional neural network. The cascaded pose tracker achieves an average accuracy of 88% in tracking the target human actor in our video recordings, and overall system achieves average test accuracy of 84% for target-specific action classification in untrimmed video recordings.",
      "fieldsOfStudy": [
        "Computer Science",
        "Medicine"
      ],
      "topics": [
        "video recordings",
        "untrimmed video recordings",
        "appearance based tracklet fusion",
        "human motor behavior",
        "basic human actions",
        "medical conditions",
        "multiple human actors",
        "complex motor behaviors",
        "videos",
        "average test accuracy",
        "view",
        "different fields",
        "environments",
        "classification",
        "changing environments",
        "overall system"
      ]
    }
  },
  {
    "sim": 0.4154838477862348,
    "gen": {
      "title": "Epidemic spreading and aging in temporal networks with memory",
      "url": "https://www.semanticscholar.org/paper/8dc4dc4d55458e6161ffd9d869237fbd13925922",
      "abstract": "Time-varying network topologies can deeply influence dynamical processes mediated by them. Memory effects in the pattern of interactions among individuals are also known to affect how diffusive and spreading phenomena take place. In this paper we analyze the combined effect of these two ingredients on epidemic dynamics on networks. We study the susceptible-infected-susceptible (SIS) and the susceptible-infected-recovered (SIR) models on the recently introduced activity-driven networks with memory. By means of an activity-based mean-field approach, we derive, in the long-time limit, analytical predictions for the epidemic threshold as a function of the parameters describing the distribution of activities and the strength of the memory effects. Our results show that memory reduces the threshold, which is the same for SIS and SIR dynamics, therefore favoring epidemic spreading. The theoretical approach perfectly agrees with numerical simulations in the long-time asymptotic regime. Strong aging effects are present in the preasymptotic regime and the epidemic threshold is deeply affected by the starting time of the epidemics. We discuss in detail the origin of the model-dependent preasymptotic corrections, whose understanding could potentially allow for epidemic control on correlated temporal networks.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics",
        "Biology"
      ],
      "topics": [
        "epidemic dynamics",
        "epidemic control",
        "correlated temporal networks",
        "Memory effects",
        "networks",
        "dynamical processes",
        "place",
        "memory",
        "Time-varying network topologies",
        "epidemic threshold",
        "Strong aging effects",
        "activities",
        "phenomena",
        "SIR",
        "SIS",
        "epidemic spreading",
        "analytical predictions",
        "memory effects"
      ]
    },
    "org": {
      "title": "Electro-magneto-mechanically response of polycrystalline materials: Computational Homogenization via the Virtual Element Method",
      "url": "https://www.semanticscholar.org/paper/6593d359aacd85f9b0dfd0a128e77cb454066e33",
      "abstract": null,
      "fieldsOfStudy": [
        "Materials Science",
        "Computer Science"
      ]
    }
  },
  {
    "sim": 0.5467787561376176,
    "gen": {
      "title": "The Anatomy of a Scientific Rumor",
      "url": "https://www.semanticscholar.org/paper/72f6fa34d979945ad0b586513e135227c6543939",
      "abstract": null,
      "fieldsOfStudy": [
        "Medicine",
        "Computer Science",
        "Physics"
      ]
    },
    "org": {
      "title": "How Are Academic Age, Productivity and Collaboration Related to Citing Behavior of Researchers?",
      "url": "https://www.semanticscholar.org/paper/41f6eebf63175350b66b36f6d478becbc41d53f4",
      "abstract": "References are an essential component of research articles and therefore of scientific communication. In this study we investigate referencing (citing) behavior in five diverse fields (astronomy, mathematics, robotics, ecology and economics) based on 213,756 core journal articles. At the macro level we find: (a) a steady increase in the number of references per article over the period studied (50 years), which in some fields is due to a higher rate of usage, while in others reflects longer articles and (b) an increase in all fields in the fraction of older, foundational references since the 1980s, with no obvious change in citing patterns associated with the introduction of the Internet. At the meso level we explore current (2006\u20132010) referencing behavior of different categories of authors (21,562 total) within each field, based on their academic age, productivity and collaborative practices. Contrary to some previous findings and expectations we find that senior researchers use references at the same rate as their junior colleagues, with similar rates of re-citation (use of same references in multiple papers). High Modified Price Index (MPI, which measures the speed of the research front more accurately than the traditional Price Index) of senior authors indicates that their research has the similar cutting-edge aspect as that of their younger colleagues. In all fields both the productive researchers and especially those who collaborate more use a significantly lower fraction of foundational references and have much higher MPI and lower re-citation rates, i.e., they are the ones pushing the research front regardless of researcher age. This paper introduces improved bibliometric methods to measure the speed of the research front, disambiguate lead authors in co-authored papers and decouple measures of productivity and collaboration.",
      "fieldsOfStudy": [
        "Physics",
        "Computer Science",
        "Medicine",
        "Mathematics"
      ],
      "topics": [
        "research articles",
        "lower re-citation rates",
        "similar rates",
        "foundational references",
        "longer articles",
        "article",
        "collaborative practices",
        "references",
        "co-authored papers",
        "researcher age",
        "senior authors",
        "multiple papers",
        "lead authors",
        "High Modified Price Index"
      ]
    }
  },
  {
    "sim": 0.4199424623196184,
    "gen": {
      "title": "The Pushshift Telegram Dataset",
      "url": "https://www.semanticscholar.org/paper/cfe486dddac8f4158a59bf06202504b9ba146960",
      "abstract": "Messaging platforms, especially those with a mobile focus, have become increasingly ubiquitous in society. These mobile messaging platforms can have deceivingly large user bases, and in addition to being a way for people to stay in touch, are often used to organize social movements, as well as a place for extremists to congregate.In this paper, we present a dataset from one such mobile messaging platform: Telegram. Our dataset is made up of over 27.8K channels and 317M messages from 2.2M unique users. To the best of our knowledge, our dataset comprises the largest and most complete of its kind. In addition to the raw data, we also provide the source code used to collect it, allowing researchers to run their own data collection instance. We believe the Pushshift Telegram dataset can help researchers from a variety of disciplines interested in studying online social movements, protests, political extremism, and disinformation.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "social movements",
        "political extremism",
        "disinformation",
        "researchers",
        "data collection instance",
        "extremists",
        "addition",
        "touch",
        "society",
        "protests",
        "people",
        "deceivingly large user bases",
        "Messaging platforms",
        "disciplines"
      ]
    },
    "org": {
      "title": "Prosody: The Rhythms and Melodies of Speech",
      "url": "https://www.semanticscholar.org/paper/9374a61d79b83fd3bcd8ed0b8dee5fe28b74cf0d",
      "abstract": "The present contribution is a tutorial on selected aspects of prosody, the rhythms and melodies of speech, based on a course of the same name at the Summer School on Contemporary Phonetics and Phonology at Tongji University, Shanghai, China in July 2016. The tutorial is not intended as an introduction to experimental methodology or as an overview of the literature on the topic, but as an outline of observationally accessible aspects of fundamental frequency and timing patterns with the aid of computational visualisation, situated in a semiotic framework of sign ranks and interpretations. After an informal introduction to the basic concepts of prosody in the introduction and a discussion of the place of prosody in the architecture of language, a selection of acoustic phonetic topics in phonemic tone and accent prosody, word prosody, phrasal prosody and discourse prosody are discussed, and a stylisation method for visualising aspects of prosody is introduced. Examples are taken from a number of typologically different languages: Anyi/Agni (Niger-Congo>Kwa, Ivory Coast), English, Kuki-Thadou (Sino-Tibetan, North-East India and Myanmar), Mandarin Chinese, Tem (Niger-Congo>Gur, Togo) and Farsi. The main focus is on fundamental frequency patterns, but issues of timing and rhythm are also discussed. In the final section, further reading and possible future research directions are outlined.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "word prosody",
        "accent prosody",
        "phrasal prosody",
        "discourse prosody",
        "prosody",
        "July",
        "acoustic phonetic topics",
        "selected aspects",
        "Mandarin Chinese",
        "Tongji University",
        "aspects",
        "Contemporary Phonetics",
        "interpretations",
        "fundamental frequency",
        "fundamental frequency patterns",
        "phonemic tone and accent prosody",
        "Farsi",
        "sign ranks"
      ]
    }
  },
  {
    "sim": 0.5547607814430445,
    "gen": {
      "title": "Disparity estimation from multi-view images and video: graph models and algorithms",
      "url": "https://www.semanticscholar.org/paper/98b7cd50dd62036c18721ed68f1488f25dee7828",
      "abstract": "In this work, we consider the problem of estimating the depth information from the following three scenarios: a stereo image pair, multi-view images, and stereo image sequences. \nFor stereo image matching, we first propose a new disparity map estimation algorithm for slant and curved surfaces. In this situation, we focus on two properties of the disparity map. The first one is continuous disparity change inside an object while the second one is sharp disparity change between object boundaries. To exploit these two properties at the same time, two techniques are proposed to improve the performance of existing stereo matching algorithms. To address disparity discontinuity in object boundaries, we present a disparity estimation procedure, which consists of two steps: a greedy disparity filling algorithm and a least-squared-errors (LSE) fitting method. Furthermore, it is observed that the existing fronto-parallel model with color segmentation is built upon the piecewise constant surface approximation. This is however not efficient in approximating slanted or curved objects. We propose to use a piecewise linear surface model to represent 3-dimensional (3D) geometric structure for better surface modeling. The proposed stereo matching system with these two new components is evaluated with Middlebury data sets with excellent quantitative and qualitative results. \nThen, a new graph model for disparity estimation of multi-view images is investigated. Two performance metrics for algorithmic evaluation are considered. They are quality and complexity. To reduce complexity, a graph model whose computational time is independent of the number of input images is proposed. With this model, new smoothness and consistency terms in the energy function are added to maintain the quality of a disparity map. Experimental results show that the proposed algorithm offers good enough quality at a much lower complexity than existing methods. \nTo further improve the quality of the disparity map in stereo matching, we propose an advanced framework based on new graph models. Along this direction, we divide stereo matching problem into 3 sub-problems: (1) disparity estimation for non-occlusion regions and occlusion detection, (2) disparity estimation for occlusion regions, and (3) post-processing of the disparity map. A three-step procedure is proposed to solve them sequentially. At the first step, we perform an initial matching and develop a new graph model using the ordering constraint to improve disparity values in non-occlusion regions and detect occlusion regions. At the second step, we determine disparity values in occlusion regions based on global optimization. Since the conventional segmentation-based stereo matching is not efficient in highly slanted or curved objects, we propose a post-processing technique for disparity map enhancement based on a 3-dimensional (3-D) geometric structure. The proposed three-step stereo matching procedure yields excellent quantitative and qualitative results with Middlebury data sets. \nFinally, disparity estimation and virtual view synthesis from stereo video inputs are examined. To enhance the overall performance, a two-stage algorithm for accurate and fast disparity estimation and occlusion handling is first presented. Then, a new virtual view synthesis method with a preprocessing algorithm is described. The preprocessing algorithm can remove false matched regions for disparity refinement effectively. This synthesis method can reduce the blurring and ghostly effects and provides an excellent tradeoff in terms of computational time and synthesized video quality.",
      "fieldsOfStudy": [
        "Mathematics"
      ],
      "topics": [
        "disparity estimation",
        "disparity map enhancement",
        "disparity values",
        "disparity refinement",
        "disparity discontinuity",
        "sharp disparity change",
        "continuous disparity change",
        "existing stereo matching algorithms",
        "stereo image sequences",
        "stereo matching problem",
        "stereo matching",
        "multi-view images",
        "occlusion regions",
        "better surface modeling",
        "non-occlusion regions"
      ]
    },
    "org": {
      "title": "Matching Capabilities of Prediction to Communication and Computing for Proactive VR Video Streaming",
      "url": "https://www.semanticscholar.org/paper/85e7f2cdd21011a628167c027fd3658bd31a6ce6",
      "abstract": "Proactive tile-based video streaming can avoid motion-to-photon latency of wireless virtual reality (VR) by computing and delivering the predicted tiles in a segment to be requested before playback. However, all existing works either focus on the tile prediction or focus on tile computing and delivering, overlooking the important fact that prediction, computing and communication have to share the same duration. Since the quality of experience (QoE) of proactive tile-based streaming depends on the worst performance of prediction, computing and communication, it is vital to match the prediction capability to the computing and communication capability. In this paper, we jointly optimize the duration of the observation window for tile prediction and the duration used for computing and communication, to maximize the QoE of watching a VR video. We find the global optimal solution with closed-form expression by decomposing the original problem equivalently into subproblems. From the optimal solution we find two regions where tile prediction and computing and communication capabilities respectively play the dominant role, and reveal the tradeoff between the performance of tile prediction and the capability of computing and communication. Simulation results using two existing tile prediction methods with a real dataset demonstrate the gain of the optimized duration over the non-optimized duration of observation window.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering",
        "Mathematics"
      ],
      "topics": [
        "tile computing",
        "prediction",
        "computing",
        "communication",
        "observation window",
        "computing and communication capabilities",
        "existing tile prediction methods",
        "tile prediction",
        "wireless virtual reality",
        "non-optimized duration",
        "prediction capability",
        "proactive tile-based streaming",
        "VR",
        "capabilities",
        "tile-based video streaming",
        "playback"
      ]
    }
  },
  {
    "sim": 0.554698395718966,
    "gen": {
      "title": "Joint Unsupervised Learning of Deep Representations and Image Clusters",
      "url": "https://www.semanticscholar.org/paper/2c37826357c18148f6f0773d22f7a4488831c1c4",
      "abstract": "In this paper, we propose a recurrent framework for joint unsupervised learning of deep representations and image clusters. In our framework, successive operations in a clustering algorithm are expressed as steps in a recurrent process, stacked on top of representations output by a Convolutional Neural Network (CNN). During training, image clusters and representations are updated jointly: image clustering is conducted in the forward pass, while representation learning in the backward pass. Our key idea behind this framework is that good representations are beneficial to image clustering and clustering results provide supervisory signals to representation learning. By integrating two processes into a single model with a unified weighted triplet loss function and optimizing it end-to-end, we can obtain not only more powerful representations, but also more precise image clusters. Extensive experiments show that our method outperforms the state of-the-art on image clustering across a variety of image datasets. Moreover, the learned representations generalize well when transferred to other tasks. The source code can be downloaded from https://github.com/ jwyang/joint-unsupervised-learning.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "representation learning",
        "good representations",
        "image clustering",
        "image datasets",
        "image",
        "joint unsupervised learning",
        "image clustering and clustering results",
        "precise image clusters",
        "Convolutional Neural Network",
        "tasks",
        "CNN",
        "image clusters",
        "clustering results",
        "supervisory signals",
        "learned representations",
        "end"
      ]
    },
    "org": {
      "title": "A Comprehensive Performance Evaluation for 3D Transformation Estimation Techniques",
      "url": "https://www.semanticscholar.org/paper/9cb57fb86ddb42296e7e939d91ca845b54a4121d",
      "abstract": "3D local feature extraction and matching is the basis for solving many tasks in the area of computer vision, such as 3D registration, modeling, recognition and retrieval. However, this process commonly draws into false correspondences, due to noise, limited features, occlusion, incomplete surface and etc. In order to estimate accurate transformation based on these corrupted correspondences, numerous transformation estimation techniques have been proposed. However, the merits, demerits and appropriate application for these methods are unclear owing to that no comprehensive evaluation for the performance of these methods has been conducted. This paper evaluates eleven state-of-the-art transformation estimation proposals on both descriptor based and synthetic correspondences. On descriptor based correspondences, several evaluation items (including the performance on different datasets, robustness to different overlap ratios and the performance of these technique combined with Iterative Closest Point (ICP), different local features and LRF/A techniques) of these methods are tested on four popular datasets acquired with different devices. On synthetic correspondences, the robustness of these methods to varying percentages of correct correspondences (PCC) is evaluated. In addition, we also evaluate the efficiencies of these methods. Finally, the merits, demerits and application guidance of these tested transformation estimation methods are summarized.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "different local features",
        "different datasets",
        "numerous transformation estimation techniques",
        "different devices",
        "different overlap ratios",
        "descriptor based correspondences",
        "3D local feature extraction",
        "correct correspondences",
        "synthetic correspondences",
        "false correspondences",
        "Iterative Closest Point",
        "tested transformation estimation methods",
        "incomplete surface",
        "accurate transformation",
        "evaluation items",
        "limited features"
      ]
    }
  },
  {
    "sim": 0.6524343071190006,
    "gen": {
      "title": "Improving Object Localization with Fitness NMS and Bounded IoU Loss",
      "url": "https://www.semanticscholar.org/paper/e1c8f1d0e8d57c44bd732b1b3fbb8013e6d60d8a",
      "abstract": "We demonstrate that many detection methods are designed to identify only a sufficently accurate bounding box, rather than the best available one. To address this issue we propose a simple and fast modification to the existing methods called Fitness NMS. This method is tested with the DeNet model and obtains a significantly improved MAP at greater localization accuracies without a loss in evaluation rate, and can be used in conjunction with Soft NMS for additional improvements. Next we derive a novel bounding box regression loss based on a set of IoU upper bounds that better matches the goal of IoU maximization while still providing good convergence properties. Following these novelties we investigate RoI clustering schemes for improving evaluation rates for the DeNet wide model variants and provide an analysis of localization performance at various input image dimensions. We obtain a MAP of 33.6%@79Hz and 41.8%@5Hz for MSCOCO and a Titan X (Maxwell). Source code available from: https://github.com/lachlants/denet",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "additional improvements",
        "input image dimensions",
        "good convergence properties",
        "IoU upper bounds",
        "Soft NMS",
        "Fitness NMS",
        "IoU maximization",
        "evaluation rates",
        "localization performance",
        "greater localization accuracies",
        "IoU",
        "https://github.com/lachlants/denet",
        "detection methods",
        "RoI clustering schemes",
        "Maxwell",
        "novel bounding box regression loss"
      ]
    },
    "org": {
      "title": "Appearance-Preserving 3D Convolution for Video-based Person Re-identification",
      "url": "https://www.semanticscholar.org/paper/468c12b1ff6a5c4f2630cdbaca214e6df0c935cc",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  {
    "sim": 0.6549192020734952,
    "gen": {
      "title": "Deep Convolutional Neural Networks and Data Augmentation for Acoustic Event Detection",
      "url": "https://www.semanticscholar.org/paper/5d4cbb358a9039d237859212cc4072b50ce21921",
      "abstract": "We propose a novel method for Acoustic Event Detection (AED). In contrast to speech, sounds coming from acoustic events may be produced by a wide variety of sources. Furthermore, distinguishing them often requires analyzing an extended time period due to the lack of a clear sub-word unit. In order to incorporate the long-time frequency structure for AED, we introduce a convolutional neural network (CNN) with a large input field. In contrast to previous works, this enables to train audio event detection end-to-end. Our architecture is inspired by the success of VGGNet and uses small, 3x3 convolutions, but more depth than previous methods in AED. In order to prevent over-fitting and to take full advantage of the modeling capabilities of our network, we further propose a novel data augmentation method to introduce data variation. Experimental results show that our CNN significantly outperforms state of the art methods including Bag of Audio Words (BoAW) and classical CNNs, achieving a 16% absolute improvement.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "end",
        "previous methods",
        "AED",
        "data variation",
        "classical CNNs",
        "Acoustic Event Detection",
        "Audio Words",
        "CNN",
        "novel data augmentation method",
        "sources",
        "acoustic events",
        "convolutional neural network",
        "clear sub-word unit",
        "large input field",
        "depth"
      ]
    },
    "org": {
      "title": "Prescribed Generative Adversarial Networks",
      "url": "https://www.semanticscholar.org/paper/fae3d474c4d7745be06458df0c20bf837a6055ef",
      "abstract": "Generative adversarial networks (GANs) are a powerful approach to unsupervised learning. They have achieved state-of-the-art performance in the image domain. However, GANs are limited in two ways. They often learn distributions with low support---a phenomenon known as mode collapse---and they do not guarantee the existence of a probability density, which makes evaluating generalization using predictive log-likelihood impossible. In this paper, we develop the prescribed GAN (PresGAN) to address these shortcomings. PresGANs add noise to the output of a density network and optimize an entropy-regularized adversarial loss. The added noise renders tractable approximations of the predictive log-likelihood and stabilizes the training procedure. The entropy regularizer encourages PresGANs to capture all the modes of the data distribution. Fitting PresGANs involves computing the intractable gradients of the entropy regularization term; PresGANs sidestep this intractability using unbiased stochastic estimates. We evaluate PresGANs on several datasets and found they mitigate mode collapse and generate samples with high perceptual quality. We further found that PresGANs reduce the gap in performance in terms of predictive log-likelihood between traditional GANs and variational autoencoders (VAEs).",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "high perceptual quality",
        "unbiased stochastic estimates",
        "mode collapse",
        "unsupervised learning",
        "traditional GANs",
        "variational autoencoders",
        "VAEs",
        "Generative adversarial networks",
        "low support",
        "predictive log-likelihood",
        "GANs",
        "distributions",
        "terms",
        "datasets",
        "samples",
        "PresGANs"
      ]
    }
  },
  {
    "sim": 0.4415134857867584,
    "gen": {
      "title": "FuncNN: An R Package to Fit Deep Neural Networks Using Generalized Input Spaces",
      "url": "https://www.semanticscholar.org/paper/89b76799802ed2dfbfbd2535ce283bcd5b43201f",
      "abstract": "Neural networks have excelled at regression and classification problems when the input space consists of scalar variables. As a result of this proficiency, several popular packages have been developed that allow users to easily fit these kinds of models. However, the methodology has excluded the use of functional covariates and to date, there exists no software that allows users to build deep learning models with this generalized input space. To the best of our knowledge, the functional neural network (FuncNN) library is the first such package in any programming language; the library has been developed for R and is built on top of the keras architecture. Throughout this paper, several functions are introduced that provide users an avenue to easily build models, generate predictions, and run cross-validations. A summary of the underlying methodology is also presented. The ultimate contribution is a package that provides a set of general modelling and diagnostic tools for data problems in which there exist both functional and scalar covariates.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "scalar variables",
        "deep learning models",
        "functional covariates",
        "models",
        "validations",
        "users",
        "data problems",
        "classification problems",
        "popular packages",
        "diagnostic tools",
        "generalized input space",
        "cross",
        "general modelling",
        "predictions",
        "Neural networks",
        "input space",
        "date"
      ]
    },
    "org": {
      "title": "Adversarial Coordination on Social Networks",
      "url": "https://www.semanticscholar.org/paper/4431e82201dc5a99ba085cf8ffd1878f4710f539",
      "abstract": "Extensive literature exists studying decentralized coordination and consensus, with considerable attention devoted to ensuring robustness to faults and attacks. However, most of the latter literature assumes that non-malicious agents follow simple stylized rules. In reality, decentralized protocols often involve humans, and understanding how people coordinate in adversarial settings is an open problem. We initiate a study of this problem, starting with a human subjects investigation of human coordination on networks in the presence of adversarial agents, and subsequently using the resulting data to bootstrap the development of a credible agent-based model of adversarial decentralized coordination. In human subjects experiments, we observe that while adversarial nodes can successfully prevent consensus, the ability to communicate can significantly improve robustness, with the impact particularly significant in scale-free networks. On the other hand, and contrary to typical stylized models of behavior, we show that the existence of trusted nodes has limited utility. Next, we use the data collected in human subject experiments to develop a data-driven agent-based model of adversarial coordination. We show that this model successfully reproduces observed behavior in experiments, is robust to small errors in individual agent models, and illustrate its utility by using it to explore the impact of optimizing network location of trusted and adversarial nodes.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics"
      ],
      "topics": [
        "adversarial nodes",
        "adversarial coordination",
        "adversarial settings",
        "individual agent models",
        "network location",
        "human coordination",
        "human subjects experiments",
        "networks",
        "non-malicious agents",
        "decentralized coordination",
        "typical stylized models",
        "trusted nodes",
        "limited utility"
      ]
    }
  },
  {
    "sim": 0.48846774296051687,
    "gen": {
      "title": "Distributed Localization and Tracking of Mobile Networks Including Noncooperative Objects",
      "url": "https://www.semanticscholar.org/paper/d6880f151a0edcfe850f31ffb397492d8906bae7",
      "abstract": "We propose a Bayesian method for distributed sequential localization of mobile networks composed of both cooperative agents and noncooperative objects. Our method provides a consistent combination of cooperative self-localization (CS) and distributed tracking (DT). Multiple mobile agents and objects are localized and tracked using measurements between agents and objects and between agents. For a distributed operation and low complexity, we combine particle-based belief propagation with a consensus or gossip scheme. High localization accuracy is achieved through a probabilistic information transfer between the CS and DT parts of the underlying factor graph. Simulation results demonstrate significant improvements in both agent self-localization and object localization performance compared to separate CS and DT, and very good scaling properties with respect to the numbers of agents and objects.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "noncooperative objects",
        "objects",
        "agents",
        "Multiple mobile agents",
        "distributed sequential localization",
        "separate CS",
        "DT",
        "High localization accuracy",
        "CS",
        "agent self-localization and object localization performance",
        "measurements",
        "cooperative agents",
        "respect",
        "underlying factor graph",
        "mobile networks",
        "localization",
        "cooperative self",
        "distributed tracking"
      ]
    },
    "org": {
      "title": "A Novel Normalized Sign Algorithm for System Identification Under Impulsive Noise Interference",
      "url": "https://www.semanticscholar.org/paper/2e5490adc436391104623dddeb4b5e66097fa955",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ]
    }
  },
  null,
  {
    "sim": 0.6101506017719759,
    "gen": {
      "title": "Model-independent, multimodality deformable image registration by local matching of anatomical features and minimization of elastic energy.",
      "url": "https://www.semanticscholar.org/paper/b73b7326b6a1d16691b13e275f4a3d4bfe9c0a03",
      "abstract": "With respect to the demands of adaptive and 4D-radiotherapy applications, an algorithm is proposed for a fully automatic, multimodality deformable registration that follows the concept of translational relocation of regularly distributed image subvolumes governed by local anatomical features. Thereby, the problem of global deformable registration is broken down to multiple independent local registration steps which allows for straightforward parallelization of the algorithm. In a subsequent step, possible local misregistrations are corrected for by minimization of the elastic energy of the displacement field under consideration of image information. The final displacement field results from interpolation of the subvolume shift vectors. The algorithm can employ as a similarity measure both the correlation coefficient and mutual information. The latter allows the application to intermodality deformable registration problems. The typical calculation time on a modern multiprocessor PC is well below 1 min, which facilitates almost-interactive, \"online\" usage. CT-to-MRI and CT-to-cone-beam-CT registrations of head-and-neck data sets are presented, as well as inhale-to-exhale registrations of lung CT data sets. For quantitative evaluation of registration accuracy, a virtual thorax phantom was developed; additionally, a landmark-based evaluation on four lung respiratory-correlated CT data sets was performed. This consistently resulted in average registration residuals on the order of the voxel size or less (3D-residuals approximately 1-2 mm). Summarizing, the presented algorithm allows an accurate multimodality deformable registration with calculation times well below 1 min, and thus bears promise as a versatile basic tool in adaptive and 4D-radiotherapy applications.",
      "fieldsOfStudy": [
        "Mathematics",
        "Medicine"
      ],
      "topics": [
        "global deformable registration",
        "lung CT data sets",
        "multiple independent local registration steps",
        "average registration residuals",
        "registration accuracy",
        "local anatomical features",
        "image information",
        "mutual information",
        "CT",
        "possible local misregistrations",
        "lung respiratory-correlated CT data sets",
        "translational relocation",
        "calculation times",
        "exhale",
        "accurate multimodality deformable registration"
      ]
    },
    "org": {
      "title": "Supermodeling of tumor dynamics with parallel isogeometric analysis solver",
      "url": "https://www.semanticscholar.org/paper/d4682780c050b32ada3b0b037ed970a776d412f9",
      "abstract": "In this paper, for the first time, we propose the supermodeling algorithm which couples and synchronizes three-dimensional isogeometric analysis simulators. We focus on the computational oncology and we show that it is possible to obtain reliable prognoses about cancer dynamics by creating the supermodel of cancer. It consists of several coupled instances (the sub-models) of a generic cancer model, developed with the isogeometric analysis. The supermodel integrates with real data by employing a prediction/correction learning scheme focused on fitting several values of coupling coefficients between sub-models. This supermodel data assimilation is an alternative to the classical methods matching scores (even hundreds) of tumor model parameters. We show that the isogeometric analysis is a proper tool to develop a generic computer model of cancer, which can be a computational framework for developing high-quality supermodels. We believe that the latent fine-grained tumor features, e.g., microscopic processes and other unpredictable events accompanying its proliferation not included in the model (that is, not involved directly in the mathematical model), are present in incoming real data and will still influence in indirect way tumor dynamics.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "tumor model parameters",
        "models",
        "cancer dynamics",
        "cancer",
        "incoming real data",
        "indirect way tumor dynamics",
        "real data",
        "generic computer model",
        "unpredictable events",
        "matching scores",
        "fitting several values",
        "coupled instances",
        "mathematical model",
        "This supermodel data assimilation",
        "tumor dynamics",
        "indirect way",
        "high-quality supermodels",
        "values"
      ]
    }
  },
  {
    "sim": 0.26649639170335027,
    "gen": {
      "title": "Personalized Deep Learning for Tag Recommendation",
      "url": "https://www.semanticscholar.org/paper/df37e2fa58670e917c22a4b7de6686afca99d348",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    },
    "org": {
      "title": "Three Modern Roles for Logic in AI",
      "url": "https://www.semanticscholar.org/paper/7c59e80ed21698ceaffeeaf4c5868ac6ff34e911",
      "abstract": "We consider three modern roles for logic in artificial intelligence, which are based on the theory of tractable Boolean circuits: (1) logic as a basis for computation, (2) logic for learning from a combination of data and knowledge, and (3) logic for reasoning about the behavior of machine learning systems.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "machine learning systems",
        "tractable Boolean circuits",
        "artificial intelligence",
        "knowledge",
        "reasoning",
        "data",
        "computation",
        "Boolean",
        "(3) logic",
        "behavior",
        "combination",
        "basis",
        "theory",
        "modern roles"
      ]
    }
  },
  {
    "sim": 0.6464725973490507,
    "gen": {
      "title": "The Expressive Power of Neural Networks: A View from the Width",
      "url": "https://www.semanticscholar.org/paper/53bfec9b34e40000d9f2174c8ac6191087fe4d57",
      "abstract": "The expressive power of neural networks is important for understanding deep learning. Most existing works consider this problem from the view of the depth of a network. In this paper, we study how width affects the expressiveness of neural networks. Classical results state that depth-bounded (e.g. depth-$2$) networks with suitable activation functions are universal approximators. We show a universal approximation theorem for width-bounded ReLU networks: width-$(n+4)$ ReLU networks, where $n$ is the input dimension, are universal approximators. Moreover, except for a measure zero set, all functions cannot be approximated by width-$n$ ReLU networks, which exhibits a phase transition. Several recent works demonstrate the benefits of depth by proving the depth-efficiency of neural networks. That is, there are classes of deep networks which cannot be realized by any shallow network whose size is no more than an exponential bound. Here we pose the dual question on the width-efficiency of ReLU networks: Are there wide networks that cannot be realized by narrow networks whose size is not substantially larger? We show that there exist classes of wide networks which cannot be realized by any narrow network whose depth is no more than a polynomial bound. On the other hand, we demonstrate by extensive experiments that narrow networks whose size exceed the polynomial bound by a constant factor can approximate wide and shallow network with high accuracy. Our results provide more comprehensive evidence that depth is more effective than width for the expressiveness of ReLU networks.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "wide networks",
        "ReLU networks",
        "neural networks",
        "networks",
        "deep networks",
        "width-bounded ReLU networks",
        "universal approximators",
        "shallow network",
        "narrow network",
        "depth",
        "high accuracy",
        "deep learning",
        "network"
      ]
    },
    "org": {
      "title": "Knowledge Matters: Importance of Prior Information for Optimization",
      "url": "https://www.semanticscholar.org/paper/523b12db4004b89284387f978c2af8ae0e79d54b",
      "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {\\em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "different locations",
        "intermediate concepts",
        "effective local minima",
        "deep learning",
        "cultural learning",
        "traditional algorithms",
        "individuals",
        "sprites",
        "learning task",
        "decision trees",
        "chance",
        "scaling and rotation transformations",
        "optimization problems",
        "unsupervised pre",
        "training"
      ]
    }
  },
  null,
  {
    "sim": 0.6644440022224561,
    "gen": {
      "title": "Wireless-powered Cooperative Spectrum Sharing Networks with Full-duplex and NOMA Transmissions",
      "url": "https://www.semanticscholar.org/paper/889115b6fe4a9ec8ee6d6edc20077fa202beb174",
      "abstract": "We consider a non-orthogonal multiple access (NOMA) cooperative spectrum sharing network, where a multi-antenna secondary transmitter assists transmission of a primary transmitter-receiver pair, and at the same time transmits to a secondary receiver. The secondary transmitter is assumed to be full-duplex and energy-constrained. Therefore, secondary transmitter replenishes its battery storage via energy harvesting from an energy access point located in its vicinity. In order to cancel the self-interference at the secondary transmitter, two zero-forcing (ZF)-based beamforming schemes and one maximum ratio combining/maximum ratio transmission (MRC/MRT) scheme are designed. Then, corresponding outage probability analysis of the primary and secondary networks with proposed beamforming schemes are derived. Outage probability results are used to study the delay-constrained throughput of the system. Our results suggest that by utilizing ZF-based beamforming schemes, significant performance improvement can be achieved compared to the half-duplex counterpart. Moreover, our results indicate that proposed ZF-based schemes achieves a zero-diversity order. Keywords-component; Non-orthogonal multiple access (NOMA); cooperative spectrum sharing networks; full-duplex, delay-constrained throughput; zero-forcing beamforming.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "proposed beamforming schemes",
        "cooperative spectrum sharing networks",
        "secondary",
        "Non-orthogonal multiple access",
        "energy harvesting",
        "significant performance improvement",
        "ZF-based beamforming schemes",
        "multi-antenna secondary transmitter",
        "transmission",
        "order",
        "proposed ZF-based schemes",
        "secondary transmitter",
        "energy access point",
        "maximum ratio"
      ]
    },
    "org": {
      "title": "An Activity Management Algorithm for Improving Energy Efficiency of Small Cell Base Stations in 5G Heterogeneous Networks",
      "url": "https://www.semanticscholar.org/paper/37be253b528a71322953cfa246d516797cae11cc",
      "abstract": "Heterogeneous networks (HetNets) are proposed in order to meet the increasing demand for next generation cellular wireless networks, but they also increase the energy consumption of the base stations. In this paper, an activity management algorithm for improving the energy efficiency of HetNets is proposed. A smart sleep strategy is employed for the operator deployed pico base stations to enter sleep and active modes. According to that strategy, when the number of users exceeds the turn on threshold, the pico node becomes active and when the number of users drop below the turn off threshold, it goes into sleep mode. Mobile users dynamically enter and leave the cells, triggering the activation and deactivation of pico base stations. The performance of the system is examined for three different cellular network architectures: cell on edge (COE), uniformly distributed cells (UDC) and macro cell only network (MoNet). Two different user distributions are considered: uniform and hotspot. The effects of number of hotspot users and sleep energies of pico nodes on the energy efficiency are also investigated. The proposed activity management algorithm increases the energy efficiency, measured in bits/J, by $20\\%$. The average bit rates achieved by HetNet users increase by $29\\%$ compared with the MoNet architecture. Thus, the proposed activity control algorithm increases the spectral efficiency of the network while consuming the energy more efficiently.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "pico base stations",
        "macro cell",
        "cell",
        "sleep mode",
        "active modes",
        "energies",
        "hotspot users",
        "generation cellular wireless networks",
        "HetNet users",
        "pico nodes",
        "users",
        "Mobile users",
        "Heterogeneous networks",
        "sleep",
        "different cellular network architectures",
        "macro cell only network",
        "sleep energies",
        "operator deployed pico base stations",
        "sleep and active modes",
        "MoNet"
      ]
    }
  },
  {
    "sim": 0.5335319045359002,
    "gen": {
      "title": "Distributed Algorithms for Solving a Class of Convex Feasibility Problems",
      "url": "https://www.semanticscholar.org/paper/1c52c5a16c877f6a13b0cb4815d34dd43c7c251e",
      "abstract": "In this paper, a class of convex feasibility problems (CFPs) are studied for multi-agent systems through local interactions. The objective is to search a feasible solution to the convex inequalities with some set constraints in a distributed manner. The distributed control algorithms, involving subgradient and projection, are proposed for both continuous- and discrete-time systems, respectively. Conditions associated with connectivity of the directed communication graph are given to ensure convergence of the algorithms. It is shown that under mild conditions, the states of all agents reach consensus asymptotically and the consensus state is located in the solution set of the CFP. Simulation examples are presented to demonstrate the effectiveness of the theoretical results.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "local interactions",
        "multi-agent systems",
        "projection",
        "subgradient",
        "consensus",
        "convergence",
        "feasibility problems",
        "The distributed control algorithms",
        "continuous- and discrete-time systems",
        "convex",
        "CFPs",
        "mild conditions",
        "consensus state",
        "distributed manner",
        "discrete-time systems",
        "convex feasibility problems",
        "theoretical results",
        "Simulation examples"
      ]
    },
    "org": {
      "title": "Convergence characteristics of the generalized residual cutting method",
      "url": "https://www.semanticscholar.org/paper/f92d98ad8b7e14495e082420959dbdda123a54f3",
      "abstract": "The residual cutting (RC) method has been proposed for efficiently solving linear equations obtained from elliptic partial differential equations. Based on the RC, we have introduced the generalized residual cutting (GRC) method, which can be applied to general sparse matrix problems. In this paper, we study the mathematics of the GRC algorithm and and prove it is a Krylov subspace method. Moreover, we show that it is deeply related to the conjugate residual (CR) method and that GRC becomes equivalent to CR for symmetric matrices. Also, in numerical experiments, GRC shows more robust convergence and needs less memory compared to GMRES, for significantly larger matrix sizes.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "elliptic partial differential equations",
        "linear equations",
        "general sparse matrix problems",
        "symmetric matrices",
        "significantly larger matrix sizes",
        "GRC",
        "memory",
        "Krylov subspace method",
        "GMRES",
        "linear",
        "CR",
        "Krylov",
        "generalized residual cutting",
        "numerical experiments",
        "GRC algorithm",
        "The residual cutting (RC) method",
        "(GRC"
      ]
    }
  },
  {
    "sim": 0.4803046708412021,
    "gen": {
      "title": "Gossip Algorithms for Distributed Signal Processing",
      "url": "https://www.semanticscholar.org/paper/36d3a61cae2fbdb588727f62005cac9737d0f6f8",
      "abstract": "Gossip algorithms are attractive for in-network processing in sensor networks because they do not require any specialized routing, there is no bottleneck or single point of failure, and they are robust to unreliable wireless network conditions. Recently, there has been a surge of activity in the computer science, control, signal processing, and information theory communities, developing faster and more robust gossip algorithms and deriving theoretical performance guarantees. This paper presents an overview of recent work in the area. We describe convergence rate results, which are related to the number of transmitted messages and thus the amount of energy consumed in the network for gossiping. We discuss issues related to gossiping over wireless links, including the effects of quantization and noise, and we illustrate the use of gossip algorithms for canonical signal processing tasks including distributed estimation, source localization, and compression.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "wireless network conditions",
        "sensor networks",
        "canonical signal processing tasks",
        "network",
        "signal processing",
        "theoretical performance guarantees",
        "wireless links",
        "single point",
        "Gossip algorithms",
        "source localization",
        "compression",
        "information theory communities",
        "distributed estimation",
        "failure",
        "unreliable wireless network conditions",
        "gossip algorithms",
        "transmitted messages",
        "noise"
      ]
    },
    "org": {
      "title": "Efficient mesh deformation using radial basis functions with a grouping-circular-based greedy algorithm",
      "url": "https://www.semanticscholar.org/paper/3d5047db0107f188cf80245ba08c77730afaf21d",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Physics"
      ]
    }
  },
  null,
  null,
  null,
  {
    "sim": 0.45559400781203296,
    "gen": {
      "title": "Efficient Partitioning Method for Optimizing the Compression on Array Data",
      "url": "https://www.semanticscholar.org/paper/6d59a3d559252cdb8d2303f52335ffbf1158520c",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    },
    "org": {
      "title": "Rethinking Default Values: a Low Cost and Efficient Strategy to Define Hyperparameters",
      "url": "https://www.semanticscholar.org/paper/1c11f08e04a147382fc46a554f07adfbc00d908e",
      "abstract": "Machine Learning (ML) algorithms have been successfully employed by a vast range of practitioners with different backgrounds. One of the reasons for ML popularity is the capability to consistently delivers accurate results, which can be further boosted by adjusting hyperparameters (HP). However, part of practitioners has limited knowledge about the algorithms and does not take advantage of suitable HP settings. In general, HP values are defined by trial and error, tuning, or by using default values. Trial and error is very subjective, time costly and dependent on the user experience. Tuning techniques search for HP values able to maximize the predictive performance of induced models for a given dataset, but with the drawback of a high computational cost and target specificity. To avoid tuning costs, practitioners use default values suggested by the algorithm developer or by tools implementing the algorithm. Although default values usually result in models with acceptable predictive performance, different implementations of the same algorithm can suggest distinct default values. To maintain a balance between tuning and using default values, we propose a strategy to generate new optimized default values. Our approach is grounded on a small set of optimized values able to obtain predictive performance values better than default settings provided by popular tools. The HP candidates are estimated through a pool of promising values tuned from a small and informative set of datasets. After performing a large experiment and a careful analysis of the results, we concluded that our approach delivers better default values. Besides, it leads to competitive solutions when compared with the use of tuned values, being easier to use and having a lower cost.Based on our results, we also extracted simple rules to guide practitioners in deciding whether using our new methodology or a tuning approach.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "distinct default values",
        "new optimized default values",
        "better default values",
        "HP values",
        "predictive performance values",
        "optimized values",
        "promising values",
        "tuned values",
        "default settings",
        "suitable HP settings",
        "popular tools",
        "acceptable predictive performance",
        "tools",
        "HP",
        "target specificity"
      ]
    }
  },
  {
    "sim": 0.7316808105131534,
    "gen": {
      "title": "Outage Probability of Dual-Hop Multiple Antenna AF Systems with Linear Processing in the Presence of Co-Channel Interference",
      "url": "https://www.semanticscholar.org/paper/f6fad0cd72e2bc1d048ba730a388672e6c680cf9",
      "abstract": "This paper considers a dual-hop amplify-and-forward (AF) relaying system where the relay is equipped with multiple antennas, while the source and the destination are equipped with a single antenna. Assuming that the relay is subjected to co-channel interference (CCI) and additive white Gaussian noise (AWGN) while the destination is corrupted by AWGN only, we propose three heuristic relay precoding schemes to combat the CCI, namely, 1) Maximum ratio combining/maximal ratio transmission (MRC/MRT), 2) Zero-forcing/MRT (ZF/MRT), 3) Minimum mean-square error/MRT (MMSE/MRT). We derive new exact outage expressions as well as simple high signal-to-noise ratio (SNR) outage approximations for all three schemes. Our findings suggest that both the MRC/MRT and the MMSE/MRT schemes achieve a full diversity of N, while the ZF/MRT scheme achieves a diversity order of N-M, where N is the number of relay antennas and M is the number of interferers. In addition, we show that the MMSE/MRT scheme always achieves the best outage performance, and the ZF/MRT scheme outperforms the MRC/MRT scheme in the low SNR regime, while becomes inferior to the MRC/MRT scheme in the high SNR regime. Finally, in the large N regime, we show that both the ZF/MRT and MMSE/MRT schemes are capable of completely eliminating the CCI, while perfect interference cancelation is not possible with the MRC/MRT scheme.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "MRT",
        "schemes",
        "relay antennas",
        "multiple antennas",
        "MRC",
        "ZF/MRT",
        "MMSE/MRT",
        "ZF/MRT scheme",
        "ZF",
        "MMSE/MRT schemes",
        "perfect interference cancelation",
        "CCI",
        "SNR",
        "heuristic relay precoding schemes",
        "maximal ratio",
        "MRC/MRT",
        "additive white Gaussian noise",
        "MMSE/MRT scheme",
        "co-channel interference",
        "new exact outage expressions"
      ]
    },
    "org": {
      "title": "On the Capacity Limit of Wireless Channels Under Colored Scattering",
      "url": "https://www.semanticscholar.org/paper/5c29d5cbe73d51ff30cf5daecb4b6328cb877ccb",
      "abstract": "It has been generally believed that the multiple-input multiple-output channel capacity grows linearly with the size of antenna arrays. In terms of degrees of freedom, linear transmit and receive arrays of length L in a scattering environment of total angular spread \\\u03a9\\ asymptotically have \\\u03a9\\L degrees of freedom. In this paper, it is claimed that the linear increase in degrees of freedom may not be attained when scattered electromagnetic fields in the underlying scattering environment are statistically correlated. After introducing a model of correlated scattering, which is referred to as the colored scattering model, we derive a capacity upper bound, assuming that the channel is known perfectly at the receiver and in distribution at the transmitter. Unlike the uncorrelated case, the prelog factor of the capacity, i.e., the number of degrees of freedom, in the colored scattering channel is asymptotically limited by \\\u03a9\\\u00b7min{L, 1/ \u0393I} where \u0393 is a parameter determining the extent of correlation. In other words, for very large arrays in the colored scattering environment, degrees of freedom can get saturated to an intrinsic limit rather than increasing linearly with the array size.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Physics"
      ],
      "topics": [
        "arrays",
        "freedom",
        "degrees",
        "total angular spread \\\u03a9\\",
        "underlying scattering environment",
        "colored scattering channel",
        "length L",
        "colored scattering model",
        "scattering environment",
        "correlation",
        "scattered electromagnetic fields",
        "array size",
        "antenna",
        "antenna arrays",
        "correlated scattering",
        "total angular spread",
        "linear transmit and receive arrays"
      ]
    }
  },
  {
    "sim": 0.6247196819422954,
    "gen": {
      "title": "Spectral Hashing",
      "url": "https://www.semanticscholar.org/paper/8a4fb7c39fde7ae172f35cd68a802de168cd4466",
      "abstract": "Semantic hashing[1] seeks compact binary codes of data-points so that the Hamming distance between codewords correlates with semantic similarity. In this paper, we show that the problem of finding a best code for a given dataset is closely related to the problem of graph partitioning and can be shown to be NP hard. By relaxing the original problem, we obtain a spectral method whose solutions are simply a subset of thresholded eigenvectors of the graph Laplacian. By utilizing recent results on convergence of graph Laplacian eigenvectors to the Laplace-Beltrami eigenfunctions of manifolds, we show how to efficiently calculate the code of a novel data-point. Taken together, both learning the code and applying it to a novel point are extremely simple. Our experiments show that our codes outperform the state-of-the art.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "compact binary codes",
        "graph Laplacian eigenvectors",
        "semantic similarity",
        "graph partitioning",
        "thresholded eigenvectors",
        "Semantic hashing[1",
        "codewords",
        "Hamming",
        "manifolds",
        "NP",
        "novel point",
        "Laplacian",
        "Laplace",
        "data-points",
        "best code",
        "novel data-point",
        "Hamming distance",
        "recent results"
      ]
    },
    "org": {
      "title": "Efficient Symmetric Norm Regression via Linear Sketching",
      "url": "https://www.semanticscholar.org/paper/43a416f9b3fe5f35fce8df76c594790dbed11c11",
      "abstract": "We provide efficient algorithms for overconstrained linear regression problems with size $n \\times d$ when the loss function is a symmetric norm (a norm invariant under sign-flips and coordinate-permutations). An important class of symmetric norms are Orlicz norms, where for a function $G$ and a vector $y \\in \\mathbb{R}^n$, the corresponding Orlicz norm $\\|y\\|_G$ is defined as the unique value $\\alpha$ such that $\\sum_{i=1}^n G(|y_i|/\\alpha) = 1$. When the loss function is an Orlicz norm, our algorithm produces a $(1 + \\varepsilon)$-approximate solution for an arbitrarily small constant $\\varepsilon > 0$ in input-sparsity time, improving over the previously best-known algorithm which produces a $d \\cdot \\polylog n$-approximate solution. When the loss function is a general symmetric norm, our algorithm produces a $\\sqrt{d} \\cdot \\polylog n \\cdot \\mathrm{mmc}(\\ell)$-approximate solution in input-sparsity time, where $\\mathrm{mmc}(\\ell)$ is a quantity related to the symmetric norm under consideration. To the best of our knowledge, this is the first input-sparsity time algorithm with provable guarantees for the general class of symmetric norm regression problem. Our results shed light on resolving the universal sketching problem for linear regression, and the techniques might be of independent interest to numerical linear algebra problems more broadly.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "symmetric norm regression problem",
        "overconstrained linear regression problems",
        "numerical linear algebra problems",
        "linear regression",
        "efficient algorithms",
        "corresponding Orlicz norm",
        "independent interest",
        "symmetric norm",
        "input-sparsity time",
        "Orlicz",
        "Orlicz norm",
        "Orlicz norms",
        "input-sparsity time algorithm"
      ]
    }
  },
  null,
  {
    "sim": 0.491409815131991,
    "gen": {
      "title": "Robotics 2019: Agent-embedded robots with machine intelligence - JongHwan Kim - Korea Advanced Institute of Science and Technology",
      "url": "https://www.semanticscholar.org/paper/127c104f200e9527ce4fcd22948134e04e84f160",
      "abstract": "To increase agent-embedded robots with system intelligence (MI), the design of intelligence working architecture (IOA) is needed for sensing, wondering and movement. One of the key modules in IOA is the reminiscence module for storing temporal occasion sequences of responsibilities, the mechanism of idea for reasoning, and movement making plans for execution, amongst others. This talk introduces how to increase agent embedded robots with MI primarily based on IOA, that specialize in long-term reminiscence for lively expertise acquisition and adaptive know-how application. The lengthyterm reminiscence is advanced as an integrated multireminiscence neural model, wherein episodic memory is designed the use of a Deep DRN (Developmental Resonance Network) neural model and semantic memory is constructed the usage of the DRN-tree. Procedural reminiscence is likewise designed using the context-based RNN (recurrent neural community) to keep the trajectories of the manipulators at the side of context facts and then retrieve them in step with the context without conscious thinking. Robots are taught both via human demonstration or symbolic description. A conduct suitable to the modern situation is selected with the aid of the mechanism of concept discovered through device intelligence studying, at the same time as a proper challenge is retrieved from the Deep DRN model. The behaviors are done safely and fast with the movement planning set of rules. The effectiveness of the agent-embedded robot improvement is demonstrated thru experiments with a humanoid robot, Mybot, evolved in the Robot Intelligence Technology Lab. At KAIST, Agent embedded Mybot is introduced specifically for herbal interactions such as VQA (Visual Question Answering) with human beings. In the remaining part, AI World Cup shall be delivered, which has three classes, AI Soccer, AI Commentator, and AI Reporter.\u00a0 \n\u00a0 \nRobots are machines or mechanical human beings which are designed to help humans with arduous and complex duties. However, such robots aren't any greater simply mechanical layout rather they've emerge as smarter with time and development of technologies. AI developments have precipitated evolution and higher ability in robots. Even robotics and AI together can revolutionize nearly any industry for the more desirable. Artificial intelligence (AI) and robotics have turn out to be more and more hot subjects in the press and in academia. In October 2017, Bloomberg published a piece of writing claiming that artificial intelligence is probably to be the \u201cmost disruptive pressure in technology inside the coming decade\u201d and caution that corporations which are sluggish to embody the technology may additionally risk extinction. Similarly, the subsequent month, the Financial Times declared\u00a0 \nthat the \u201crobotic navy\u201d is remodeling the worldwide place of work. This hobby is possibly due to the speedy gains that synthetic intelligence has been making in some programs, inclusive of photo recognition and abstract strategy games, and that advanced robotics has been making in labs, despite the fact that vast industrial applications can be lagging. Scholars were more and more interested in the monetary, social, and distributive implications of synthetic intelligence, robotics, and other kinds of automation. For instance, over the last 2\u2009years, economists at the University of Toronto have convened meetings across the economics of artificial intelligence, which have been attended by means of a spectacular array of economics pupils from numerous factor of views inclusive of Nobel Prize winners Edmund Phelps, Paul Romer, Joseph Stiglit Some research has taken a morez, and others. There are some of well-attended meetings for felony, manufacturing, technical, and well known-interest groups which includes the World Conference on Robotics and Artificial Intelligence, We Robot, and AI Now. Organizational students are a chunk overdue to the sport and have only just started out to awareness on the organizational implications of artificial intelligence, robotics, and different kinds of advanced technology. However, as we describe on this primer, we believe that these technology present a completely unique opportunity for organizational pupils. Periods of high-quality technological exchange can result in first-rate development but also incredible turmoil. For example, while the steam engine caused superb monetary increase.\u00a0 \n\u00a0 \nWhile many instructions can be drawn from previous episodes of automation, it's miles possible that synthetic intelligence and robotics may have precise results. Differences from previous episodes of automation encompass that the character of business hobby has shifted dramatically over the past decade such that many companies now depend on platform (i.e., 2sided marketplace) business models, artificial intelligence is likely to have an effect on white-collar people more so than blue-collar people (whilst perhaps robotics may also have an effect on blue-collar workers extra than white-collar people), and artificial intelligence may additionally have an effect on the links between establishments and companies.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "artificial intelligence",
        "system intelligence",
        "intelligence working architecture",
        "neural model",
        "advanced robotics",
        "AI developments",
        "advanced technology",
        "AI World Cup",
        "AI Reporter",
        "AI Commentator",
        "AI Soccer",
        "AI",
        "robotics",
        "technologies"
      ]
    },
    "org": {
      "title": "Scalable End-to-end Recurrent Neural Network for Variable star classification",
      "url": "https://www.semanticscholar.org/paper/448e2ab483ec7f9de16341a18a6546db57113e20",
      "abstract": "\n During the last decade, considerable effort has been made to perform automatic classification of variable stars using machine-learning techniques. Traditionally, light curves are represented as a vector of descriptors or features used as input for many algorithms. Some features are computationally expensive, cannot be updated quickly and hence for large data sets such as the LSST cannot be applied. Previous work has been done to develop alternative unsupervised feature extraction algorithms for light curves, but the cost of doing so still remains high. In this work, we propose an end-to-end algorithm that automatically learns the representation of light curves that allows an accurate automatic classification. We study a series of deep learning architectures based on recurrent neural networks and test them in automated classification scenarios. Our method uses minimal data pre-processing, can be updated with a low computational cost for new observations and light curves, and can scale up to massive data sets. We transform each light curve into an input matrix representation whose elements are the differences in time and magnitude, and the outputs are classification probabilities. We test our method in three surveys: OGLE-III, Gaia, and WISE. We obtain accuracies of about $95{{\\ \\rm per\\ cent}}$ in the main classes and $75{{\\ \\rm per\\ cent}}$ in the majority of subclasses. We compare our results with the Random Forest classifier and obtain competitive accuracies while being faster and scalable. The analysis shows that the computational complexity of our approach grows up linearly with the light-curve size, while the traditional approach cost grows as Nlog\u2009(N).",
      "fieldsOfStudy": [
        "Physics",
        "Computer Science"
      ],
      "topics": [
        "light curves",
        "classification probabilities",
        "automated classification scenarios",
        "massive data sets",
        "large data sets",
        "alternative unsupervised feature extraction algorithms",
        "variable stars",
        "algorithms",
        "recurrent neural networks",
        "light curve",
        "new observations",
        "accurate automatic classification",
        "LSST",
        "minimal data pre",
        "subclasses",
        "WISE"
      ]
    }
  },
  {
    "sim": 0.6357110969319995,
    "gen": {
      "title": "Numerical methods for stochastic Volterra integral equations with weakly singular kernels",
      "url": "https://www.semanticscholar.org/paper/c65caee9bcb33530978150e45207841d7aae8b96",
      "abstract": "In this paper, we first establish the existence, uniqueness and Holder continuity of the solution to stochastic Volterra integral equations with weakly singular kernels. Then, we propose a $\\theta$-Euler-Maruyama scheme and a Milstein scheme to solve the equations numerically and we obtain the strong rates of convergence for both schemes in $L^{p}$ norm for any $p\\geq 1$. For the $\\theta$-Euler-Maruyama scheme the rate is $\\min\\{1-\\alpha,\\frac{1}{2}-\\beta\\}~ % (0<\\alpha<1, 0< \\beta<\\frac{1}{2})$ and for the Milstein scheme the rate is $\\min\\{1-\\alpha,1-2\\beta\\}$ when $\\alpha\\neq \\frac 12$, where $(0<\\alpha<1, 0< \\beta<\\frac{1}{2})$. These results on the rates of convergence are significantly different from that of the similar schemes for the stochastic Volterra integral equations with regular kernels. The difficulty to obtain our results is the lack of Ito formula for the equations. To get around of this difficulty we use instead the Taylor formula and then carry a sophisticated analysis on the equation the solution satisfies.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "Volterra integral equations",
        "weakly singular kernels",
        "regular kernels",
        "stochastic Volterra integral equations",
        "Volterra",
        "Ito formula",
        "convergence",
        "0<\\alpha<1",
        "Milstein scheme",
        "similar schemes",
        "strong rates",
        "equations",
        "\\frac",
        "Milstein",
        "Holder continuity"
      ]
    },
    "org": {
      "title": "Two-level a posteriori error estimation for adaptive multilevel stochastic Galerkin FEM",
      "url": "https://www.semanticscholar.org/paper/41904fdd3eb3c2e11a3658dfb81e93fab8d7f032",
      "abstract": "The paper considers a class of parametric elliptic partial differential equations (PDEs), where the coefficients and the right-hand side function depend on infinitely many (uncertain) parameters. We introduce a two-level a posteriori estimator to control the energy error in multilevel stochastic Galerkin approximations for this class of PDE problems. We prove that the two-level estimator always provides a lower bound for the unknown approximation error, while the upper bound is equivalent to a saturation assumption. We propose and empirically compare three adaptive algorithms, where the structure of the estimator is exploited to perform spatial refinement as well as parametric enrichment. The paper also discusses implementation aspects of computing multilevel stochastic Galerkin approximations.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "computing multilevel stochastic Galerkin approximations",
        "parametric elliptic partial differential equations",
        "PDE problems",
        "parametric enrichment",
        "Galerkin",
        "spatial refinement",
        "unknown approximation error",
        "PDE",
        "saturation assumption",
        "right-hand side function",
        "implementation aspects",
        "infinitely many (uncertain) parameters",
        "upper bound",
        "multilevel stochastic Galerkin approximations",
        "PDEs",
        "lower bound",
        "energy error"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.5147252380947399,
    "gen": {
      "title": "A Game-Theoretic Framework for Autonomous Vehicles Velocity Control: Bridging Microscopic Differential Games and Macroscopic Mean Field Games",
      "url": "https://www.semanticscholar.org/paper/0e94f242d5cd3d8a907c83559ab4fac501228132",
      "abstract": "This paper proposes an efficient computational framework for longitudinal velocity control of a large number of autonomous vehicles (AVs) and develops a traffic flow theory for AVs. Instead of hypothesizing explicitly how AVs drive, our goal is to design future AVs as rational, utility-optimizing agents that continuously select optimal velocity over a period of planning horizon. With a large number of interacting AVs, this design problem can become computationally intractable. This paper aims to tackle such a challenge by employing mean field approximation and deriving a mean field game (MFG) as the limiting differential game with an infinite number of agents. The proposed micro-macro model allows one to define individuals on a microscopic level as utility-optimizing agents while translating rich microscopic behaviors to macroscopic models. Different from existing studies on the application of MFG to traffic flow models, the present study offers a systematic framework to apply MFG to autonomous vehicle velocity control. The MFG-based AV controller is shown to mitigate traffic jam faster than the LWR-based controller. MFG also embodies classical traffic flow models with behavioral interpretation, thereby providing a new traffic flow theory for AVs.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Physics"
      ],
      "topics": [
        "traffic flow models",
        "classical traffic flow models",
        "future AVs",
        "AVs",
        "interacting AVs",
        "traffic jam",
        "autonomous vehicle velocity control",
        "macroscopic models",
        "longitudinal velocity control",
        "rich microscopic behaviors",
        "optimal velocity",
        "planning horizon",
        "autonomous vehicles",
        "agents",
        "new traffic flow theory"
      ]
    },
    "org": {
      "title": "On Adaptive Influence Maximization Under General Feedback Models",
      "url": "https://www.semanticscholar.org/paper/d12579374da0f7a0d248c1ad7b6da0a9b8317a66",
      "abstract": "The classic influence maximization problem explores the strategies for deploying cascades such that the total influence is maximized, and it assumes that the seed nodes that initiate the cascades are computed prior to the diffusion process. In its adaptive version, the seed nodes are allowed to be launched in an adaptive manner after observing certain diffusion results. In this article, we provide a systematic study on the adaptive influence maximization problem, focusing on the algorithmic analysis of the general feedback models. We introduce the concept of regret ratio to characterize the key trade-off in designing adaptive seeding strategies, based on which we present the approximation analysis for the well-known greedy policy. In addition, we provide analysis concerning improving the efficiencies and bounding the regret ratio. Finally, we propose several future research directions.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "adaptive seeding strategies",
        "certain diffusion results",
        "analysis",
        "future research directions",
        "cascades",
        "The classic influence maximization problem",
        "diffusion process",
        "general feedback models",
        "adaptive manner",
        "approximation analysis",
        "adaptive version",
        "regret ratio",
        "seed nodes"
      ]
    }
  },
  {
    "sim": 0.5013345095322871,
    "gen": {
      "title": "A Characterization of Undirected Graphs Admitting Optimal Cost Shares",
      "url": "https://www.semanticscholar.org/paper/442192bbd7fbd30838ec3f7519ebf2de6860719c",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ]
    },
    "org": {
      "title": "Un-unzippable Convex Caps",
      "url": "https://www.semanticscholar.org/paper/dd324719c23235e10fdf5bfa41cbb7cb678d02cc",
      "abstract": "An unzipping of a polyhedron P is a cut-path through its vertices that unfolds P to a non-overlapping shape in the plane. It is an open problem to decide if every convex P has an unzipping. Here we show that there are nearly flat convex caps that have no unzipping. A convex cap is a \"top\" portion of a convex polyhedron; it has a boundary, i.e., it is not closed by a base.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "non-overlapping shape",
        "polyhedron P",
        "convex P",
        "nearly flat convex caps",
        "plane",
        "convex polyhedron",
        "base",
        "A convex cap",
        "unzipping",
        "cut-path",
        "vertices",
        "open problem",
        "boundary"
      ]
    }
  },
  {
    "sim": 0.21857808569115822,
    "gen": {
      "title": "A recurrent neural network without chaos",
      "url": "https://www.semanticscholar.org/paper/f451d0212e65ab9970a58b584b3363a853c9811c",
      "abstract": "We introduce an exceptionally simple gated recurrent neural network (RNN) that achieves performance comparable to well-known gated architectures, such as LSTMs and GRUs, on the word-level language modeling task. We prove that our model has simple, predicable and non-chaotic dynamics. This stands in stark contrast to more standard gated architectures, whose underlying dynamical systems exhibit chaotic behavior.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "chaotic behavior",
        "word-level language modeling task",
        "GRUs",
        "performance",
        "standard gated architectures",
        "LSTMs",
        "simple, predicable and non-chaotic dynamics",
        "RNN",
        "stark contrast",
        "underlying dynamical systems",
        "exceptionally simple gated recurrent neural network",
        "well-known gated architectures",
        "model",
        "This"
      ]
    },
    "org": {
      "title": "A two-stage algorithm for aircraft conflict resolution with trajectory recovery",
      "url": "https://www.semanticscholar.org/paper/3074b8bdddde9e33deb3fc0c02266cbf97f2284e",
      "abstract": "As air traffic volume is continuously increasing, it has become a priority to improve traffic control algorithms to handle future air travel demand and improve airspace capacity. We address the conflict resolution problem in air traffic control using a novel approach for aircraft collision avoidance with trajectory recovery. We present a two-stage algorithm that first solves all initial conflicts by adjusting aircraft headings and speeds, before identifying the optimal time for aircraft to recover towards their target destination. The collision avoidance stage extends an existing mixed-integer programming formulation to heading control. For the trajectory recovery stage, we introduce a novel exact mixed-integer programming formulation as well as a greedy heuristic algorithm. The proposed two-stage approach guarantees that all trajectories during both the collision avoidance and recovery stages are conflict-free. Numerical results on benchmark problems show that the proposed heuristic for trajectory recovery is competitive while also emphasizing the difficulty of this optimization problem. The proposed approach can be used as a decision-support tool for introducing automation in air traffic control.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "air traffic control",
        "air traffic volume",
        "future air travel demand",
        "aircraft collision avoidance",
        "control",
        "aircraft headings",
        "trajectory recovery",
        "airspace capacity",
        "recovery stages",
        "aircraft",
        "benchmark problems",
        "trajectory recovery stage",
        "conflict resolution problem",
        "novel exact mixed-integer programming formulation",
        "speeds",
        "traffic control algorithms",
        "heading control",
        "greedy heuristic algorithm"
      ]
    }
  },
  {
    "sim": 0.51745337805948,
    "gen": {
      "title": "Correction to: On the\u00a0achievable rate of bandlimited continuous-time AWGN channels with 1-bit output quantization",
      "url": "https://www.semanticscholar.org/paper/ea9d699844725ac25f1802df8a374d26d427a10b",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    },
    "org": {
      "title": "Models and Information Rates for Wiener Phase Noise Channels",
      "url": "https://www.semanticscholar.org/paper/03a9d8bbbbe0e2803f08ffd9bb316721edfd97da",
      "abstract": "A waveform channel is considered where the transmitted signal is corrupted by Wiener phase noise and additive white Gaussian noise. A discrete-time channel model that considers the effect of filtering on the phase noise is developed. The model is based on a multi-sample receiver, i.e., an integrate-and-dump filter whose output is sampled at a rate higher than the signaling rate. It is shown that, at high Signal-to-Noise Ratio (SNR), the multi-sample receiver achieves a rate that grows logarithmically with the SNR if the number of samples per symbol (oversampling factor) grows with the cubic root of the SNR. Moreover, the pre-log factor is at least 1/2 and can be achieved by amplitude modulation. For an approximate discrete-time model of the multi-sample receiver, the capacity pre-log at high SNR is shown to be at least 3/4 if the number of samples per symbol grows with the square root of the SNR. The analysis shows that phase modulation achieves a pre-log of at least 1/4, while amplitude modulation still achieves a pre-log of 1/2. This is strictly greater than the capacity pre-log of the (approximate) discrete-time Wiener phase noise channel with only one sample per symbol, which is 1/2. Numerical simulations are used to compute lower bounds on the information rates achieved by the multi-sample receiver. The simulations show that oversampling is beneficial for both strong and weak phase noise at high SNR. In fact, the information rates are sometimes substantially larger than when using commonly-used approximate discrete-time models.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "high SNR",
        "SNR",
        "Wiener phase noise",
        "additive white Gaussian noise",
        "phase modulation",
        "amplitude modulation",
        "symbol",
        "samples",
        "multi-sample receiver",
        "log",
        "phase noise",
        "SNR",
        "pre-log factor",
        "oversampling factor"
      ]
    }
  },
  {
    "sim": 0.7108833405922491,
    "gen": {
      "title": "Learning Robust Global Representations by Penalizing Local Predictive Power",
      "url": "https://www.semanticscholar.org/paper/4ae0c4a511697e960c477ea3e37b3e11bf3e0e02",
      "abstract": "Despite their renowned predictive power on i.i.d. data, convolutional neural networks are known to rely more on high-frequency patterns that humans deem superficial than on low-frequency patterns that agree better with intuitions about what constitutes category membership. This paper proposes a method for training robust convolutional networks by penalizing the predictive power of the local representations learned by earlier layers. Intuitively, our networks are forced to discard predictive signals such as color and texture that can be gleaned from local receptive fields and to rely instead on the global structures of the image. Across a battery of synthetic and benchmark domain adaptation tasks, our method confers improved generalization out of the domain. Also, to evaluate cross-domain transfer, we introduce ImageNet-Sketch, a new dataset consisting of sketch-like images, that matches the ImageNet classification validation set in categories and scale.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "category membership",
        "categories",
        "scale",
        "local receptive fields",
        "earlier layers",
        "ImageNet",
        "convolutional neural networks",
        "ImageNet classification validation",
        "synthetic and benchmark domain adaptation tasks",
        "predictive signals",
        "generalization",
        "sketch-like images",
        "low-frequency patterns",
        "cross-domain transfer",
        "robust convolutional networks",
        "improved generalization",
        "ImageNet classification validation set",
        "i.i.d. data"
      ]
    },
    "org": {
      "title": "Zero-Shot Recognition via Semantic Embeddings and Knowledge Graphs",
      "url": "https://www.semanticscholar.org/paper/ff65e3bf34e892ef75d91c5e3d7294e0b64d867d",
      "abstract": "We consider the problem of zero-shot recognition: learning a visual classifier for a category with zero training examples, just using the word embedding of the category and its relationship to other categories, which visual data are provided. The key to dealing with the unfamiliar or novel category is to transfer knowledge obtained from familiar classes to describe the unfamiliar class. In this paper, we build upon the recently introduced Graph Convolutional Network (GCN) and propose an approach that uses both semantic embeddings and the categorical relationships to predict the classifiers. Given a learned knowledge graph (KG), our approach takes as input semantic embeddings for each node (representing visual category). After a series of graph convolutions, we predict the visual classifier for each category. During training, the visual classifiers for a few categories are given to learn the GCN parameters. At test time, these filters are used to predict the visual classifiers of unseen categories. We show that our approach is robust to noise in the KG. More importantly, our approach provides significant improvement in performance compared to the current state-of-the-art results (from 2 ~ 3% on some metrics to whopping 20% on a few).",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "representing visual category",
        "categories",
        "unseen categories",
        "visual data",
        "familiar classes",
        "semantic embeddings",
        "categories",
        "significant improvement",
        "knowledge",
        "visual classifiers",
        "category",
        "category",
        "visual category"
      ]
    }
  },
  {
    "sim": 0.6561674561620519,
    "gen": {
      "title": "Multicarrier delay diversity modulation for MIMO systems",
      "url": "https://www.semanticscholar.org/paper/1114f92b746cceaa17e11e726df5ff0eab56f4a8",
      "abstract": "Multicarrier delay diversity modulation (MDDM) is a scheme that uses orthogonal frequency division multiplexing (OFDM) on a \"multipath\" channel that is generated by using delay diversity. The full diversity criterion for MDDM is proven and illustrative examples of full-diversity codes are obtained based on the established criterion. Coding gains and interleaver designs are also considered and analyzed. Simulation results for MDDM on quasi-static flat and frequency-selective fading channels are discussed. MDDM is established as a strong competitive technique to existing space-time block codes and space-time tellis codes techniques for multiple input multiple output systems.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "delay diversity",
        "multiple input multiple output systems",
        "diversity modulation",
        "orthogonal frequency division multiplexing",
        "illustrative examples",
        "MDDM",
        "existing space-time block codes",
        "full-diversity codes",
        "The full diversity criterion",
        "techniques",
        "quasi-static flat and frequency-selective fading channels",
        "Coding gains",
        "OFDM",
        "space-time tellis",
        "tellis",
        "Multicarrier delay diversity modulation",
        "space-time tellis codes techniques",
        "strong competitive technique",
        "interleaver designs",
        "established criterion"
      ]
    },
    "org": {
      "title": "Distributed Space-Time Coding for Full-Duplex Asynchronous Cooperative Communications",
      "url": "https://www.semanticscholar.org/paper/6a1c3c48e7e7a39fa75428f9fdd4f07e99fa3259",
      "abstract": "In this paper, we propose two distributed linear convolutional space-time coding (DLC-STC) schemes for full-duplex (FD) asynchronous cooperative communications. The DLC-STC Scheme 1 is for the case of the complete loop channel cancellation, which achieves the full asynchronous cooperative diversity. The DLC-STC Scheme 2 is for the case of the partial loop channel cancellation and amplifying, where some loop signals are used as the self-coding instead of treated as interference to be directly cancelled. We show this scheme can achieve full asynchronous cooperative diversity. We then evaluate the performance of the two schemes when loop channel information is not accurate and present an amplifying factor control method for the DLC-STC Scheme 2 to improve its performance with inaccurate loop channel information. Simulation results show that the DLC-STC Scheme 1 outperforms the DLC-STC Scheme 2 and the delay diversity scheme if perfect or high quality loop channel information is available at the relay, while the DLC-STC Scheme 2 achieves better performance if the loop channel information is imperfect.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "inaccurate loop channel information",
        "perfect or high quality loop channel information",
        "loop channel information",
        "complete loop channel cancellation",
        "partial loop channel cancellation",
        "asynchronous cooperative diversity",
        "better performance",
        "delay diversity scheme",
        "loop signals",
        "The DLC-STC Scheme",
        "amplifying factor control method",
        "interference",
        "DLC-STC Scheme"
      ]
    }
  },
  {
    "sim": 0.34076132105176127,
    "gen": {
      "title": "A Weakly Non-hydrostatic Shallow Model for Dry Granular Flows",
      "url": "https://www.semanticscholar.org/paper/386e08f22fca8ce8d840ff8a2ceee278ea03b0bf",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Physics",
        "Mathematics"
      ]
    },
    "org": {
      "title": "Power Law in Sparsified Deep Neural Networks",
      "url": "https://www.semanticscholar.org/paper/dc02d5d2cc9ece0415c48084286c037b78061fb2",
      "abstract": "The power law has been observed in the degree distributions of many biological neural networks. Sparse deep neural networks, which learn an economical representation from the data, resemble biological neural networks in many ways. In this paper, we study if these artificial networks also exhibit properties of the power law. Experimental results on two popular deep learning models, namely, multilayer perceptrons and convolutional neural networks, are affirmative. The power law is also naturally related to preferential attachment. To study the dynamical properties of deep networks in continual learning, we propose an internal preferential attachment model to explain how the network topology evolves. Experimental results show that with the arrival of a new task, the new connections made follow this preferential attachment process.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "biological neural networks",
        "resemble biological neural networks",
        "convolutional neural networks",
        "Sparse deep neural networks",
        "deep networks",
        "preferential attachment",
        "ways",
        "internal preferential attachment model",
        "continual learning",
        "network topology",
        "preferential attachment process",
        "artificial networks",
        "popular deep learning models",
        "properties",
        "economical representation"
      ]
    }
  },
  null,
  {
    "sim": 0.5701884107793612,
    "gen": {
      "title": "Graph Learning for Inverse Landscape Genetics",
      "url": "https://www.semanticscholar.org/paper/e3617f58dba10757e02cd60be40c23ecdd5b6d42",
      "abstract": "The problem of inferring unknown graph edges from numerical data at a graph's nodes appears in many forms across machine learning. We study a version of this problem that arises in the field of landscape genetics, where genetic similarity between organisms living in a heterogeneous landscape is explained by a weighted graph that encodes the ease of dispersal through that landscape. Our main contribution is an efficient algorithm for inverse landscape genetics, which is the task of inferring this graph from measurements of genetic similarity at different locations (graph nodes). \n\nInverse landscape genetics is important in discovering impediments to species dispersal that threaten biodiversity and long-term species survival. In particular, it is widely used to study the effects of climate change and human development. Drawing on influential work that models organism dispersal using graph effective resistances (McRae 2006), we reduce the inverse landscape genetics problem to that of inferring graph edges from noisy measurements of these resistances, which can be obtained from genetic similarity data. \n\nBuilding on the NeurIPS 2018 work of Hoskins et al. (2018) on learning edges in social networks, we develop an efficient first-order optimization method for solving this problem. Despite its non-convex nature, experiments on synthetic and real genetic data establish that our method provides fast and reliable convergence, significantly outperforming existing heuristics used in the field. By providing researchers with a powerful, general purpose algorithmic tool, we hope our work will have a positive impact on accelerating work on landscape genetics.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "inferring graph edges",
        "graph nodes",
        "graph effective resistances",
        "unknown graph edges",
        "genetic similarity",
        "machine learning",
        "organism dispersal",
        "inverse landscape genetics problem",
        "numerical data",
        "forms",
        "dispersal",
        "graph edges",
        "species dispersal"
      ]
    },
    "org": {
      "title": "Network Connectivity Under a Probabilistic Node Failure Model",
      "url": "https://www.semanticscholar.org/paper/d1f6c0bb0d78fbf0adb8f5c8f657c0670b2014c6",
      "abstract": "Node-removal processes are generally used to test network robustness against failures, to verify the strength of a power grid, or to contain fake news. Yet, a node-removal task is typically assumed to be always successful; we argue that this is unrealistic, and that the node strengths should also be considered to better accommodate network failure scenarios. We propose a <italic>probabilistic node failure model</italic>, considering two variants: <italic>Uniform</italic> nodes survival-to-failure probability; and <italic>Best Connected</italic>, i.e., survival probability proportional to node degree. Our evaluation considers five popular centrality metrics (degree, h-index, coreness, Eigenvector, Katz centrality), performing an experimental analysis on <italic>effectiveness</italic> and <italic>coverage</italic>, on eight real-world graphs. Specifically, the effectiveness is defined as the drop in the spectral radius <inline-formula><tex-math notation=\"LaTeX\">$\\lambda _{1}$</tex-math></inline-formula> after node removal, while the coverage is understood as the reduction of the size of the largest connected component <inline-formula><tex-math notation=\"LaTeX\">$c$</tex-math></inline-formula> of a graph. We find that the degree can generally be used to cause the biggest drop in both <inline-formula><tex-math notation=\"LaTeX\">$\\lambda _{1}$</tex-math></inline-formula> and <inline-formula><tex-math notation=\"LaTeX\">$c$</tex-math></inline-formula>, especially in graphs deriving from human interactions/collaborations. Comparing with conventional methods, our probabilistic model exhibits significant differences (ranging from 0% to 83%), highlighting the benefits of the proposed method.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "network failure scenarios",
        "human interactions",
        "collaborations",
        "graphs",
        "node removal",
        "fake news",
        "failures",
        "node degree",
        "significant differences",
        "network robustness",
        "conventional methods",
        "formula><tex-math",
        "italic>effectiveness</italic",
        "formula",
        "Katz centrality",
        "human interactions/collaborations",
        "degree"
      ]
    }
  },
  {
    "sim": 0.6378278223687719,
    "gen": {
      "title": "Deep Semantic Multimodal Hashing Network for Scalable Image-Text and Video-Text Retrievals.",
      "url": "https://www.semanticscholar.org/paper/e7c9d77abef94ffc0ec4d207d41b46e1c7901478",
      "abstract": "Hashing has been widely applied to multimodal retrieval on large-scale multimedia data due to its efficiency in computation and storage. In this article, we propose a novel deep semantic multimodal hashing network (DSMHN) for scalable image-text and video-text retrieval. The proposed deep hashing framework leverages 2-D convolutional neural networks (CNN) as the backbone network to capture the spatial information for image-text retrieval, while the 3-D CNN as the backbone network to capture the spatial and temporal information for video-text retrieval. In the DSMHN, two sets of modality-specific hash functions are jointly learned by explicitly preserving both intermodality similarities and intramodality semantic labels. Specifically, with the assumption that the learned hash codes should be optimal for the classification task, two stream networks are jointly trained to learn the hash functions by embedding the semantic labels on the resultant hash codes. Moreover, a unified deep multimodal hashing framework is proposed to learn compact and high-quality hash codes by exploiting the feature representation learning, intermodality similarity-preserving learning, semantic label-preserving learning, and hash function learning with different types of loss functions simultaneously. The proposed DSMHN method is a generic and scalable deep hashing framework for both image-text and video-text retrievals, which can be flexibly integrated with different types of loss functions. We conduct extensive experiments for both single-modal- and cross-modal-retrieval tasks on four widely used multimodal-retrieval data sets. Experimental results on both image-text- and video-text-retrieval tasks demonstrate that the DSMHN significantly outperforms the state-of-the-art methods.",
      "fieldsOfStudy": [
        "Computer Science",
        "Medicine"
      ],
      "topics": [
        "loss functions",
        "intramodality semantic labels",
        "multimodal retrieval",
        "semantic label-preserving learning",
        "different types",
        "network",
        "modality-specific hash functions",
        "learned hash codes",
        "intermodality similarity-preserving learning",
        "video-text retrieval",
        "image-text retrieval",
        "hash functions",
        "resultant hash codes",
        "storage",
        "hash function learning",
        "novel deep semantic multimodal hashing network"
      ]
    },
    "org": {
      "title": "Hi-Fi: Hierarchical Feature Integration for Skeleton Detection",
      "url": "https://www.semanticscholar.org/paper/93ecf2f9680d9f239cdca288eb80f2c3a7325787",
      "abstract": "In natural images, the scales (thickness) of object skeletons may\n\ndramatically vary among objects and object parts.\n\nThus, robust skeleton detection requires powerful multi-scale feature integration ability.\n\nTo address this issue, we present a new convolutional neural network (CNN) architecture\n\nby introducing a novel hierarchical feature integration mechanism,\n\nnamed Hi-Fi, to address the object skeleton detection problem.\n\nThe proposed CNN-based approach intrinsically captures high-level semantics from deeper layers,\n\nas well as low-level details from shallower layers.\n\nBy hierarchically integrating different CNN feature levels with bidirectional guidance,\n\nour approach (1) enables mutual refinement across features of different levels,\n\nand (2) possesses the strong ability to capture both rich object context\n\nand high-resolution details.\n\nExperimental results show that our method\n\nsignificantly outperforms the state-of-the-art methods\n\nin terms of effectively fusing features from very different scales,\n\nas evidenced by a considerable performance improvement on several benchmarks.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "shallower layers",
        "different CNN feature levels",
        "deeper layers",
        "different levels",
        "powerful multi-scale feature integration ability",
        "object parts",
        "object skeletons",
        "objects",
        "features",
        "low-level details",
        "Hi-Fi",
        "benchmarks",
        "high-level semantics",
        "high-resolution details",
        "novel hierarchical feature integration mechanism",
        "robust skeleton detection",
        "CNN",
        "object skeleton detection problem",
        "rich object context"
      ]
    }
  },
  {
    "sim": 0.6477474320600907,
    "gen": {
      "title": "Improving Sequential Recommendation with Knowledge-Enhanced Memory Networks",
      "url": "https://www.semanticscholar.org/paper/f4e5af510c63ecb84c4619b9fc12a2d26a3c8d40",
      "abstract": "With the revival of neural networks, many studies try to adapt powerful sequential neural models, \u0131e Recurrent Neural Networks (RNN), to sequential recommendation. RNN-based networks encode historical interaction records into a hidden state vector. Although the state vector is able to encode sequential dependency, it still has limited representation power in capturing complicated user preference. It is difficult to capture fine-grained user preference from the interaction sequence. Furthermore, the latent vector representation is usually hard to understand and explain. To address these issues, in this paper, we propose a novel knowledge enhanced sequential recommender. Our model integrates the RNN-based networks with Key-Value Memory Network (KV-MN). We further incorporate knowledge base (KB) information to enhance the semantic representation of KV-MN. RNN-based models are good at capturing sequential user preference, while knowledge-enhanced KV-MNs are good at capturing attribute-level user preference. By using a hybrid of RNNs and KV-MNs, it is expected to be endowed with both benefits from these two components. The sequential preference representation together with the attribute-level preference representation are combined as the final representation of user preference. With the incorporation of KB information, our model is also highly interpretable. To our knowledge, it is the first time that sequential recommender is integrated with external memories by leveraging large-scale KB information.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "sequential user preference",
        "user preference",
        "complicated user preference",
        "limited representation power",
        "powerful sequential neural models",
        "sequential dependency",
        "sequential recommendation",
        "capturing attribute-level user preference",
        "The sequential preference representation",
        "KB information",
        "KV",
        "novel knowledge enhanced sequential recommender",
        "historical interaction records",
        "attribute-level user preference",
        "attribute-level preference representation",
        "neural networks"
      ]
    },
    "org": {
      "title": "Constructing a Highlight Classifier with an Attention Based LSTM Neural Network",
      "url": "https://www.semanticscholar.org/paper/309a35019fe96bca4be784b6b920c4a666f6bd68",
      "abstract": "Data is being produced in larger quantities than ever before in human history. It's only natural to expect a rise in demand for technology that aids humans in sifting through and analyzing this inexhaustible supply of information. This need exists in the market research industry, where large amounts of consumer research data is collected through video recordings. At present, the standard method for analyzing video data is human labor. Market researchers manually review the vast majority of consumer research video in order to identify relevant portions - highlights. The industry state of the art turnaround ratio is 2.2 - for every hour of video content 2.2 hours of manpower are required. In this study we present a novel approach for NLP-based highlight identification and extraction based on a supervised learning model that aides market researchers in sifting through their data. Our approach hinges on a manually curated user-generated highlight clips constructed from long and short-form video data. The problem is best suited for an NLP approach due to the availability of video transcription. We evaluate multiple classes of models, from gradient boosting to recurrent neural networks, comparing their performance in extraction and identification of highlights. The best performing models are then evaluated using four sampling methods designed to analyze documents much larger than the maximum input length of the classifiers. We report very high performances for the standalone classifiers, ROC AUC scores in the range 0.93-0.94, but observe a significant drop in effectiveness when evaluated on large documents. Based on our results we suggest combinations of models/sampling algorithms for various use cases.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "video data",
        "consumer research video",
        "video recordings",
        "consumer research data",
        "video content",
        "video transcription",
        "large documents",
        "highlights",
        "larger quantities",
        "ROC AUC scores",
        "Data",
        "large amounts",
        "human history",
        "human labor",
        "ROC AUC",
        "use cases"
      ]
    }
  },
  {
    "sim": 0.4914684052477458,
    "gen": {
      "title": "Fast Global Convergence for Low-rank Matrix Recovery via Riemannian Gradient Descent with Random Initialization",
      "url": "https://www.semanticscholar.org/paper/1423031585b73ea317463db778302d01108e7cba",
      "abstract": "In this paper, we propose a new global analysis framework for a class of low-rank matrix recovery problems on the Riemannian manifold. We analyze the global behavior for the Riemannian optimization with random initialization. We use the Riemannian gradient descent algorithm to minimize a least squares loss function, and study the asymptotic behavior as well as the exact convergence rate. We reveal a previously unknown geometric property of the low-rank matrix manifold, which is the existence of spurious critical points for the simple least squares function on the manifold. We show that under some assumptions, the Riemannian gradient descent starting from a random initialization with high probability avoids these spurious critical points and only converges to the ground truth in nearly linear convergence rate, i.e. $\\mathcal{O}(\\text{log}(\\frac{1}{\\epsilon})+ \\text{log}(n))$ iterations to reach an $\\epsilon$-accurate solution. We use two applications as examples for our global analysis. The first one is a rank-1 matrix recovery problem. The second one is a generalization of the Gaussian phase retrieval problem. It only satisfies the weak isometry property, but has behavior similar to that of the first one except for an extra saddle set. Our convergence guarantee is nearly optimal and almost dimension-free, which fully explains the numerical observations. The global analysis can be potentially extended to other data problems with random measurement structures and empirical least squares loss functions.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "spurious critical points",
        "random measurement structures",
        "random initialization",
        "data problems",
        "squares loss function",
        "behavior",
        "high probability",
        "\\epsilon$-accurate",
        "low-rank matrix recovery problems",
        "iterations",
        "Riemannian",
        "simple least squares",
        "exact convergence rate",
        "nearly linear convergence rate",
        "simple least squares function",
        "Riemannian manifold"
      ]
    },
    "org": {
      "title": "Exponential Time Differencing for the Tracer Equations Appearing in Primitive Equation Ocean Models",
      "url": "https://www.semanticscholar.org/paper/754025b4f4d75a8acbd2e24ff8c267abbba7e7f8",
      "abstract": null,
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science",
        "Physics"
      ]
    }
  },
  {
    "sim": 0.4332437961304414,
    "gen": {
      "title": "A novel fractional order fuzzy PID controller and its optimal time domain tuning based on integral performance indices",
      "url": "https://www.semanticscholar.org/paper/820f61a3c1d35d40e8ff780c2785067c008cbeda",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    },
    "org": {
      "title": "Signal-Based Properties: Taxonomy and Logic-based Characterization",
      "url": "https://www.semanticscholar.org/paper/7327aa2d1d3f3909609f6025169924887425aa83",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
      ]
    }
  },
  {
    "sim": 0.46194762515939747,
    "gen": {
      "title": "Structure-preserving Method for Reconstructing Unknown Hamiltonian Systems from Trajectory Data",
      "url": "https://www.semanticscholar.org/paper/65e53c158d4f171d700f654a346b23dabeafa225",
      "abstract": "We present a numerical approach for approximating unknown Hamiltonian systems using observation data. A distinct feature of the proposed method is that it is structure-preserving, in the sense that it enforces conservation of the reconstructed Hamiltonian. This is achieved by directly approximating the underlying unknown Hamiltonian, rather than the right-hand-side of the governing equations. We present the technical details of the proposed algorithm and its error estimate in a special case, along with a practical de-noising procedure to cope with noisy data. A set of numerical examples are then presented to demonstrate the structure-preserving property and effectiveness of the algorithm.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Physics"
      ],
      "topics": [
        "noisy data",
        "observation data",
        "practical de-noising procedure",
        "unknown Hamiltonian systems",
        "governing equations",
        "underlying unknown Hamiltonian",
        "effectiveness",
        "conservation",
        "reconstructed Hamiltonian",
        "numerical examples",
        "special case",
        "proposed algorithm",
        "error estimate",
        "structure-preserving property",
        "algorithm"
      ]
    },
    "org": {
      "title": "A universal negative group delay filter for the prediction of band-limited signals",
      "url": "https://www.semanticscholar.org/paper/c5edfd80c1a60b5f1ad790e75b45e4ee77e03863",
      "abstract": "A filter for universal real-time prediction of band-limited signals is presented. The filter consists of multiple time-delayed feedback terms in order to accomplish anticipatory coupling, which again leads to a negative group delay for frequencies in the baseband. The universality of the filter arises from its property that it does not rely on a specific model of the signal. Specifically, as long as the signal to be predicted is band-limited with a known cutoff frequency, the filter order, the only parameter of the filter, follows and the filter predicts the signal in real time up to a prediction horizon that depends on the cutoff frequency, too. It is worked out in detail how signal prediction arises from the negative group delay of the filter. Its properties, including stability, are investigated theoretically, by numerical simulations, and by application to a physiological signal. Possible control and signal processing applications of this filter are discussed.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "signal processing applications",
        "real time",
        "frequencies",
        "order",
        "anticipatory coupling",
        "signal prediction",
        "filter order",
        "band-limited signals",
        "universal real-time prediction",
        "known cutoff frequency",
        "application",
        "multiple time-delayed feedback terms",
        "negative group delay",
        "physiological signal",
        "Possible control and signal processing applications"
      ]
    }
  },
  {
    "sim": 0.7890095845421478,
    "gen": {
      "title": "Performance Analysis of Ambient RF Energy Harvesting with Repulsive Point Process Modeling",
      "url": "https://www.semanticscholar.org/paper/86ca8d0750954d4ca52be426549e782e37985111",
      "abstract": "Ambient radio frequency (RF) energy harvesting technique has recently been proposed as a potential solution for providing proactive energy replenishment for wireless devices. This paper aims to analyze the performance of a battery-free wireless sensor powered by ambient RF energy harvesting using a stochastic geometry approach. Specifically, we consider the point-to-point uplink transmission of a wireless sensor in a stochastic geometry network, where ambient RF sources, such as mobile transmit devices, access points and base stations, are distributed as a Ginibre \u03b1-determinantal point process (DPP). The DPP is able to capture repulsion among points, and hence, it is more general than the Poisson point process (PPP). We analyze two common receiver architectures: separated receiver and time-switching architectures. For each architecture, we consider the scenarios with and without co-channel interference for information transmission. We derive the expectation of the RF energy harvesting rate in closed form and also compute its variance. Moreover, we perform a worst-case study which derives the upper bound of both power and transmission outage probabilities. Additionally, we provide guidelines on the setting of optimal time-switching coefficient in the case of the time-switching architecture. Numerical results verify the correctness of the analysis and show various tradeoffs between parameter setting. Lastly, we prove that the RF-powered sensor performs better when the distribution of the ambient sources exhibits stronger repulsion.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "access points",
        "points",
        "ambient RF energy harvesting",
        "ambient RF sources",
        "information transmission",
        "wireless devices",
        "Ginibre \u03b1-determinantal point process",
        "stronger repulsion",
        "repulsion",
        "proactive energy replenishment",
        "Poisson point process",
        "mobile transmit devices",
        "parameter setting",
        "base stations",
        "co-channel interference",
        "optimal time-switching coefficient"
      ]
    },
    "org": {
      "title": "Performance analysis for energy harvesting communication protocols with fixed rate transmission",
      "url": "https://www.semanticscholar.org/paper/205a2ba8f6c835a7628ae8847ad48a5ea2c0a0a4",
      "abstract": "Energy Harvesting (EH) has emerged as a promising technique for Green Communications and it is a novel technique to prolong the lifetime of the wireless networks with replenishable nodes. In this paper, we consider the energy shortage analysis of fixed rate transmission in communication systems with energy harvesting nodes. First, we study the finite-horizon transmission and provide the general formula for the energy shortage probability. We also give some examples as benchmarks. Then, we continue to derive a closed-form expression for infinite-horizon transmission, which is a lower bound for the energy shortage probability of any finite-horizon transmission. These results are proposed for both Additive White Gaussian Noise (AWGN) and fading channels. Moreover, we show that even under \\emph{random energy arrival}, one can transmit at a fixed rate equal to capacity in the AWGN channels with negligible aggregate shortage time. We achieve this result using our practical transmission schemes, proposed for finite-horizon. Also, comprehensive numerical simulations are performed in AWGN and fading channels with no Channel State Information (CSI) available at the transmitter, which corroborate our theoretical findings. Furthermore, we improve the performance of our transmission schemes in the fading channel with no CSI at the transmitter by optimizing the transmission initiation threshold.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "fixed rate transmission",
        "replenishable nodes",
        "fading channels",
        "negligible aggregate shortage time",
        "Energy Harvesting",
        "\\emph{random energy arrival",
        "infinite-horizon transmission",
        "energy shortage probability",
        "transmission initiation threshold",
        "AWGN",
        "energy shortage analysis",
        "CSI",
        "AWGN and fading channels",
        "communication systems",
        "energy harvesting nodes",
        "energy arrival",
        "transmission schemes"
      ]
    }
  },
  {
    "sim": 0.5338944559994984,
    "gen": {
      "title": "Asymptotics and Approximation of the SIR Distribution in General Cellular Networks",
      "url": "https://www.semanticscholar.org/paper/f49a29766abbebd749642d25ef6120599b9f6439",
      "abstract": "It has recently been observed that the SIR distributions of a variety of cellular network models and transmission techniques look very similar in shape. As a result, they are well approximated by a simple horizontal shift (or gain) of the distribution of the most tractable model, the Poisson point process (PPP). To study and explain this behavior, this paper focuses on general single-tier network models with nearest-base station association and studies the asymptotic gain both at 0 and at infinity. We show that the gain at 0 is determined by the so-called mean interference-to-signal ratio (MISR) between the PPP and the network model under consideration, while the gain at infinity is determined by the expected fading-to-interference ratio (EFIR). The analysis of the MISR is based on a novel type of point process, the so-called relative distance process, which is a one-dimensional point process on the unit interval [0,1] that fully determines the SIR. A comparison of the gains at 0 and infinity shows that the gain at 0 indeed provides an excellent approximation for the entire SIR distribution. Moreover, the gain is mostly a function of the network geometry and barely depends on the path loss exponent and the fading. The results are illustrated using several examples of repulsive point processes.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "point process",
        "cellular network models",
        "repulsive point processes",
        "gain",
        "interference",
        "general single-tier network models",
        "PPP",
        "Poisson point process",
        "infinity",
        "shape",
        "EFIR",
        "transmission techniques",
        "network model",
        "MISR",
        "entire SIR distribution",
        "consideration"
      ]
    },
    "org": {
      "title": "On the Effect of Data Contamination on Track Purity",
      "url": "https://www.semanticscholar.org/paper/b14d18ea228c70a919292053f595c7e7b27bd027",
      "abstract": "The work presented here is concerned with performance analysis for data association, in a target tracking environment. Effects of misassociation are considered in a simple (linear) multiscan framework so as to provide closed-form expressions of the probability of correct association. We focus here on the development of explicit approximations of this probability. Via rigorous calculations the effect of dimensioning parameters (number of scans, false measurement positions or densities) is analyzed, for various modelings of the false measurements. Remarkably, it is possible to derive very simple expressions of the probability of correct association which are independent of the scenario kinematic parameters.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "false measurement positions",
        "modelings",
        "densities",
        "correct association",
        "dimensioning parameters",
        "false measurements",
        "data association",
        "scans",
        "scenario kinematic parameters",
        "number",
        "multiscan framework",
        "target tracking environment",
        "performance analysis",
        "explicit approximations",
        "closed-form expressions",
        "rigorous calculations"
      ]
    }
  },
  {
    "sim": 0.41145864163304924,
    "gen": {
      "title": "A Comparative Survey of Machine Learning and MetaHeuristic Optimization Algorithms for Sustainable and Smart Healthcare",
      "url": "https://www.semanticscholar.org/paper/6a1f5bd8e338bf2c7f715108853eafa21d0c1276",
      "abstract": "The healthcare industry uses machine learning for diagnosis, prognosis, and surveillance. Health Catalyst believes machine learning (ML) is the life-saving technology that will transform healthcare. This technology challenges the traditional reactive approach to healthcare. In fact, it\u2019s the exact opposite; it is the predictive, proactive, and preventive life-saving qualities that make it a critically essential capability in every health system. The third goal of good health and well-being by the United Nations Sustainable Development Goals of 2030 has opened research opportunities across the globe. In this literature review, an intensive study of twenty-one papers published between 2014 and 2017 is carried out. The study has raised various questions regarding the best machine learning technique on different disease dataset and solutions to overcome the problem of optimizing the feature selection for better performance. A comparison of the various algorithms is presented in tabular form based on two categories, namely the use of ML and also the use of ML with meta-heuristic algorithms in disease dataset. A model proposed for future work, which uses meta-heuristic algorithms for feature selections, appears to be better for any dataset. Machine learning in medicine has recently made headlines. Google has developed a machine learning algorithm to help identify cancerous tumors on mammograms. Stanford University is using a deep learning algorithm to identify skin cancer. Deep machine learning algorithm has been used in the literature to diagnose diabetic retinopathy in retinal images. It is clear that machine learning puts another arrow in the quiver of clinical decision making. A dataset is prepared from the surveyed research papers and this is compared for better visualization of algorithms. To make a comparative analysis of the retrieved dataset and choosing a right algorithm for any disease diagnosis, a graph is plotted using ML libraries of python language. The graph shows that the use of Support Vector Machine (SVM) with the optimization algorithms, like EPSO_ABC, and Artificial Neural Networks (ANN), give 100% accuracy. This paper provides an enhanced description of future work in sustainable healthcare. The use of meta-heuristic algorithms with ML techniques will provide better and faster results.",
      "fieldsOfStudy": null,
      "topics": [
        "Deep machine learning algorithm",
        "algorithms",
        "machine learning",
        "disease dataset",
        "different disease dataset",
        "better performance",
        "better visualization",
        "sustainable healthcare",
        "ML techniques",
        "healthcare",
        "ML libraries",
        "feature selections",
        "research opportunities",
        "meta-heuristic algorithms"
      ]
    },
    "org": {
      "title": "Robust classification of graph-based data",
      "url": "https://www.semanticscholar.org/paper/3245e8aaf753e7e7eb12ad18d9d0076def2fe88f",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ]
    }
  },
  {
    "sim": 0.8203022171774149,
    "gen": {
      "title": "Joint Beamforming and Power Allocation in Downlink NOMA Multiuser MIMO Networks",
      "url": "https://www.semanticscholar.org/paper/100df13d39828731c8798c615a3507f1e898924f",
      "abstract": "In this paper, a novel joint design of beamforming and power allocation is proposed for a multi-cell multiuser multiple-input multiple-output non-orthogonal multiple access network. In this network, base stations adopt coordinated multipoint for downlink transmission. We study a new scenario where the users are divided into two groups according to their quality-of-service requirements, rather than their channel qualities as investigated in the literature. Our proposed joint design aims to maximize the sum rate of the users in one group with the best effort while guaranteeing the minimum required target rates of the users in the other group. The joint design is formulated as a non-convex NP-hard problem. To make the problem tractable, a series of transformations is adopted to simplify the design problem. Then, an iterative suboptimal resource allocation algorithm based on successive convex approximation is proposed. In each iteration, a rank-constrained optimization problem is solved optimally via semidefinite program relaxation. Numerical results reveal that the proposed scheme offers significant sum-rate gains compared to the existing schemes and converges fast to a suboptimal solution.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "semidefinite program relaxation",
        "downlink transmission",
        "successive convex approximation",
        "multi-cell multiuser multiple-input multiple-output non-orthogonal multiple access network",
        "coordinated multipoint",
        "minimum required target rates",
        "non-convex NP-hard problem",
        "significant sum-rate gains",
        "base stations",
        "service",
        "Our proposed joint design",
        "design problem",
        "transformations",
        "iterative suboptimal resource allocation algorithm",
        "converges",
        "power allocation",
        "sum rate"
      ]
    },
    "org": {
      "title": "Constructive Interference in Linear Precoding Systems: Power Allocation and User Selection",
      "url": "https://www.semanticscholar.org/paper/eeba07a631b94208a02374eb03811f9f0b1434b8",
      "abstract": "The exploitation of interference in a constructive manner has recently been proposed for the downlink of multiuser, multi-antenna transmitters. This novel linear precoding technique, herein referred to as constructive interference zero forcing (CIZF) precoding, has exhibited substantial gains over conventional approaches; the concept is to cancel, on a symbol-by-symbol basis, only the interfering users that do not add to the intended signal power. In this paper, the power allocation problem towards maximizing the performance of a CIZF system with respect to some metric (throughput or fairness) is investigated. What is more, it is shown that the performance of the novel precoding scheme can be further boosted by choosing some of the constructive multiuser interference terms in the precoder design. Finally, motivated by the significant effect of user selection on conventional, zero forcing (ZF) precoding, the problem of user selection for the novel precoding method is tackled. A new iterative, low complexity algorithm for user selection in CIZF is developed. Simulation results are provided to display the gains of the algorithm compared to known user selection approaches.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "known user selection approaches",
        "user selection",
        "multi-antenna transmitters",
        "conventional approaches",
        "constructive interference",
        "symbol",
        "CIZF",
        "substantial gains",
        "fairness",
        "power allocation problem",
        "This novel linear precoding technique",
        "novel precoding method",
        "novel precoding scheme",
        "intended signal power",
        "throughput",
        "interference",
        "multiuser, multi-antenna transmitters",
        "constructive multiuser interference terms"
      ]
    }
  },
  null,
  {
    "sim": 0.3881035477939744,
    "gen": {
      "title": "A Review of Population-Based Metaheuristics for Large-Scale Black-Box Global Optimization\u2014Part I",
      "url": "https://www.semanticscholar.org/paper/18e09ae5505126f43f1853c60892f29575333b44",
      "abstract": "Scalability of optimization algorithms is a major challenge in coping with the ever-growing size of optimization problems in a wide range of application areas from high-dimensional machine learning to complex large-scale engineering problems. The field of large-scale global optimization is concerned with improving the scalability of global optimization algorithms, particularly, population-based metaheuristics. Such metaheuristics have been successfully applied to continuous, discrete, or combinatorial problems ranging from several thousand dimensions to billions of decision variables. In this two-part survey, we review recent studies in the field of large-scale black-box global optimization to help researchers and practitioners gain a bird\u2019s-eye view of the field, learn about its major trends, and the state-of-the-art algorithms. Part I of the series covers two major algorithmic approaches to large-scale global optimization: 1) problem decomposition and 2) memetic algorithms. Part II of the series covers a range of other algorithmic approaches to large-scale global optimization, describes a wide range of problem areas, and finally, touches upon the pitfalls and challenges of current research and identifies several potential areas for future research.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "global optimization algorithms",
        "optimization problems",
        "problem areas",
        "potential areas",
        "future research",
        "decision variables",
        "current research",
        "application areas",
        "Such metaheuristics",
        "optimization",
        "complex large-scale engineering problems",
        "large-scale black-box global optimization",
        "algorithmic approaches",
        "challenges",
        "optimization algorithms"
      ]
    },
    "org": {
      "title": "Channel Estimation and Hybrid Precoding for Distributed Phased Arrays Based MIMO Wireless Communications",
      "url": "https://www.semanticscholar.org/paper/b654a8426f99023c9562c3314dcfec4716cfff88",
      "abstract": "Distributed phased arrays based multiple-input multiple-output (DPA-MIMO) is a newly introduced architecture that enables both spatial multiplexing and beamforming while facilitating highly reconfigurable hardware implementation in millimeter-wave (mmWave) frequency bands. With a DPA-MIMO system, we focus on channel state information (CSI) acquisition and hybrid precoding. As benefited from a coordinated and open-loop pilot beam pattern design, all the sub-arrays can perform channel sounding with less training overhead compared with the traditional orthogonal operation of each sub-array. Furthermore, two sparse channel recovery algorithms, known as joint orthogonal matching pursuit (JOMP) and joint sparse Bayesian learning with $\\ell _2$ reweighting (JSBL-$\\ell _2$), are proposed to exploit the hidden structured sparsity in the beam-domain channel vector. Finally, successive interference cancellation (SIC) based hybrid precoding through sub-array grouping is illustrated for the DPA-MIMO system, which decomposes the joint sub-array RF beamformer design into an interactive per-sub-array-group handle. Simulation results show that the proposed two channel estimators fully take advantage of the partial coupling characteristic of DPA-MIMO channels to perform channel recovery, and the proposed hybrid precoding algorithm is suitable for such array-of-sub-arrays architecture with satisfactory performance and low complexity.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "channel recovery",
        "channel state information",
        "channel",
        "joint orthogonal matching pursuit",
        "sub",
        "-array grouping",
        "arrays",
        "joint sparse Bayesian",
        "joint sub-array RF beamformer design",
        "low complexity",
        "hybrid precoding",
        "DPA",
        "training overhead",
        "channel sounding",
        "Distributed phased arrays",
        "joint sparse Bayesian learning",
        "sub-array-group",
        "sparse channel recovery algorithms"
      ]
    }
  },
  {
    "sim": 0.6244652199020304,
    "gen": {
      "title": "Research Report Department of Statistics No . 2004 : 2 BAYESIAN ANALYSIS OF EXPONENTIAL RANDOM GRAPHS-ESTIMATION OF PARAMETERS AND MODEL SELECTION",
      "url": "https://www.semanticscholar.org/paper/ba0b11d5b913cad72ee9462b6c92cd0590627d60",
      "abstract": "Many probability models for graphs and directed graphs have been proposed and the aim has usually been to reduce the probability of a graph to some function that does not take the entire (graph-) structure into account, e.g. the number of edges (Bernoulli graph), dyadic properties in directed graphs (p1 Holland and Leinhardt, 1981), subgraph counts (Markov Graphs Frank and Strauss, 1986), etc. Many of these models give you analytically tractable forms for inference about parameters while assuming dependencies that are not always realistic in social science applications, whereas others make up for their increased realism with computational complexity. The Markov Graph of Frank and Strauss (1986), was later developed by Wasserman and Pattison (1996) into the so called p\u2217 model, an exponential model for graphs that comprise arbitrary statistics of graphs and attributes. In this paper we propose a procedure for making Bayesian inference in the exponential graph framework. The aim is to obtain a joint posterior distribution of the parameters in the model, which captures the uncertainty about our parameter values given the observed data. A second objective is to assess how much support different parameterizations of the model are given by data. Typically in Bayesian statistics, the expression for the posterior distribution is not analytically tractable because of the normalizing constant involving a complicated integral or sum. In the case of exponential random graphs we have an additional difficulty, namely that for the p\u2217 model the likelihood is only known up to a constant of proportionality (with respect to data). When the likelihood is easily evaluated, the first problem is easily handled by means of Markov chain Monte Carlo (MCMC) methods. Here, using this fact, the posterior is obtained from a two-step algorithm, which samples from both the sample space and the parameter space. For calculating the marginal likelihood function needed for model comparison, we employ a method suggested by Chib and Jeliazkov (2001). This involves estimating the posterior density evaluated in a suitably chosen point, something which is accomplished using only the key components of the MCMC algorithm, taking averages over the posterior distribution and candidate proposal distribution.",
      "fieldsOfStudy": null,
      "topics": [
        "directed graphs",
        "exponential random graphs",
        "Bernoulli graph",
        "graphs",
        "Many probability models",
        "data",
        "parameters",
        "computational complexity",
        "Markov Graphs Frank",
        "social science applications",
        "Jeliazkov",
        "exponential graph framework",
        "Bayesian inference",
        "subgraph counts",
        "dyadic properties",
        "model comparison",
        "candidate proposal distribution"
      ]
    },
    "org": {
      "title": "Co-clustering of fuzzy lagged data",
      "url": "https://www.semanticscholar.org/paper/4d649cce927ea2786a8729d14ff808db8e0c29d6",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  null,
  {
    "sim": 0.5455252887564017,
    "gen": {
      "title": "Enabling Ubiquitous Non-Orthogonal Multiple Access and Pervasive Federated Learning via STAR-RIS",
      "url": "https://www.semanticscholar.org/paper/06c601a9ec07afa79dab5e20b72c7f921688854e",
      "abstract": "This paper proposes a new, compatible, unified framework which integrates non-orthogonal multiple access (NOMA) and over-the-air federated learning (AirFL) via concurrent communication. In particular, a simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) is leveraged to adjust the signal processing order for efficient interference mitigation and omni-directional coverage extension. With the aim of investigating the impact of non-ideal wireless communication on AirFL, we provide a closed-form expression for the optimality gap over a given number of communication rounds. This result reveals that the learning performance is significantly affected by the resource allocation scheme and channel noise. To minimize the derived optimality gap, a mixed-integer non-linear programming (MINLP) problem is formulated by jointly designing the transmit power at users and configuration mode at the STAR-RIS. Through developing an alternating optimization algorithm, a suboptimal solution for the original MINLP problem is obtained. Simulation results show that the learning performance in terms of training loss and test accuracy can be effectively improved with the aid of the STAR-RIS.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "efficient interference mitigation",
        "non-ideal wireless communication",
        "communication rounds",
        "concurrent communication",
        "non-orthogonal multiple access",
        "omni-directional coverage extension",
        "configuration mode",
        "channel noise",
        "AirFL",
        "signal processing order",
        "STAR-RIS",
        "reconfigurable intelligent surface",
        "test accuracy",
        "users",
        "training loss",
        "original MINLP problem"
      ]
    },
    "org": {
      "title": "Fault-tolerant aggregation: Flow-Updating meets Mass-Distribution",
      "url": "https://www.semanticscholar.org/paper/5631d06bb60457815e218ec94991a5688f25b3f5",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  {
    "sim": 0.46680646752885624,
    "gen": {
      "title": "A fast and accurate physics-informed neural network reduced order model with shallow masked autoencoder",
      "url": "https://www.semanticscholar.org/paper/691c6922e74c65a5fe627ba330fbf6f73076f49d",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ]
    },
    "org": {
      "title": "Segregation dynamics with reinforcement learning and agent based modeling",
      "url": "https://www.semanticscholar.org/paper/0d6fcc24621f2f3be1785c4b864d018e25126f1f",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Physics",
        "Medicine"
      ]
    }
  },
  {
    "sim": 0.664598804883954,
    "gen": {
      "title": "Semi-supervised Learning Meets Factorization: Learning to Recommend with Chain Graph Model",
      "url": "https://www.semanticscholar.org/paper/c4703afe04021e4a81999acf6d3328434b7138ea",
      "abstract": "Recently latent factor model (LFM) has been drawing much attention in recommender systems due to its good performance and scalability. However, existing LFMs predict missing values in a user-item rating matrix only based on the known ones, and thus the sparsity of the rating matrix always limits their performance. Meanwhile, semi-supervised learning (SSL) provides an effective way to alleviate the label (i.e., rating) sparsity problem by performing label propagation, which is mainly based on the smoothness insight on affinity graphs. However, graph-based SSL suffers serious scalability and graph unreliable problems when directly being applied to do recommendation. In this paper, we propose a novel probabilistic chain graph model (CGM) to marry SSL with LFM. The proposed CGM is a combination of Bayesian network and Markov random field. The Bayesian network is used to model the rating generation and regression procedures, and the Markov random field is used to model the confidence-aware smoothness constraint between the generated ratings. Experimental results show that our proposed CGM significantly outperforms the state-of-the-art approaches in terms of four evaluation metrics, and with a larger performance margin when data sparsity increases.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "data sparsity",
        "unreliable problems",
        "Markov random field",
        "label propagation",
        "affinity graphs",
        "scalability",
        "recommendation",
        "scalability",
        "recommender systems",
        "rating matrix",
        "graph-based SSL",
        "attention",
        "SSL",
        "larger performance margin",
        "generated ratings",
        "graph unreliable problems"
      ]
    },
    "org": {
      "title": "Semi-supervised Evidential Label Propagation Algorithm for Graph Data",
      "url": "https://www.semanticscholar.org/paper/44a61e4d36c78e2634e1326b6414b7c5a9adab54",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  null,
  null,
  null,
  null,
  null,
  {
    "sim": 0.6549274366585022,
    "gen": {
      "title": "Spectral Methods for Immunization of Large Networks",
      "url": "https://www.semanticscholar.org/paper/9d61adcd7a09cbfbc212665ab73a2a3f9f1c2807",
      "abstract": "Given a network of nodes, minimizing the spread of a contagion using a limited budget is a well-studied problem with applications in network security, viral marketing, social networks, and public health. In real graphs, virus may infect a node which in turn infects its neighbor nodes and this may trigger an epidemic in the whole graph. The goal thus is to select the best k nodes (budget constraint) that are immunized (vaccinated, screened, filtered) so as the remaining graph is less prone to the epidemic. It is known that the problem is, in all practical models, computationally intractable even for moderate sized graphs. In this paper we employ ideas from spectral graph theory to define relevance and importance of nodes. Using novel graph theoretic techniques, we then design an efficient approximation algorithm to immunize the graph. Theoretical guarantees on the running time of our algorithm show that it is more efficient than any other known solution in the literature. We test the performance of our algorithm on several real world graphs. Experiments show that our algorithm scales well for large graphs and outperforms state of the art algorithms both in quality (containment of epidemic) and efficiency (runtime and space complexity).",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "large graphs",
        "real graphs",
        "moderate sized graphs",
        "spectral graph theory",
        "novel graph theoretic techniques",
        "real world graphs",
        "nodes",
        "epidemic",
        "social networks",
        "graph",
        "remaining graph",
        "network security",
        "public health",
        "runtime and space complexity",
        "graph",
        "budget constraint"
      ]
    },
    "org": {
      "title": "Mean Field Analysis of Personalized PageRank with Implications for Local Graph Clustering",
      "url": "https://www.semanticscholar.org/paper/ef063dd351860643e5b51d63d00cc0c4b0b66ab8",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ]
    }
  },
  {
    "sim": 0.6749014162366211,
    "gen": {
      "title": "Correction for \"On the Convergence of the Iterative Shrinkage/Thresholding Algorithm with a Weakly Convex Penalty\"",
      "url": "https://www.semanticscholar.org/paper/f7f628d327fc992058072ee6885fabacc9956112",
      "abstract": "We consider the iterative shrinkage/thresholding algorithm (ISTA) applied to a cost function composed of a data fidelity term and a penalty term. The penalty is nonconvex but the concavity of the penalty is accounted for by the data fidelity term so that the overall cost function is convex. We provide a generalization of the convergence result for ISTA viewed as a forward-backward splitting algorithm. We also demonstrate experimentally that for the current setup, using large stepsizes in ISTA can accelerate convergence more than existing schemes proposed for the convex case, like TwIST or FISTA.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "overall cost function",
        "data fidelity term",
        "existing schemes",
        "ISTA",
        "cost function",
        "large stepsizes",
        "convergence",
        "penalty",
        "nonconvex",
        "convex case",
        "iterative shrinkage/thresholding algorithm",
        "TwIST",
        "iterative shrinkage",
        "shrinkage thresholding"
      ]
    },
    "org": {
      "title": "Convergence Rate of Distributed Optimization Algorithms Based on Gradient Tracking",
      "url": "https://www.semanticscholar.org/paper/42b0d0cb6e8774cae76ec9a5716cbf9c50156ea4",
      "abstract": "We study distributed, strongly convex and nonconvex, multiagent optimization over (directed, time-varying) graphs. We consider the minimization of the sum of a smooth (possibly nonconvex) function--the agent's sum-utility plus a nonsmooth convex one, subject to convex constraints. In a companion paper, we introduced SONATA, the first algorithmic framework applicable to such a general class of composite minimization, and we studied its convergence when the smooth part of the objective function is nonconvex. The algorithm combines successive convex approximation techniques with a perturbed push-sum consensus mechanism that aims to track locally the gradient of the (smooth part of the) sum-utility. This paper studies the convergence rate of SONATA. When the smooth part of the objective function is strongly convex, SONATA is proved to converge at a linear rate whereas sublinar rate is proved when the objective function is nonconvex. To our knowledge, this is the first work proving a convergence rate (in particular, linear rate) for distributed algorithms applicable to such a general class of composite, constrained optimization problems over graphs.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "convex constraints",
        "sublinar rate",
        "graphs",
        "constrained optimization problems",
        "successive convex approximation techniques",
        "nonconvex",
        "composite minimization",
        "multiagent optimization",
        "SONATA",
        "distributed algorithms",
        "linear",
        "particular, linear rate",
        "nonsmooth convex",
        "objective function",
        "linear rate",
        "sum",
        "composite, constrained optimization problems",
        "convergence rate",
        "smooth part"
      ]
    }
  },
  {
    "sim": 0.4962216582205724,
    "gen": {
      "title": "Nonlinear Stochastic Estimators on the Special Euclidean Group SE(3) Using Uncertain IMU and Vision Measurements",
      "url": "https://www.semanticscholar.org/paper/62e2a439b5a519a4c50c98077b75a427ea4966dd",
      "abstract": "Two novel robust nonlinear stochastic full pose (i.e., attitude and position) estimators on the Special Euclidean Group $\\mathbb {SE}(3)$ are proposed using the available uncertain measurements. The resulting estimators utilize the basic structure of the deterministic pose estimators adopting it to the stochastic sense. The proposed estimators for six degrees of freedom (DOF) pose estimations consider the group velocity vectors to be contaminated with constant bias and Gaussian random noise, unlike nonlinear deterministic pose estimators which disregard the noise component in the estimator derivations. The proposed estimators ensure that the closed-loop error signals are semi-globally uniformly ultimately bounded in mean square. The efficiency and robustness of the proposed estimators are demonstrated by the numerical results which test the estimators against high levels of noise and bias associated with the group velocity and body-frame measurements and large initialization error.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering",
        "Mathematics"
      ],
      "topics": [
        "large initialization error",
        "mean square",
        "Gaussian random noise",
        "constant bias",
        "noise",
        "deterministic pose estimators",
        "bias",
        "high levels",
        "proposed estimators",
        "estimator derivations",
        "body-frame measurements",
        "group velocity vectors",
        "available uncertain measurements",
        "The resulting estimators"
      ]
    },
    "org": {
      "title": "Real-Time Stochastic Predictive Control for Hybrid Vehicle Energy Management",
      "url": "https://www.semanticscholar.org/paper/e3b190fccab3b68f458624bc1802d6df09138730",
      "abstract": "This work presents three computational methods for real time energy management in a hybrid hydraulic vehicle (HHV) when driver behavior and vehicle route are not known in advance. These methods, implemented in a receding horizon control (aka model predictive control) framework, are rather general and can be applied to systems with nonlinear dynamics subject to a Markov disturbance. State and input constraints are considered in each method. A mechanism based on the steady state distribution of the underlying Markov chain is developed for planning beyond a finite horizon in the HHV energy management problem. Road elevation information is forecasted along the horizon and then merged with the statistical model of driver behavior to increase accuracy of the horizon optimization. The characteristics of each strategy are compared and the benefit of learning driver behavior is analyzed through simulation on three drive cycles, including one real world drive cycle. A simulation is designed to explicitly demonstrate the benefit of adapting the Markov chain to real time driver behavior. Experimental results demonstrate the real time potential of the primary algorithm when implemented on a processor with limited computational resources.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "real time driver behavior",
        "real time energy management",
        "driver behavior",
        "vehicle route",
        "real world drive cycle",
        "limited computational resources",
        "Markov",
        "advance",
        "nonlinear dynamics",
        "HHV",
        "HHV energy management problem",
        "real time potential",
        "receding horizon control",
        "drive cycles",
        "hybrid hydraulic vehicle",
        "systems",
        "underlying Markov chain"
      ]
    }
  },
  null,
  null,
  null,
  {
    "sim": 0.4693576615566213,
    "gen": {
      "title": "Brain organization into resting state networks emerges at criticality on a model of the human connectome.",
      "url": "https://www.semanticscholar.org/paper/a84c52cfd55407d21cb6e62998b71d4e35de5b0f",
      "abstract": "The relation between large-scale brain structure and function is an outstanding open problem in neuroscience. We approach this problem by studying the dynamical regime under which realistic spatiotemporal patterns of brain activity emerge from the empirically derived network of human brain neuroanatomical connections. The results show that critical dynamics unfolding on the structural connectivity of the human brain allow the recovery of many key experimental findings obtained from functional magnetic resonance imaging, such as divergence of the correlation length, the anomalous scaling of correlation fluctuations, and the emergence of large-scale resting state networks.",
      "fieldsOfStudy": [
        "Biology",
        "Physics",
        "Medicine",
        "Computer Science",
        "Psychology"
      ],
      "topics": [
        "human brain neuroanatomical connections",
        "brain activity",
        "correlation fluctuations",
        "functional magnetic resonance imaging",
        "key experimental findings",
        "realistic spatiotemporal patterns",
        "large-scale resting state networks",
        "large-scale brain structure",
        "human brain",
        "divergence",
        "neuroscience",
        "function",
        "correlation length",
        "outstanding open problem",
        "critical dynamics"
      ]
    },
    "org": {
      "title": "The Nature of Explosive Percolation Phase Transition",
      "url": "https://www.semanticscholar.org/paper/fa1e03a7a9a6c990737c4b9fa19d4a0de0f3c5df",
      "abstract": null,
      "fieldsOfStudy": [
        "Physics",
        "Mathematics",
        "Computer Science"
      ]
    }
  },
  null,
  {
    "sim": 0.43144576081343655,
    "gen": {
      "title": "Computational Intelligence and Security, International Conference, CIS 2006, Guangzhou, China, November 3-6, 2006, Revised Selected Papers",
      "url": "https://www.semanticscholar.org/paper/09d94bbbc754b333e736e5518057ed24a619e723",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    },
    "org": {
      "title": "Control-Aware Representations for Model-based Reinforcement Learning",
      "url": "https://www.semanticscholar.org/paper/b50da2e0bf200bb481725d92e5e3c80f8273dacc",
      "abstract": "A major challenge in modern reinforcement learning (RL) is efficient control of dynamical systems from high-dimensional sensory observations. Learning controllable embedding (LCE) is a promising approach that addresses this challenge by embedding the observations into a lower-dimensional latent space, estimating the latent dynamics, and utilizing it to perform control in the latent space. Two important questions in this area are how to learn a representation that is amenable to the control problem at hand, and how to achieve an end-to-end framework for representation learning and control. In this paper, we take a few steps towards addressing these questions. We first formulate a LCE model to learn representations that are suitable to be used by a policy iteration style algorithm in the latent space. We call this model control-aware representation learning (CARL). We derive a loss function for CARL that has close connection to the prediction, consistency, and curvature (PCC) principle for representation learning. We derive three implementations of CARL. In the offline implementation, we replace the locally-linear control algorithm (e.g.,~iLQR) used by the existing LCE methods with a RL algorithm, namely model-based soft actor-critic, and show that it results in significant improvement. In online CARL, we interleave representation learning and control, and demonstrate further gain in performance. Finally, we propose value-guided CARL, a variation in which we optimize a weighted version of the CARL loss function, where the weights depend on the TD-error of the current policy. We evaluate the proposed algorithms by extensive experiments on benchmark tasks and compare them with several LCE baselines.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "representation learning",
        "efficient control",
        "control",
        "representations",
        "modern reinforcement learning",
        "LCE baselines",
        "significant improvement",
        "latent space",
        "model control-aware representation learning",
        "gain",
        "CARL",
        "performance",
        "latent dynamics",
        "LCE",
        "policy iteration style algorithm",
        "control-aware representation learning",
        "lower-dimensional latent space",
        "online CARL"
      ]
    }
  },
  {
    "sim": 0.1742164298215635,
    "gen": {
      "title": "Multi-Source Spatial Entity Linkage",
      "url": "https://www.semanticscholar.org/paper/d58826e62235a272527f24cd2d1a379a338b797a",
      "abstract": "Besides the traditional cartographic data sources, spatial information can also be derived from location-based sources. However, even though different location-based sources refer to the same physical world, each one has only partial coverage of the spatial entities, describe them with different attributes, and sometimes provide contradicting information. Hence, we introduce the spatial entity linkage problem, which finds which pairs of spatial entities belong to the same physical spatial entity. Our proposed solution (<italic>QuadSky</italic>) starts with a time-efficient spatial blocking technique (<italic>QuadFlex</italic>), compares pairwise the spatial entities in the same block, ranks the pairs using Pareto optimality with the <italic>SkyRank</italic> algorithm, and finally, classifies the pairs with our novel <italic>SkyEx-*</italic> family of algorithms that yield 0.85 <italic>precision</italic> and 0.85 <italic>recall</italic> for a manually labeled dataset of 1,500 pairs and 0.87 <italic>precision</italic> and 0.6 <italic>recall</italic> for a semi-manually labeled dataset of 777,452 pairs. Moreover, we provide a theoretical guarantee and formalize the <italic>SkyEx-FES</italic> algorithm that explores only 27 percent of the skylines without any loss in <italic>F-measure</italic>. Furthermore, our fully unsupervised algorithm <italic>SkyEx-D</italic> approximates the optimal result with an <italic>F-measure</italic> loss of just 0.01. Finally, <italic>QuadSky</italic> provides the best trade-off between <italic>precision</italic> and <italic>recall</italic>, and the best <italic>F-measure</italic> compared to the existing baselines and clustering techniques, and approximates the results of supervised learning solutions.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "spatial information",
        "physical spatial entity",
        "italic>precision</italic",
        "italic>recall</italic",
        "supervised learning solutions",
        "clustering techniques",
        "spatial entity linkage problem",
        "measure</italic",
        "spatial entities",
        "<italic",
        "recall</italic",
        "algorithms",
        "contradicting information",
        "Pareto optimality",
        "different attributes",
        "time-efficient spatial blocking technique",
        "different location-based sources",
        "physical world"
      ]
    },
    "org": {
      "title": "Discriminatory Transfer",
      "url": "https://www.semanticscholar.org/paper/75432a2660c2844f0cfe0d89794cba0abc58a64d",
      "abstract": "Weobserve standard transfer learning can improve prediction accuracies of target tasks at the cost of lowering their prediction fairness \u2013 a phenomenon we named discriminatory transfer. We examine prediction fairness of a standard hypothesis transfer algorithm and a standardmulti-task learning algorithm, and show they both suffer discriminatory transfer on the real-world Communities and Crime data set. The presented case study introduces an interaction between fairness and transfer learning, as an extension of existing fairness studies that focus on single task learning.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "standard transfer learning",
        "discriminatory transfer",
        "single task learning",
        "existing fairness studies",
        "target tasks",
        "prediction accuracies",
        "fairness and transfer learning",
        "standard hypothesis transfer algorithm",
        "standardmulti-task learning algorithm",
        "Communities",
        "prediction fairness",
        "real-world Communities and Crime data",
        "The presented case study",
        "cost",
        "transfer learning",
        "fairness",
        "real-world Communities and Crime data set",
        "Communities and Crime"
      ]
    }
  },
  {
    "sim": 0.54393296985937,
    "gen": {
      "title": "A Nonuniform Sampling Approach to Data Compression",
      "url": "https://www.semanticscholar.org/paper/70678f27b9e64d19982e151eec37b2931bd1fc0b",
      "abstract": "A nonuniform sampling approach to digital encoding of analog sources is proposed. The nonuniform sampler is basically a level crossing detector (LCD) which produces a sample whenever the input to the LCD crosses a threshold level. The information about the source signal is contained in the time intervals between level crossings and in the directions of level crossings. By assigning strings of the 2-tuple \"00\" to represent the time between level crossings and \"01\" and \"10\" to denote the directions of level crossings, the output binary sequence of the nonuniform sampling encoder (NSE) contains a high probability of the 0 symbol, which makes it suitable for further simple run-length encoding (RLE) to attain a \"good\" overall compression ratio. Introduction of prediction converts the NSE to a nonuniform sampling predictive coding (NSPC) scheme, which, depending on the source, can potentially improve the compression ratio. Results obtained in the encoding of a band-limied Gaussian source and a rasterscanned black and white still image reveal that an NSE/RLE or NSPC/ RLE system exhibits performance superior to that of an adaptive delta modulation system.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "level crossings",
        "adaptive delta modulation system",
        "analog sources",
        "RLE",
        "level crossing detector",
        "performance",
        "digital encoding",
        "LCD",
        "simple run-length encoding",
        "threshold level",
        "nonuniform",
        "compression ratio",
        "nonuniform sampling encoder",
        "A nonuniform sampling approach",
        "output binary sequence",
        "NSE"
      ]
    },
    "org": {
      "title": "Error-Correcting Codes for Reliable Communications in Microgravity Platforms",
      "url": "https://www.semanticscholar.org/paper/738cf796cb540aa6a33397993fcb1584b9feeb78",
      "abstract": "The PAANDA experiment was conceived to characterize the acceleration ambient of a rocket launched microgravity platform, specially the microgravity phase. The recorded data was transmitted to ground stations, leading to loss of telemetry information sent during the reentry period. Traditionally, an error-correcting code for this channel consists of a block code with very large block size to protect against long periods of data loss. Instead, we propose the use of digital fountain codes along with conventional Reed-Solomon block codes to protect against long and short burst error periods, respectively. Aiming to use this approach for a second version of PAANDA to prevent data corruption, we propose a model for the communication channel based on information extracted from Cum\\~a II's telemetry data, and simulate the performance of our proposed error-correcting code under this channel model. Simulation results show that nearly all telemetry data can be recovered, including data from the reentry period.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "data loss",
        "long periods",
        "telemetry information",
        "data corruption",
        "loss",
        "digital fountain codes",
        "information",
        "long and short burst error periods",
        "data",
        "microgravity platform",
        "Cum\\~a IIs telemetry data",
        "reentry period",
        "conventional Reed-Solomon block codes",
        "block code",
        "proposed error-correcting code",
        "nearly all telemetry data"
      ]
    }
  },
  {
    "sim": 0.6951231534642556,
    "gen": {
      "title": "Decentralized Structural-RNN for Robot Crowd Navigation with Deep Reinforcement Learning",
      "url": "https://www.semanticscholar.org/paper/9bcb7fecfb7cbbe0cccd3a17a60ba900b94f09ca",
      "abstract": "Safe and efficient navigation through human crowds is an essential capability for mobile robots. Previous work on robot crowd navigation assumes that the dynamics of all agents are known and well-defined. In addition, the performance of previous methods deteriorates in partially observable environments and environments with dense crowds. To tackle these problems, we propose decentralized structural-Recurrent Neural Network (DS-RNN), a novel network that reasons about spatial and temporal relationships for robot decision making in crowd navigation. We train our network with model-free deep reinforcement learning without any expert supervision. We demonstrate that our model outperforms previous methods in challenging crowd navigation scenarios. We successfully transfer the policy learned in the simulator to a real-world TurtleBot 2i.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "crowd navigation",
        "challenging crowd navigation scenarios",
        "human crowds",
        "dense crowds",
        "mobile robots",
        "robot decision",
        "TurtleBot",
        "previous methods",
        "environments",
        "Safe and efficient navigation",
        "Previous work",
        "decentralized structural-Recurrent Neural Network",
        "model-free deep reinforcement learning",
        "spatial and temporal relationships",
        "robot decision making",
        "essential capability"
      ]
    },
    "org": {
      "title": "Model-Based Bayesian Reinforcement Learning in Large Structured Domains",
      "url": "https://www.semanticscholar.org/paper/6660f6d84b55d8ec997380ab3e503e5401346cc1",
      "abstract": "Model-based Bayesian reinforcement learning has generated significant interest in the AI community as it provides an elegant solution to the optimal exploration-exploitation tradeoff in classical reinforcement learning. Unfortunately, the applicability of this type of approach has been limited to small domains due to the high complexity of reasoning about the joint posterior over model parameters. In this paper, we consider the use of factored representations combined with online planning techniques, to improve scalability of these methods. The main contribution of this paper is a Bayesian framework for learning the structure and parameters of a dynamical system, while also simultaneously planning a (near-)optimal sequence of actions.",
      "fieldsOfStudy": [
        "Computer Science",
        "Medicine"
      ],
      "topics": [
        "classical reinforcement learning",
        "significant interest",
        "model parameters",
        "actions",
        "parameters",
        "online planning techniques",
        "AI",
        "Model-based Bayesian reinforcement learning",
        "small domains",
        "scalability",
        "optimal exploration-exploitation tradeoff",
        "factored representations",
        "AI community",
        "elegant solution",
        "reasoning",
        "dynamical system",
        "joint posterior"
      ]
    }
  },
  {
    "sim": 0.3093017870918964,
    "gen": {
      "title": "Expected Risk Minimization and Robust Preventive Inference of Transfer Learning for COVID-19 Diagnosis within Chest X-Rays",
      "url": "https://www.semanticscholar.org/paper/ecafca5fea042c73980cf4b70aaad2bd09bcfe1c",
      "abstract": ": The creation of a treatment strategy and the choice of patient-checking circumstances within many others are supported by early diagnosis of COVID-19 infection. It is possible to detect COVID-19 early on by applying a deep learning method to radiographic medical lab images. Convolutional neural networks (CNN) are used in this study to improve COVID-19 diagnoses using X-ray scans. An automated diagnostic solution that can swiftly deliver accurate diagnostic results is required. CNNs have been found to be efficient at classifying medical images using deep learning techniques. Transfer Learning (TF) is the most reliable research supervised learning method, offering useful analysis to examine many radiographs image samples, and can considerably detect potential and infer preventative detection of COVID-19. Despite its high True Positive, testing healthcare professionals remains a serious risk. Three distinct deep TF and regularization-based architectures were studied on chest X-ray images for the diagnosis of COVID-19. Because these models already include weights trained on the ImageNet database, large training sets are unnecessary. To evaluate the model's performance, 21,165 chest x-ray scan samples were obtained from various sources and identified as COVID-19 data collection from four classes in the Kaggle repository. Average metrics results are collected to get the actual predictions for all classes. Although Saving training time with TF, an advance improvement for performance can be achieved by applying only some parts of the input image with most important segments of the input image are localized. To prove the validity of our approach we use Grad Cam algorithm to find the input image parts with most valuable features for decision making. The localised image region map is udsed to reproduce a lighter version of the image database with only marked as most important image regions. Metrics including precision, F1-Score, confusion matrix, accuracy, sensitivity, specificity, error rate, and error rate have been used to assess the performance of all the TF models., besides false positive (FP), Matthews Correlation Coefficient (MCC), and Kappa performance measures. In terms of performance, the ResNet-50 model outperforms all others with a low error rate of 0.039 and achieves more than a 96% accuracy. The study findings proven the proposed model validity as a computer-aided diagnostics model with a guarantee to supply help for radiologists quickly and accurately.",
      "fieldsOfStudy": null,
      "topics": [
        "chest X-ray images",
        "medical images",
        "radiographs image samples",
        "radiographic medical lab images",
        "error rate",
        "COVID-19 data collection",
        "X-ray scans",
        "COVID-19 diagnoses",
        "Kappa performance measures",
        "deep learning techniques",
        "COVID-19 infection",
        "input image parts",
        "important image regions",
        "early diagnosis",
        "decision making",
        "COVID-19",
        "21,165 chest x-ray scan samples"
      ]
    },
    "org": {
      "title": "Local structure entropy of complex networks",
      "url": "https://www.semanticscholar.org/paper/d93d980a9880a90d91caf2e136b27752f6b0ee6f",
      "abstract": "Identifying influential nodes in the complex networks is of theoretical and practical significance. There are many methods are proposed to identify the influential nodes in the complex networks. In this paper, a local structure entropy which is based on the degree centrality and the statistical mechanics is proposed to identifying the influential nodes in the complex network. \nIn the definition of the local structure entropy, each node has a local network, the local structure entropy of each node is equal to the structure entropy of the local network. The main idea in the local structure entropy is try to use the influence of the local network to replace the node's influence on the whole network. \nThe influential nodes which are identified by the local structure entropy are the intermediate nodes in the network. The intermediate nodes which connect those nodes with a big value of degree. \nWe use the $Susceptible-Infective$ (SI) model to evaluate the performance of the influential nodes which are identified by the local structure entropy. In the SI model the nodes use as the source of infection. According to the SI model, the bigger the percentage of the infective nodes in the network the important the node to the whole networks. The simulation on four real networks show that the proposed method is efficacious and rationality to identify the influential nodes in the complex networks.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics"
      ],
      "topics": [
        "node",
        "local network",
        "complex networks",
        "networks",
        "real networks",
        "intermediate nodes",
        "infective nodes",
        "local structure",
        "local structure entropy"
      ]
    }
  },
  {
    "sim": 0.5126392277540449,
    "gen": {
      "title": "Detecting the Influence of Spreading in Social Networks with Excitable Sensor Networks",
      "url": "https://www.semanticscholar.org/paper/e00cae519b02a1cd7886aa7a290bd8228257574e",
      "abstract": "Detecting spreading outbreaks in social networks with sensors is of great significance in applications. Inspired by the formation mechanism of humans\u2019 physical sensations to external stimuli, we propose a new method to detect the influence of spreading by constructing excitable sensor networks. Exploiting the amplifying effect of excitable sensor networks, our method can better detect small-scale spreading processes. At the same time, it can also distinguish large-scale diffusion instances due to the self-inhibition effect of excitable elements. Through simulations of diverse spreading dynamics on typical real-world social networks (Facebook, coauthor, and email social networks), we find that the excitable sensor networks are capable of detecting and ranking spreading processes in a much wider range of influence than other commonly used sensor placement methods, such as random, targeted, acquaintance and distance strategies. In addition, we validate the efficacy of our method with diffusion data from a real-world online social system, Twitter. We find that our method can detect more spreading topics in practice. Our approach provides a new direction in spreading detection and should be useful for designing effective detection methods.",
      "fieldsOfStudy": [
        "Computer Science",
        "Medicine",
        "Physics"
      ],
      "topics": [
        "social networks",
        "effective detection methods",
        "spreading processes",
        "sensors",
        "excitable elements",
        "commonly used sensor placement methods",
        "excitable sensor networks",
        "typical real-world social networks",
        "influence",
        "applications",
        "great significance",
        "detection",
        "diffusion data",
        "Twitter",
        "email social networks",
        "spreading detection",
        "spreading topics",
        "diverse spreading dynamics",
        "spreading",
        "spreading outbreaks"
      ]
    },
    "org": {
      "title": "Enhancing the long-term performance of recommender system",
      "url": "https://www.semanticscholar.org/paper/c7384b5bfd90aea28119c604a94e6cf2cec2cfb0",
      "abstract": null,
      "fieldsOfStudy": [
        "Mathematics",
        "Physics",
        "Computer Science"
      ]
    }
  },
  {
    "sim": 0.5068413051033331,
    "gen": {
      "title": "Distributed Estimation and Control of Algebraic Connectivity Over Random Graphs",
      "url": "https://www.semanticscholar.org/paper/62b63228db550ce3c0e1f1428474b10e8829b932",
      "abstract": "In this paper, we propose a distributed algorithm for the estimation and control of the connectivity of ad-hoc networks in the presence of a random topology. First, given a generic random graph, we introduce a novel stochastic power iteration method that allows each node to estimate and track the algebraic connectivity of the underlying expected graph. Using results from stochastic approximation theory, we prove that the proposed method converges almost surely (a.s.) to the desired value of connectivity even in the presence of imperfect communication scenarios. The estimation strategy is then used as a basic tool to adapt the power transmitted by each node of a wireless network, in order to maximize the network connectivity in the presence of realistic medium access control (MAC) protocols or simply to drive the connectivity toward a desired target value. Numerical results corroborate our theoretical findings, thus illustrating the main features of the algorithm and its robustness to fluctuations of the network graph due to the presence of random link failures.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "connectivity",
        "imperfect communication scenarios",
        "random link failures",
        "stochastic approximation theory",
        "network connectivity",
        "novel stochastic power iteration method",
        "network graph",
        "control",
        "generic random graph",
        "underlying expected graph",
        "algebraic connectivity",
        "MAC",
        "desired value",
        "realistic medium access control (MAC) protocols",
        "wireless network"
      ]
    },
    "org": {
      "title": "A Scalable Thermal Reservoir Simulator for Giant Models on Parallel Computers",
      "url": "https://www.semanticscholar.org/paper/bfc90d34cb7472a635a66168201cee47c9b99e7b",
      "abstract": "This paper introduces the model, numerical methods, algorithms and parallel implementation of a thermal reservoir simulator that designed for numerical simulations of thermal reservoir with multiple components in three dimensional domain using distributed-memory parallel computers. Its full mathematical model is introduced with correlations for important properties and well modeling. Various well constraints, such as fixed bottom hole pressure, fixed oil, water, gas and liquid rates, constant heat transfer model, convective heat transfer model, heater model (temperature control, rate control, dual rate/temperature control), and subcool (steam trap), are introduced in details, including their mathematical models and methods. Efficient numerical methods and parallel computing technologies are presented. The simulator is designed for giant models with billions or even trillions of grid blocks using hundreds of thousands of CPUs. Numerical experiments show that our results match commercial simulators, which confirms the correctness of our methods and implementations. SAGD simulation with 15106 well pairs is also presented to study the effectiveness of our numerical methods. Scalability testings demonstrate that our simulator can handle giant models with over 200 billion grid blocks using 100,800 CPU cores and the simulator has good scalability.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "convective heat transfer model",
        "giant models",
        "Efficient numerical methods",
        "heater model",
        "parallel implementation",
        "parallel computing technologies",
        "commercial simulators",
        "rate control",
        "thermal reservoir",
        "methods",
        "numerical simulations",
        "temperature control",
        "Numerical experiments",
        "grid blocks",
        "numerical methods",
        "good scalability"
      ]
    }
  },
  {
    "sim": 0.5616648227148304,
    "gen": {
      "title": "Learning Heuristics for Quantified Boolean Formulas through Reinforcement Learning",
      "url": "https://www.semanticscholar.org/paper/66c40b2b5e9853632a11e877993ad9efb1e449fd",
      "abstract": "We demonstrate how to learn efficient heuristics for automated reasoning algorithms for quantified Boolean formulas through deep reinforcement learning. We focus on a backtracking search algorithm, which can already solve formulas of impressive size - up to hundreds of thousands of variables. The main challenge is to find a representation of these formulas that lends itself to making predictions in a scalable way. For a family of challenging problems, we learned a heuristic that solves significantly more formulas compared to the existing handwritten heuristics.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "quantified Boolean formulas",
        "deep reinforcement learning",
        "formulas",
        "efficient heuristics",
        "automated reasoning algorithms",
        "variables",
        "existing handwritten heuristics",
        "Boolean",
        "predictions",
        "significantly more formulas",
        "scalable way",
        "challenging problems",
        "impressive size - up",
        "backtracking search algorithm",
        "formulas",
        "impressive size",
        "heuristic"
      ]
    },
    "org": {
      "title": "Short Portfolio Training for CSP Solving",
      "url": "https://www.semanticscholar.org/paper/8efd2428a6f10425410bdc9cb97686face7f59f4",
      "abstract": "Many different approaches for solving Constraint Satisfaction Problems (CSPs) and related Constraint Optimization Problems (COPs) exist. However, there is no single solver (nor approach) that performs well on all classes of problems and many portfolio approaches for selecting a suitable solver based on simple syntactic features of the input CSP instance have been developed. In this paper we first present a simple portfolio method for CSP based on k-nearest neighbors method. Then, we propose a new way of using portfolio systems --- training them shortly in the exploitation time, specifically for the set of instances to be solved and using them on that set. Thorough evaluation has been performed and has shown that the approach yields good results. We evaluated several machine learning techniques for our portfolio. Due to its simplicity and efficiency, the selected k-nearest neighbors method is especially suited for our short training approach and it also yields the best results among the tested methods. We also confirm that our approach yields good results on SAT domain.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "portfolio approaches",
        "Constraint Optimization Problems",
        "Constraint Satisfaction Problems",
        "good results",
        "portfolio systems",
        "Many different approaches",
        "approach",
        "SAT domain",
        "instances",
        "simple syntactic features",
        "CSP",
        "simple portfolio method",
        "short training approach",
        "input CSP instance",
        "related Constraint Optimization Problems",
        "tested methods"
      ]
    }
  },
  {
    "sim": 0.44415380216188693,
    "gen": {
      "title": "Detecting Intrusion via Insider Attack in Database Transactions by Learning Disentangled Representation with Deep Metric Neural Network",
      "url": "https://www.semanticscholar.org/paper/e8193b81a9f563ee186fbffc934138afe631dac5",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    },
    "org": {
      "title": "How Far are We from Solving Pedestrian Detection?",
      "url": "https://www.semanticscholar.org/paper/8f9f3ee403a0d0deab85df00e005c206abb2d6e4",
      "abstract": "Encouraged by the recent progress in pedestrian detection, we investigate the gap between current state-of-the-art methods and the \"perfect single frame detector\". We enable our analysis by creating a human baseline for pedestrian detection (over the Caltech dataset), and by manually clustering the recurrent errors of a top detector. Our results characterise both localisation and background-versusforeground errors. To address localisation errors we study the impact of training annotation noise on the detector performance, and show that we can improve even with a small portion of sanitised training data. To address background/foreground discrimination, we study convnets for pedestrian detection, and discuss which factors affect their performance. Other than our in-depth analysis, we report top performance on the Caltech dataset, and provide a new sanitised set of training and test annotations.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "training annotation noise",
        "sanitised training data",
        "test annotations",
        "training",
        "detector performance",
        "pedestrian detection",
        "localisation errors",
        "Caltech",
        "new sanitised set",
        "detector",
        "small portion",
        "\"perfect single frame detector",
        "performance",
        "Caltech dataset",
        "training and test annotations",
        "recurrent errors"
      ]
    }
  },
  {
    "sim": 0.3896695245954209,
    "gen": {
      "title": "A Vision-Based System for Monitoring the Loss of Attention in Automotive Drivers",
      "url": "https://www.semanticscholar.org/paper/a4ee76e6063195d9ff52ec0bdec681cb6640d7ef",
      "abstract": "Onboard monitoring of the alertness level of an automotive driver has been challenging to research in transportation safety and management. In this paper, we propose a robust real-time embedded platform to monitor the loss of attention of the driver during day and night driving conditions. The percentage of eye closure has been used to indicate the alertness level. In this approach, the face is detected using Haar-like features and is tracked using a Kalman filter. The eyes are detected using principal component analysis during daytime and using the block local-binary-pattern features during nighttime. Finally, the eye state is classified as open or closed using support vector machines. In-plane and off-plane rotations of the driver's face have been compensated using affine transformation and perspective transformation, respectively. Compensation in illumination variation is carried out using bihistogram equalization. The algorithm has been cross-validated using brain signals and, finally, has been implemented on a single-board computer that has an Intel Atom processor with a 1.66-GHz clock, a random access memory of 1 GB, \u00d786 architecture, and a Windows-embedded XP operating system. The system is found to be robust under actual driving conditions.",
      "fieldsOfStudy": [
        "Engineering",
        "Computer Science"
      ],
      "topics": [
        "perspective transformation",
        "affine transformation",
        "actual driving conditions",
        "support vector machines",
        "management",
        "transportation safety",
        "day and night driving conditions",
        "bihistogram equalization",
        "GB",
        "XP",
        "Windows-embedded XP operating system",
        "principal component analysis",
        "nighttime",
        "brain signals",
        "Atom",
        "Windows"
      ]
    },
    "org": {
      "title": "User Attention and Behaviour in Virtual Reality Art Encounter",
      "url": "https://www.semanticscholar.org/paper/45a699c95791b442c9c7f25cedb567a56ea3dd4c",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  null,
  {
    "sim": 0.46929932083505554,
    "gen": {
      "title": "RESDN: A Novel Metric and Method for Energy Efficient Routing in Software Defined Networks",
      "url": "https://www.semanticscholar.org/paper/18400c1aa364e9c4209926d63b1f43d4b7022ae4",
      "abstract": "Software-defined networking (SDN) paradigm, with the flexible and logically centralized control, enables dynamically minimizing the network energy consumption by redirecting paths of packets. However, the links and switches are designed to accommodate maximum traffic volume and their power consumption is not traffic proportional. Moreover, there exists a trade-off between energy efficiency and network performance that need to be considered together. Addressing these issues, we propose an energy efficiency metric named Ratio for Energy Saving in SDN (RESDN) that quantifies energy efficiency based on link utility intervals. We provide integer programming formulation and method for maximizing the RESDN of the network. To the best of our knowledge, RESDN approach is novel as it measures how links are profitably utilized in terms of the amount of energy they consume with respect to their utility. We analyze our approach considering various metrics of interest and different types of SDN enabled switches. Experiments show that maximizing the RESDN value improves energy efficiency while maintaining acceptable network performance. In comparison to state-of-the-art utility-based heuristics, RESDN method achieves up to 30% better ratio for energy saving, 14.7 watts per switch power saving, 38% link saving, 2 hops decrease in average path length, and 5% improved traffic proportionality.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "energy saving",
        "energy efficiency",
        "switch power saving",
        "energy",
        "network performance",
        "acceptable network performance",
        "link utility intervals",
        "maximum traffic volume",
        "traffic proportional",
        "RESDN method",
        "RESDN approach",
        "average path length",
        "RESDN",
        "redirecting paths",
        "metrics",
        "SDN enabled switches",
        "network energy consumption",
        "SDN"
      ]
    },
    "org": {
      "title": "Probabilistic model checking for energy analysis in software product lines",
      "url": "https://www.semanticscholar.org/paper/5ffa01eee1e3c28a23cae00a0373af36e1dfed27",
      "abstract": "In a software product line (SPL), a collection of software products is defined by their commonalities in terms of features rather than explicitly specifying all products one-by-one. Several verification techniques were adapted to establish temporal properties of SPLs. Symbolic and family-based model checking have been proven to be successful for tackling the combinatorial blow-up arising when reasoning about several feature combinations. However, most formal verification approaches for SPLs presented in the literature focus on the static SPLs, where the features of a product are fixed and cannot be changed during runtime. This is in contrast to dynamic SPLs, allowing to adapt feature combinations of a product dynamically after deployment. The main contribution of the paper is a compositional modeling framework for dynamic SPLs, which supports probabilistic and nondeterministic choices and allows for quantitative analysis. We specify the feature changes during runtime within an automata-based coordination component, enabling to reason over strategies how to trigger dynamic feature changes for optimizing various quantitative objectives, e.g., energy or monetary costs and reliability. For our framework there is a natural and conceptually simple translation into the input language of the prominent probabilistic model checker PRISM. This facilitates the application of PRISM's powerful symbolic engine to the operational behavior of dynamic SPLs and their family-based analysis against various quantitative queries. We demonstrate feasibility of our approach by a case study issuing an energy-aware bonding network device.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "dynamic feature changes",
        "feature combinations",
        "dynamic SPLs",
        "features",
        "quantitative queries",
        "quantitative objectives",
        "software products",
        "quantitative analysis",
        "runtime",
        "SPLs",
        "Several verification techniques",
        "feature changes",
        "deployment",
        "prominent probabilistic model checker PRISM",
        "monetary costs",
        "reliability",
        "energy"
      ]
    }
  },
  {
    "sim": 0.5494074478875388,
    "gen": {
      "title": "Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net",
      "url": "https://www.semanticscholar.org/paper/d39a5ea57b1c242a0450385523fd3471b172458c",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    },
    "org": {
      "title": "Three Factors Influencing Minima in SGD",
      "url": "https://www.semanticscholar.org/paper/f9e6af73d33e7aac3f349bef927fcd666e8e00db",
      "abstract": "We study the statistical properties of the endpoint of stochastic gradient descent (SGD). We approximate SGD as a stochastic differential equation (SDE) and consider its Boltzmann Gibbs equilibrium distribution under the assumption of isotropic variance in loss gradients.. Through this analysis, we find that three factors \u2013 learning rate, batch size and the variance of the loss gradients \u2013 control the trade-off between the depth and width of the minima found by SGD, with wider minima favoured by a higher ratio of learning rate to batch size. In the equilibrium distribution only the ratio of learning rate to batch size appears, implying that it\u2019s invariant under a simultaneous rescaling of each by the same amount. We experimentally show how learning rate and batch size affect SGD from two perspectives: the endpoint of SGD and the dynamics that lead up to it. For the endpoint, the experiments suggest the endpoint of SGD is similar under simultaneous rescaling of batch size and learning rate, and also that a higher ratio leads to flatter minima, both findings are consistent with our theoretical analysis. We note experimentally that the dynamics also seem to be similar under the same rescaling of learning rate and batch size, which we explore showing that one can exchange batch size and learning rate in a cyclical learning rate schedule. Next, we illustrate how noise affects memorization, showing that high noise levels lead to better generalization. Finally, we find experimentally that the similarity under simultaneous rescaling of learning rate and batch size breaks down if the learning rate gets too large or the batch size gets too small.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "rate",
        "rate and batch size",
        "simultaneous rescaling",
        "SGD",
        "wider minima",
        "flatter minima",
        "loss gradients",
        "cyclical learning rate schedule",
        "minima",
        "batch size",
        "high noise levels",
        "learning rate",
        "better generalization",
        "stochastic gradient descent",
        "isotropic variance",
        "width"
      ]
    }
  },
  {
    "sim": 0.6378699126048981,
    "gen": {
      "title": "Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model",
      "url": "https://www.semanticscholar.org/paper/69d1ee8a99f55e9228f33fdb3a0339541ad1201c",
      "abstract": "Deep reinforcement learning (RL) algorithms can use high-capacity deep networks to learn directly from image observations. However, these high-dimensional observation spaces present a number of challenges in practice, since the policy must now solve two problems: representation learning and task learning. In this work, we tackle these two problems separately, by explicitly learning latent representations that can accelerate reinforcement learning from images. We propose the stochastic latent actor-critic (SLAC) algorithm: a sample-efficient and high-performing RL algorithm for learning policies for complex continuous control tasks directly from high-dimensional image inputs. SLAC provides a novel and principled approach for unifying stochastic sequential models and RL into a single method, by learning a compact latent representation and then performing RL in the model's learned latent space. Our experimental evaluation demonstrates that our method outperforms both model-free and model-based alternatives in terms of final performance and sample efficiency, on a range of difficult image-based control tasks. Our code and videos of our results are available at our website.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "task learning",
        "image observations",
        "complex continuous control tasks",
        "reinforcement learning",
        "images",
        "latent representations",
        "difficult image-based control tasks",
        "stochastic sequential models",
        "RL",
        "high-dimensional image inputs",
        "sample efficiency",
        "policies",
        "final performance",
        "challenges",
        "practice"
      ]
    },
    "org": {
      "title": "Exploiting Spatial Invariance for Scalable Unsupervised Object Tracking",
      "url": "https://www.semanticscholar.org/paper/c764e2232b4fb9ddcb09c25185c28e0d6ba76e25",
      "abstract": "The ability to detect and track objects in the visual world is a crucial skill for any intelligent agent, as it is a necessary precursor to any object-level reasoning process. Moreover, it is important that agents learn to track objects without supervision (i.e. without access to annotated training videos) since this will allow agents to begin operating in new environments with minimal human assistance. The task of learning to discover and track objects in videos, which we call unsupervised object tracking, has grown in prominence in recent years; however, most architectures that address it still struggle to deal with large scenes containing many objects. In the current work, we propose an architecture that scales well to the large-scene, many-object setting by employing spatially invariant computations (convolutions and spatial attention) and representations (a spatially local object specification scheme). In a series of experiments, we demonstrate a number of attractive features of our architecture; most notably, that it outperforms competing methods at tracking objects in cluttered scenes with many objects, and that it can generalize well to videos that are larger and/or contain more objects than videos encountered during training.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "objects",
        "tracking objects",
        "objects",
        "objects",
        "unsupervised object tracking",
        "annotated training videos",
        "large scenes",
        "minimal human assistance",
        "videos",
        "cluttered scenes",
        "many-object setting",
        "agents",
        "training",
        "spatial attention",
        "new environments",
        "architectures",
        "recent years"
      ]
    }
  },
  {
    "sim": 0.7283681153671501,
    "gen": {
      "title": "Blang: Bayesian Declarative Modeling of General Data Structures and Inference via Algorithms Based on Distribution Continua",
      "url": "https://www.semanticscholar.org/paper/2d9108d1bf718803acfe1de09cd8b76a2cf7cb00",
      "abstract": "Consider a Bayesian inference problem where a variable of interest does not take values in a Euclidean space. These \u201cnon-standard\u201d data structures are in reality fairly common. They are frequently used in problems involving latent discrete factor models, networks, and domain specific problems such as sequence alignments and reconstructions, pedigrees, and phylogenies. In principle, Bayesian inference should be particularly wellsuited in such scenarios, as the Bayesian paradigm provides a principled way to obtain confidence assessment for random variables of any type. However, much of the recent work on making Bayesian analysis more accessible and computationally efficient has focused on inference in Euclidean spaces. In this paper, we introduce Blang, a domain specific language and library aimed at bridging this gap. Blang allows users to perform Bayesian analysis on arbitrary data types while using a declarative syntax similar to the popular family of probabilistic programming languages, BUGS. Blang is augmented with intuitive language additions to create data types of the user\u2019s choosing. To perform inference at scale on such arbitrary state spaces, Blang leverages recent advances in sequential Monte Carlo and non-reversible Markov chain Monte Carlo methods.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "arbitrary state spaces",
        "Monte Carlo methods",
        "sequential Monte Carlo",
        "Euclidean spaces",
        "Monte Carlo",
        "arbitrary data types",
        "probabilistic programming languages",
        "non-reversible Markov chain",
        "data types",
        "recent advances",
        "intuitive language additions",
        "Bayesian inference",
        "random variables",
        "Bayesian analysis",
        "specific problems",
        "sequential Monte Carlo and non-reversible Markov chain Monte Carlo methods",
        "domain specific problems",
        "latent discrete factor models",
        "scenarios",
        "confidence assessment"
      ]
    },
    "org": {
      "title": "Sequential Bayesian Experimental Design for Implicit Models via Mutual Information",
      "url": "https://www.semanticscholar.org/paper/1f8ebeafff428718da7295eb48fe5722bdc15866",
      "abstract": "Bayesian experimental design (BED) is a framework that uses statistical models and decision making under uncertainty to optimise the cost and performance of a scientific experiment. Sequential BED, as opposed to static BED, considers the scenario where we can sequentially update our beliefs about the model parameters through data gathered in the experiment. A class of models of particular interest for the natural and medical sciences are implicit models, where the data generating distribution is intractable, but sampling from it is possible. Even though there has been a lot of work on static BED for implicit models in the past few years, the notoriously difficult problem of sequential BED for implicit models has barely been touched upon. We address this gap in the literature by devising a novel sequential design framework for parameter estimation that uses the Mutual Information (MI) between model parameters and simulated data as a utility function to find optimal experimental designs, which has not been done before for implicit models. Our approach uses likelihood-free inference by ratio estimation to simultaneously estimate posterior distributions and the MI. During the sequential BED procedure we utilise Bayesian optimisation to help us optimise the MI utility. We find that our framework is efficient for the various implicit models tested, yielding accurate parameter estimates after only a few iterations.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "implicit models",
        "model parameters",
        "models",
        "statistical models",
        "parameter estimation",
        "accurate parameter estimates",
        "sequential BED",
        "optimal experimental designs",
        "simulated data",
        "Bayesian experimental design",
        "static BED",
        "implicit models",
        "data",
        "posterior distributions",
        "Sequential BED",
        "MI"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.4670125908660063,
    "gen": {
      "title": "The limits and potentials of deep learning for robotics",
      "url": "https://www.semanticscholar.org/paper/643fb5aeccce0351cac89bb8e446c8d7e48a3d99",
      "abstract": "The application of deep learning in robotics leads to very specific problems and research questions that are typically not addressed by the computer vision and machine learning communities. In this paper we discuss a number of robotics-specific learning, reasoning, and embodiment challenges for deep learning. We explain the need for better evaluation metrics, highlight the importance and unique challenges for deep robotic learning in simulation, and explore the spectrum between purely data-driven and model-driven approaches. We hope this paper provides a motivating overview of important research directions to overcome the current limitations, and helps to fulfill the promising potentials of deep learning in robotics.",
      "fieldsOfStudy": [
        "Computer Science",
        "Engineering",
        "Mathematics"
      ],
      "topics": [
        "deep learning",
        "deep robotic learning",
        "machine learning communities",
        "embodiment challenges",
        "unique challenges",
        "robotics-specific learning",
        "research questions",
        "important research directions",
        "robotics",
        "simulation",
        "reasoning",
        "better evaluation metrics",
        "purely data-driven and model-driven approaches",
        "specific problems",
        "promising potentials",
        "computer vision and machine learning communities",
        "robotics-specific learning, reasoning, and embodiment challenges",
        "current limitations",
        "spectrum"
      ]
    },
    "org": {
      "title": "Understanding the wiring evolution in differentiable neural architecture search",
      "url": "https://www.semanticscholar.org/paper/39fe8291dedac3f300586c72ea0d361e01427a98",
      "abstract": "Controversy exists on whether differentiable neural architecture search methods discover wiring topology effectively. To understand how wiring topology evolves, we study the underlying mechanism of several existing differentiable NAS frameworks. Our investigation is motivated by three observed searching patterns of differentiable NAS: 1) they search by growing instead of pruning; 2) wider networks are more preferred than deeper ones; 3) no edges are selected in bi-level optimization. To anatomize these phenomena, we propose a unified view on searching algorithms of existing frameworks, transferring the global optimization to local cost minimization. Based on this reformulation, we conduct empirical and theoretical analyses, revealing implicit inductive biases in the cost's assignment mechanism and evolution dynamics that cause the observed phenomena. These biases indicate strong discrimination towards certain topologies. To this end, we pose questions that future differentiable methods for neural wiring discovery need to confront, hoping to evoke a discussion and rethinking on how much bias has been enforced implicitly in existing NAS methods.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "existing differentiable NAS frameworks",
        "local cost minimization",
        "existing NAS methods",
        "bi-level optimization",
        "differentiable neural architecture search methods",
        "differentiable NAS",
        "wiring topology",
        "existing frameworks",
        "future differentiable methods",
        "neural wiring discovery",
        "certain topologies",
        "evolution dynamics",
        "implicit inductive biases",
        "NAS",
        "deeper ones",
        "searching algorithms"
      ]
    }
  },
  {
    "sim": 0.5952962469517254,
    "gen": {
      "title": "It's FLAN time! Summing feature-wise latent representations for interpretability",
      "url": "https://www.semanticscholar.org/paper/37394756549aafdb15a86e26ec4d9f120c1a6470",
      "abstract": "Interpretability has become a necessary feature for machine learning models deployed in critical scenarios, e.g. legal system, healthcare. In these situations, algorithmic decisions may have (potentially negative) long-lasting effects on the end-user affected by the decision. In many cases, the representational power of deep learning models is not needed, therefore simple and interpretable models (e.g. linear models) should be preferred. However, in high-dimensional and/or complex domains (e.g. computer vision), the universal approximation capabilities of neural networks are required. Inspired by linear models and the KolmogorovArnol representation theorem, we propose a novel class of structurally-constrained neural networks, which we call FLANs (Feature-wise Latent Additive Networks). Crucially, FLANs process each input feature separately, computing for each of them a representation in a common latent space. These feature-wise latent representations are then simply summed, and the aggregated representation is used for prediction. These constraints (which are at the core of the interpretability of linear models) allow a user to estimate the effect of each individual feature independently from the others, enhancing interpretability. In a set of experiments across different domains, we show how without compromising excessively the test performance, the structural constraints proposed in FLANs indeed increase the interpretability of deep learning models.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "deep learning models",
        "machine learning models",
        "neural networks",
        "interpretability",
        "Latent Additive Networks",
        "algorithmic decisions",
        "healthcare",
        "Feature-wise Latent Additive Networks",
        "FLANs",
        "critical scenarios",
        "linear",
        "prediction",
        "e.g. linear models",
        "simple and interpretable models",
        "These feature-wise latent representations",
        "KolmogorovArnol representation theorem"
      ]
    },
    "org": {
      "title": "Kernel-based Translations of Convolutional Networks",
      "url": "https://www.semanticscholar.org/paper/9bfe52177fb10fa5e30898434ff52cbcb5f50927",
      "abstract": "Convolutional Neural Networks, as most artificial neural networks, are commonly viewed as methods different in essence from kernel-based methods. We provide a systematic translation of Convolutional Neural Networks (ConvNets) into their kernel-based counterparts, Convolutional Kernel Networks (CKNs), and demonstrate that this perception is unfounded both formally and empirically. We show that, given a Convolutional Neural Network, we can design a corresponding Convolutional Kernel Network, easily trainable using a new stochastic gradient algorithm based on an accurate gradient computation, that performs on par with its Convolutional Neural Network counterpart. We present experimental results supporting our claims on landmark ConvNet architectures comparing each ConvNet to its CKN counterpart over several parameter settings.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "Convolutional Kernel Networks",
        "parameter settings",
        "Convolutional Neural Network counterpart",
        "methods",
        "corresponding Convolutional Kernel Network",
        "landmark ConvNet architectures",
        "artificial neural networks",
        "Convolutional Neural Network",
        "kernel-based methods",
        "essence",
        "ConvNet",
        "par",
        "new stochastic gradient algorithm",
        "accurate gradient computation"
      ]
    }
  },
  null,
  {
    "sim": 0.32287088028604227,
    "gen": {
      "title": "Scalable Probabilistic Matrix Factorization with Graph-Based Priors",
      "url": "https://www.semanticscholar.org/paper/7721b5629e829e8d2bffe6c526c9736fbf8218ae",
      "abstract": "In matrix factorization, available graph side-information may not be well suited for the matrix completion problem, having edges that disagree with the latent-feature relations learnt from the incomplete data matrix. We show that removing these contested edges improves prediction accuracy and scalability. We identify the contested edges through a highly-efficient graphical lasso approximation. The identification and removal of contested edges adds no computational complexity to state-of-the-art graph-regularized matrix factorization, remaining linear with respect to the number of non-zeros. Computational load even decreases proportional to the number of edges removed. Formulating a probabilistic generative model and using expectation maximization to extend graph-regularised alternating least squares (GRALS) guarantees convergence. Rich simulated experiments illustrate the desired properties of the resulting algorithm. On real data experiments we demonstrate improved prediction accuracy with fewer graph edges (empirical evidence that graph side-information is often inaccurate). A 300 thousand dimensional graph with three million edges (Yahoo music side-information) can be analyzed in under ten minutes on a standard laptop computer demonstrating the efficiency of our graph update.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "fewer graph edges",
        "edges",
        "matrix factorization",
        "contested edges",
        "non-zeros",
        "available graph side-information",
        "prediction accuracy",
        "graph-regularised alternating least squares",
        "convergence",
        "zeros",
        "real data experiments",
        "Yahoo music side-information",
        "graph update",
        "incomplete data matrix",
        "graph side-information",
        "empirical evidence"
      ]
    },
    "org": {
      "title": "Checkpointing Strategies with Prediction Windows",
      "url": "https://www.semanticscholar.org/paper/65a0c1ed4187ff51bff9509b3550ac0d05bbe4df",
      "abstract": "This paper deals with the impact of fault prediction techniques on check pointing strategies. We consider fault-prediction systems that do not provide exact prediction dates, but instead time intervals during which faults are predicted to strike. These intervals dramatically complicate the analysis of the check pointing strategies. We propose a new approach based upon two periodic modes, a regular mode outside prediction windows, and a proactive mode inside prediction windows, whenever the size of these windows is large enough. We are able to compute the best period for any size of the prediction windows, thereby deriving the scheduling strategy that minimizes platform waste. In addition, the results of the analytical study are nicely corroborated by a comprehensive set of simulations, which demonstrate the validity of the model and the accuracy of the approach.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "platform waste",
        "fault prediction techniques",
        "exact prediction dates",
        "prediction windows",
        "time intervals",
        "fault-prediction systems",
        "check pointing strategies",
        "faults",
        "periodic modes",
        "regular mode",
        "proactive mode",
        "scheduling strategy",
        "simulations"
      ]
    }
  },
  {
    "sim": 0.45792218127460593,
    "gen": {
      "title": "Finding low-energy conformations of lattice protein models by quantum annealing",
      "url": "https://www.semanticscholar.org/paper/ce58b84f218565683b92e66c98204103bbbbe0bf",
      "abstract": null,
      "fieldsOfStudy": [
        "Physics",
        "Medicine"
      ]
    },
    "org": {
      "title": "#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning",
      "url": "https://www.semanticscholar.org/paper/0fcb2034e31a2bc2f12a2b1363d0d77baf445fdf",
      "abstract": "Count-based exploration algorithms are known to perform near-optimally when used in conjunction with tabular reinforcement learning (RL) methods for solving small discrete Markov decision processes (MDPs). It is generally thought that count-based methods cannot be applied in high-dimensional state spaces, since most states will only occur once. Recent deep RL exploration strategies are able to deal with high-dimensional continuous state spaces through complex heuristics, often relying on optimism in the face of uncertainty or intrinsic motivation. In this work, we describe a surprising finding: a simple generalization of the classic count-based approach can reach near state-of-the-art performance on various high-dimensional and/or continuous deep RL benchmarks. States are mapped to hash codes, which allows to count their occurrences with a hash table. These counts are then used to compute a reward bonus according to the classic count-based exploration theory. We find that simple hash functions can achieve surprisingly good results on many challenging tasks. Furthermore, we show that a domain-dependent learned hash code may further improve these results. Detailed analysis reveals important aspects of a good hash function: 1) having appropriate granularity and 2) encoding information relevant to solving the MDP. This exploration strategy achieves near state-of-the-art performance on both continuous control tasks and Atari 2600 games, hence providing a simple yet powerful baseline for solving MDPs that require considerable exploration.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "considerable exploration",
        "Recent deep RL exploration strategies",
        "simple hash functions",
        "challenging tasks",
        "states",
        "States",
        "MDPs",
        "small discrete Markov decision processes",
        "hash codes",
        "intrinsic motivation",
        "high-dimensional state spaces",
        "tabular reinforcement learning",
        "Count-based exploration algorithms",
        "RL",
        "continuous control tasks",
        "high-dimensional and/or continuous deep RL benchmarks"
      ]
    }
  },
  {
    "sim": 0.5667564071103262,
    "gen": {
      "title": "Byzantine Resilient Distributed Learning in Multirobot Systems",
      "url": "https://www.semanticscholar.org/paper/def2379f47d7f55e5d1e54f8249c2a12db83d3ad",
      "abstract": "Distributed machine learning algorithms are increasingly used in multirobot systems and are prone to Byzantine attacks. In this article, we consider a distributed implementation of the stochastic gradient descent (SGD) algorithm in a cooperative network, where networked agents optimize a global loss function using SGD on the local data and aggregation of the estimates of immediate neighbors. Byzantine agents can send arbitrary estimates to their neighbors, which may disrupt the convergence of normal agents to the optimum state. We show that if every normal agent combines its neighbors\u2019 estimates (states) such that the aggregated state is in the convex hull of its normal neighbors\u2019 states, then the resilient convergence is guaranteed. To assure this sufficient condition, we propose a resilient aggregation rule based on the notion of centerpoint, which is a generalization of the median in the higher-dimensional Euclidean space. We evaluate our results using examples of target pursuit and pattern recognition in multirobot systems. The evaluation results demonstrate that distributed learning with average, coordinate-wise median, and geometric median-based aggregation rules fail to converge to the optimum state, whereas the centerpoint-based aggregation rule is resilient in the same scenario.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "states",
        "normal agents",
        "immediate neighbors",
        "Byzantine attacks",
        "aggregation",
        "multirobot systems",
        "networked agents",
        "geometric median-based aggregation rules",
        "arbitrary estimates",
        "Byzantine agents",
        "resilient aggregation rule",
        "centerpoint",
        "optimum state",
        "Distributed machine learning algorithms",
        "Byzantine",
        "estimates",
        "normal neighbors"
      ]
    },
    "org": {
      "title": "Generalized Byzantine-tolerant SGD",
      "url": "https://www.semanticscholar.org/paper/b8167db77296f9557328f0fb6d7fe3c044d1043a",
      "abstract": "We propose three new robust aggregation rules for distributed synchronous Stochastic Gradient Descent~(SGD) under a general Byzantine failure model. The attackers can arbitrarily manipulate the data transferred between the servers and the workers in the parameter server~(PS) architecture. We prove the Byzantine resilience properties of these aggregation rules. Empirical analysis shows that the proposed techniques outperform current approaches for realistic use cases and Byzantine attack scenarios.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "Byzantine attack scenarios",
        "Stochastic Gradient",
        "Byzantine",
        "realistic use cases",
        "general Byzantine failure model",
        "current approaches",
        "Byzantine resilience properties",
        "new robust aggregation rules",
        "aggregation rules",
        "Empirical analysis",
        "parameter server~(PS",
        ") architecture",
        "proposed techniques",
        "workers",
        "servers",
        "distributed synchronous Stochastic Gradient Descent~(SGD",
        "parameter server~(PS) architecture",
        "data"
      ]
    }
  },
  {
    "sim": 0.5421032497000206,
    "gen": {
      "title": "Evaluation of 3D Correspondence Methods for Model Building",
      "url": "https://www.semanticscholar.org/paper/c5691f36181185d3ca80d16047145eff97095a0f",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Medicine",
        "Mathematics"
      ]
    },
    "org": {
      "title": "Multi-cue Structure Preserving MRF for Unconstrained Video Segmentation",
      "url": "https://www.semanticscholar.org/paper/76ab4da5ec8658e34529475e6884c8ae04b18ffa",
      "abstract": "Video segmentation is a stepping stone to understanding video context. Video segmentation enables one to represent a video by decomposing it into coherent regions which comprise whole or parts of objects. However, the challenge originates from the fact that most of the video segmentation algorithms are based on unsupervised learning due to expensive cost of pixelwise video annotation and intra-class variability within similar unconstrained video classes. We propose a Markov Random Field model for unconstrained video segmentation that relies on tight integration of multiple cues: vertices are defined from contour based superpixels, unary potentials from temporally smooth label likelihood and pairwise potentials from global structure of a video. Multi-cue structure is a breakthrough to extracting coherent object regions for unconstrained videos in absence of supervision. Our experiments on VSB100 dataset show that the proposed model significantly outperforms competing state-of-the-art algorithms. Qualitative analysis illustrates that video segmentation result of the proposed model is consistent with human perception of objects.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "unconstrained video segmentation",
        "unconstrained videos",
        "similar unconstrained video classes",
        "video segmentation result",
        "video context",
        "pixelwise video annotation",
        "objects",
        "coherent regions",
        "intra-class variability",
        "video segmentation algorithms",
        "contour based superpixels",
        "pairwise potentials",
        "global structure",
        "unary potentials"
      ]
    }
  },
  null,
  {
    "sim": 0.6071952154045969,
    "gen": {
      "title": "The Impact of Social Media on Panic During the COVID-19 Pandemic in Iraqi Kurdistan: Online Questionnaire Study",
      "url": "https://www.semanticscholar.org/paper/e6471eeb21379cd82e83ec0749c81f99166e509b",
      "abstract": "Background In the first few months of 2020, information and news reports about the coronavirus disease (COVID-19) were rapidly published and shared on social media and social networking sites. While the field of infodemiology has studied information patterns on the Web and in social media for at least 18 years, the COVID-19 pandemic has been referred to as the first social media infodemic. However, there is limited evidence about whether and how the social media infodemic has spread panic and affected the mental health of social media users. Objective The aim of this study is to determine how social media affects self-reported mental health and the spread of panic about COVID-19 in the Kurdistan Region of Iraq. Methods To carry out this study, an online questionnaire was prepared and conducted in Iraqi Kurdistan, and a total of 516 social media users were sampled. This study deployed a content analysis method for data analysis. Correspondingly, data were analyzed using SPSS software. Results Participants reported that social media has a significant impact on spreading fear and panic related to the COVID-19 outbreak in Iraqi Kurdistan, with a potential negative influence on people\u2019s mental health and psychological well-being. Facebook was the most used social media network for spreading panic about the COVID-19 outbreak in Iraq. We found a significant positive statistical correlation between self-reported social media use and the spread of panic related to COVID-19 (R=.8701). Our results showed that the majority of youths aged 18-35 years are facing psychological anxiety. Conclusions During lockdown, people are using social media platforms to gain information about COVID-19. The nature of the impact of social media panic among people varies depending on an individual's gender, age, and level of education. Social media has played a key role in spreading anxiety about the COVID-19 outbreak in Iraqi Kurdistan.",
      "fieldsOfStudy": [
        "Psychology"
      ],
      "topics": [
        "social media platforms",
        "social networking sites",
        "Iraqi Kurdistan",
        "COVID-19",
        "self-reported social media use",
        "516 social media users",
        "Kurdistan",
        "social media infodemic",
        "panic",
        "psychological anxiety",
        "Iraqi",
        "data analysis"
      ]
    },
    "org": {
      "title": "Analysis of social media content and search behavior related to seasonal topics using the sociophysics approach",
      "url": "https://www.semanticscholar.org/paper/4dbafdfa8428b914ed059dd08d308191e7eff4dc",
      "abstract": "We studied the time interval between posting social media content and search action related to seasonal topics. The analysis was performed using a mathematical model of the search behavior as in the theory of sociophysics. As seasonal topics, the word cherry blossom was considered for spring, bikini for summer, autumn leaves for fall, and skiing for winter. We examined the influence of blogs and Twitter posts given the search behavior and found a time deviation of interest on these topics.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science",
        "Physics"
      ],
      "topics": [
        "seasonal topics",
        "winter",
        "cherry blossom",
        "search action",
        "social media content",
        "bikini",
        "autumn",
        "fall",
        "spring",
        "summer",
        "sociophysics",
        "Twitter posts",
        "interest",
        "search behavior",
        "topics",
        "autumn leaves",
        "skiing",
        "posting social media content",
        "word cherry blossom"
      ]
    }
  },
  {
    "sim": 0.5942006075827243,
    "gen": {
      "title": "A concise frictional contact formulation based on surface potentials and isogeometric discretization",
      "url": "https://www.semanticscholar.org/paper/e1616babcaea7fb85b715369eb3046e0ffd6617f",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Physics"
      ]
    },
    "org": {
      "title": "Optimization\u2010based autonomous racing of 1:43 scale RC cars",
      "url": "https://www.semanticscholar.org/paper/1f3486989c79a527dac35324e17df4596146a07a",
      "abstract": "This paper describes autonomous racing of RC race cars based on mathematical optimization. Using a dynamical model of the vehicle, control inputs are computed by receding horizon based controllers, where the objective is to maximize progress on the track subject to the requirement of staying on the track and avoiding opponents. Two different control formulations are presented. The first controller employs a two\u2010level structure, consisting of a path planner and a nonlinear model predictive controller (NMPC) for tracking. The second controller combines both tasks in one nonlinear optimization problem (NLP) following the ideas of contouring control. Linear time varying models obtained by linearization are used to build local approximations of the control NLPs in the form of convex quadratic programs (QPs) at each sampling time. The resulting QPs have a typical MPC structure and can be solved in the range of milliseconds by recent structure exploiting solvers, which is key to the real\u2010time feasibility of the overall control scheme. Obstacle avoidance is incorporated by means of a high\u2010level corridor planner based on dynamic programming, which generates convex constraints for the controllers according to the current position of opponents and the track layout. The control performance is investigated experimentally using 1:43 scale RC race cars, driven at speeds of more than 3\u2009m/s and in operating regions with saturated rear tire forces (drifting). The algorithms run at 50\u2009Hz sampling rate on embedded computing platforms, demonstrating the real\u2010time feasibility and high performance of optimization\u2010based approaches for autonomous racing. Copyright \u00a9 2014 John Wiley & Sons, Ltd.",
      "fieldsOfStudy": [
        "Engineering",
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "contouring control",
        "control inputs",
        "receding horizon based controllers",
        "RC race cars",
        "opponents",
        "saturated rear tire forces",
        "convex quadratic programs",
        "Linear time varying models",
        "mathematical optimization",
        "convex constraints",
        "recent structure",
        "autonomous racing",
        "operating regions",
        "high performance",
        "overall control scheme",
        "embedded computing platforms",
        "recent structure exploiting solvers",
        "drifting"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.634703119053164,
    "gen": {
      "title": "Decentralized Deep Learning Using Momentum-Accelerated Consensus",
      "url": "https://www.semanticscholar.org/paper/3cbf742833bee3d691ae49cd1c6323fb1f9e08de",
      "abstract": "We consider the problem of decentralized deep learning where multiple agents collaborate to learn from a distributed dataset. While several decentralized deep learning approaches exist, the majority consider a central parameter-server topology for aggregating the model parameters from the agents. However, such a topology may be inapplicable in networked systems such as ad-hoc mobile networks, field robotics, and power network systems where direct communication with the central parameter server may be inefficient. In this context, we propose and analyze a novel decentralized deep learning algorithm where the agents interact over a fixed communication topology (without a central server). Our algorithm is based on the heavy-ball acceleration method used in gradient-based optimization. We propose a novel consensus protocol where each agent shares with its neighbors its model parameters and gradient-momentum values during the optimization process. We consider nonconvex objective functions and theoretically analyze our algorithm\u2019s performance. We present several empirical comparisons with competing decentralized learning methods to demonstrate the efficacy of our approach under different communication topologies.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "different communication topologies",
        "direct communication",
        "competing decentralized learning methods",
        "decentralized deep learning approaches",
        "decentralized deep learning",
        "multiple agents",
        "networked systems",
        "field robotics",
        "central parameter-server topology",
        "fixed communication topology",
        "model parameters",
        "gradient-based optimization"
      ]
    },
    "org": {
      "title": "Self-organizing Democratized Learning: Towards Large-scale Distributed Learning Systems",
      "url": "https://www.semanticscholar.org/paper/0308a8ca4a63c2592c08ecd452a6d2d9b3046ba3",
      "abstract": "Emerging cross-device artificial intelligence (AI) applications require a transition from conventional centralized learning systems toward large-scale distributed AI systems that can collaboratively perform complex learning tasks. In this regard, democratized learning (Dem-AI) lays out a holistic philosophy with underlying principles for building large-scale distributed and democratized machine learning systems. The outlined principles are meant to study a generalization in distributed learning systems that go beyond existing mechanisms such as federated learning (FL). Moreover, such learning systems rely on hierarchical self-organization of well-connected distributed learning agents who have limited and highly personalized data and can evolve and regulate themselves based on the underlying duality of specialized and generalized processes. Inspired by Dem-AI philosophy, a novel distributed learning approach is proposed in this article. The approach consists of a self-organizing hierarchical structuring mechanism based on agglomerative clustering, hierarchical generalization, and corresponding learning mechanism. Subsequently, hierarchical generalized learning problems in recursive forms are formulated and shown to be approximately solved using the solutions of distributed personalized learning problems and hierarchical update mechanisms. To that end, a distributed learning algorithm, namely DemLearn, is proposed. Extensive experiments on benchmark MNIST, Fashion-MNIST, FE-MNIST, and CIFAR-10 datasets show that the proposed algorithm demonstrates better results in the generalization performance of learning models in agents compared to the conventional FL algorithms. The detailed analysis provides useful observations to further handle both the generalization and specialization performance of the learning models in Dem-AI systems.",
      "fieldsOfStudy": [
        "Computer Science",
        "Medicine",
        "Mathematics"
      ],
      "topics": [
        "distributed learning systems",
        "learning systems",
        "distributed personalized learning problems",
        "corresponding learning mechanism",
        "conventional centralized learning systems",
        "hierarchical generalized learning problems",
        "democratized learning",
        "complex learning tasks",
        "hierarchical update mechanisms",
        "hierarchical generalization",
        "existing mechanisms",
        "novel distributed learning approach",
        "large-scale distributed AI systems",
        "large-scale distributed and democratized machine learning systems",
        "learning models",
        "distributed learning algorithm"
      ]
    }
  },
  {
    "sim": 0.46076254147034756,
    "gen": {
      "title": "Intelligent data engineering and automated learning - IDEAL 2014 : 15th International Conference, Salamanca, Spain, September 10-12, 2014 : proceedings",
      "url": "https://www.semanticscholar.org/paper/41966ca5e134b398f3def2251429bab287ff4e37",
      "abstract": "MLeNN: A First Approach to Heuristic Multilabel Undersampling.- Development of Eye-Blink Controlled Application for Physically Handicapped Children.- Generation of Reducts Based on Nearest Neighbor Relation.- Automatic Content Related Feedback for MOOCs Based on Course Domain Ontology.- User Behavior Modeling in a Cellular Network Using Latent Dirichlet Allocation.- Sample Size Issues in the Choice between the Best Classifier and Fusion by Trainable Combiners.- On Interlinking Linked Data Sources by Using Ontology Matching Techniques and the Map-Reduce Framework.- Managing Borderline and Noisy Examples in Imbalanced Classification by Combining SMOTE with Ensemble Filtering.- TweetSemMiner: A Meta-Topic Identification Model for Twitter Using Semantic Analysis.- Use of Empirical Mode Decomposition for Classification of MRCP Based Task Parameters.- Diversified Random Forests Using Random Subspaces.- Fast Frequent Pattern Detection Using Prime Numbers.- Multi-step Forecast Based on Modified Neural Gas Mixture Autoregressive Model.- LBP and Machine Learning for Diabetic Retinopathy Detection.- Automatic Validation of Flowmeter Data in Transport Water Networks: Application to the ATLLc Water Network.- Data Analysis for Detecting a Temporary Breath Inability Episode.- CPSO Applied in the Optimization of a Speech Recognition System.- Object-Neighbourhood Clustering Ensemble Method.- A Novel Recursive Kernel-Based Algorithm for Robust Pattern Classification.- Multi-Objective Genetic Algorithms for Sparse Least Square Support Vector Machines.- Pixel Classification and Heuristics for Facial Feature Localization.- A New Appearance Signature for Real Time Person Re-identification.- A New Hand Posture Recognizer Based on Hybrid Wavelet Network Including a Fuzzy Decision Support System.- Sim-EA: An Evolutionary Algorithm Based on Problem Similarity.- Multiobjective Dynamic Constrained Evolutionary Algorithm for Control of a Multi-segment Articulated Manipulator.- Parameter Dependence in Cumulative Selection.- Explanatory Inference under Uncertainty.- A Novel Ego-Centered Academic Community Detection Approach via Factor Graph Model.- Intelligent Promotions Recommendation System for Instaprom Platform.- Kernel K-Means Low Rank Approximation for Spectral Clustering and Diffusion Maps.- Linear Regression Fisher Discrimination Dictionary Learning for Hyperspectral Image Classification.- Ensemble-Distributed Approach in Classification Problem Solution for Intrusion Detection Systems.- Weight Update Sequence in MLP Networks.- Modeling of Bicomponent Mixing System Used in the Manufacture of Wind Generator Blades.- Branching to Find Feasible Solutions in Unmanned Air Vehicle Mission Planning.- Towards Data Mart Building from Social Network for Opinion Analysis.- A Novel Self Suppression Operator Used in TMA.- Machine Learning Methods for Mortality Prediction of Polytraumatized Patients in Intensive Care Units - Dealing with Imbalanced and High-Dimensional Data.- Nonconvex Functions Optimization Using an Estimation of Distribution Algorithm Based on a Multivariate Extension of the Clayton Copula.- News Mining Using Evolving Fuzzy Systems.- Predicting Students' Results Using Rough Sets Theory.- Graph-Based Object Class Discovery from Images with Multiple Objects.- A Proposed Extreme Learning Machine Pruning Based on the Linear Combination of the Input Data and the Output Layer Weights.- A Drowsy Driver Detection System Based on a New Method of Head Posture Estimation.- A CBR-Based Game Recommender for Rehabilitation Videogames in Social Networks.- A New Semantic Approach for CBIR Based on Beta Wavelet Network Modeling Shape Refined by Texture and Color Features.- Tackling Ant Colony Optimization Meta-Heuristic as Search Method in Feature Subset Selection Based on Correlation or Consistency Measures.- EventStory: Event Detection Using Twitter Stream Based on Locality.- Univariate Marginal Distribution Algorithm with Markov Chain Predictor in Continuous Dynamic Environments.- A Diversity-Adaptive Hybrid Evolutionary Algorithm to Solve a Project Scheduling Problem.- Computing Platforms for Large-Scale Multi-Agent Simulations: The Niche for Heterogeneous Systems.- Fuzzy Tool for Proposal of Suitable Products in Online Store and CRM System.- Giving Voice to the Internet by Means of Conversational Agents.- Multivariate Cauchy EDA Optimisation.- Continuous Population-Based Incremental Learning with Mixture Probability Modeling for Dynamic Optimization Problems.- Zero-Latency Data Warehouse System Based on Parallel Processing and Cache Module.- Distributed Multimedia Information System for Traffic Monitoring and Managing.- Auto-adaptation of Genetic Operators for Multi-objective Optimization in the Firefighter Problem.- Business and Government Organizations' Adoption of Cloud Computing.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "Multi-objective Optimization",
        "-identification.- A New Hand Posture Recognizer",
        "Classification.- Multi-Objective Genetic Algorithms",
        "Prime Numbers.- Multi-step Forecast",
        "Intrusion Detection Systems.- Weight Update Sequence",
        "Imbalanced Classification",
        "Random Subspaces.- Fast Frequent Pattern Detection",
        "Beta Wavelet Network Modeling Shape",
        "Problem Similarity.- Multiobjective Dynamic Constrained Evolutionary Algorithm",
        "Bicomponent Mixing System",
        "Locality.- Univariate Marginal Distribution Algorithm",
        "Heterogeneous Systems.- Fuzzy Tool",
        "MLP Networks.- Modeling",
        "Event Detection Using",
        "Classification Problem Solution",
        "MRCP Based Task Parameters.-",
        "Machine Learning",
        "Multiobjective Dynamic Constrained Evolutionary Algorithm",
        "Linear Regression Fisher Discrimination Dictionary Learning",
        "Multi-Objective Genetic Algorithms",
        "Distribution Algorithm",
        "Mixture Probability Modeling",
        "Univariate Marginal Distribution Algorithm",
        "Dynamic Optimization Problems.-",
        "Intrusion Detection Systems.-",
        "MLP Networks.-"
      ]
    },
    "org": {
      "title": "Modularity in Multilayer Networks Using Redundancy-Based Resolution and Projection-Based Inter-Layer Coupling",
      "url": "https://www.semanticscholar.org/paper/3f60306e71c2c142ec841596f8393fb8116d08ed",
      "abstract": "The generalized version of modularity for multilayer networks, a.k.a. multislice modularity, is characterized by two model parameters, namely resolution factor and inter-layer coupling factor. The former corresponds to a notion of layer-specific relevance, whereas the inter-layer coupling factor represents the strength of node connections across the network layers. Despite the potential of this approach, the setting of both parameters can be arbitrarily selected, without considering specific characteristics from the topology of the multilayer network as well as from an available community structure. Also, the multislice modularity is not designed to explicitly model order relations over the layers, which is of prior importance for dynamic networks. This paper aims to overcome the main limitations of the multislice modularity by introducing a new formulation of modularity for multilayer networks. We revise the role and semantics of both the resolution and inter-layer coupling factors based on information available from the within-layer and inter-layer structures of the multilayer communities. Also, our proposed multilayer modularity is general enough to consider orderings of network layers and their constraints on layer coupling. Experiments were carried out on synthetic and real-world multilayer networks using state-of-the-art approaches for multilayer community detection. The obtained results have shown the meaningfulness of the proposed modularity, revealing the effects of different combinations of the resolution and inter-layer coupling functions. This paper also represents a starting point for the development of new optimization methods for community detection in multilayer networks.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics",
        "Mathematics"
      ],
      "topics": [
        "layer coupling",
        "dynamic networks",
        "community detection",
        "multilayer community detection",
        "inter-layer coupling factor",
        "multilayer network",
        "modularity",
        "available community structure",
        "multilayer communities",
        "proposed multilayer modularity",
        "layer-specific relevance",
        "layer",
        "resolution and inter-layer coupling functions"
      ]
    }
  },
  {
    "sim": 0.6492960736693626,
    "gen": {
      "title": "A ConvNet for the 2020s",
      "url": "https://www.semanticscholar.org/paper/177e957f5cd93229c9794ea652c646d2557b4a69",
      "abstract": "The \u201cRoaring 20s\u201d of visual recognition began with the introduction of Vision Transformers (ViTs), which quickly superseded ConvNets as the state-of-the-art image classification model. A vanilla ViT, on the other hand, faces difficulties when applied to general computer vision tasks such as object detection and semantic segmentation. It is the hierarchical Transformers (e.g., Swin Transformers) that reintroduced several ConvNet priors, making Transformers practically viable as a generic vision backbone and demonstrating remarkable performance on a wide variety of vision tasks. However, the effectiveness of such hybrid approaches is still largely credited to the intrinsic superiority of Transformers, rather than the inherent inductive biases of convolutions. In this work, we reexamine the design spaces and test the limits of what a pure ConvNet can achieve. We gradually \u201cmodernize\u201d a standard ResNet toward the design of a vision Transformer, and discover several key components that contribute to the performance difference along the way. The outcome of this exploration is a family of pure ConvNet models dubbed ConvNeXt. Constructed entirely from standard ConvNet modules, ConvNeXts compete favorably with Transformers in terms of accuracy and scalability, achieving 87.8% ImageNet top-1 accuracy and outperforming Swin Transformers on COCO detection and ADE20K segmentation, while maintaining the simplicity and efficiency of standard ConvNets.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "pure ConvNet models",
        "vision tasks",
        "general computer vision tasks",
        "standard ConvNet modules",
        "ImageNet top-1 accuracy",
        "ADE20K segmentation",
        "ConvNeXt",
        "semantic segmentation",
        "ConvNet priors",
        "Vision Transformers",
        "object detection",
        "Transformers",
        "COCO detection",
        "remarkable performance"
      ]
    },
    "org": {
      "title": "Efficient and accurate approximations of nonlinear convolutional networks",
      "url": "https://www.semanticscholar.org/paper/b64601d509711468f5d085261d463846f36785b2",
      "abstract": "This paper aims to accelerate the test-time computation of deep convolutional neural networks (CNNs). Unlike existing methods that are designed for approximating linear filters or linear responses, our method takes the nonlinear units into account. We minimize the reconstruction error of the nonlinear responses, subject to a low-rank constraint which helps to reduce the complexity of filters. We develop an effective solution to this constrained nonlinear optimization problem. An algorithm is also presented for reducing the accumulated error when multiple layers are approximated. A whole-model speedup ratio of 4\u00d7 is demonstrated on a large network trained for ImageNet, while the top-5 error rate is only increased by 0.9%. Our accelerated model has a comparably fast speed as the \u201cAlexNet\u201d [11], but is 4.7% more accurate.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "linear filters",
        "linear",
        "filters",
        "deep convolutional neural networks",
        "existing methods",
        "account",
        "multiple layers",
        "CNNs",
        "constrained nonlinear optimization problem",
        "nonlinear responses",
        "AlexNet",
        "ImageNet",
        "nonlinear units",
        "accumulated error",
        "top-5 error rate",
        "large network"
      ]
    }
  },
  null,
  {
    "sim": 0.452152006279263,
    "gen": {
      "title": "Back to the Future: an Even More Nearly Optimal Cardinality Estimation Algorithm",
      "url": "https://www.semanticscholar.org/paper/7334ade850f17a4c43c8107cd9da3b55d3ba41c5",
      "abstract": "We describe a new cardinality estimation algorithm that is extremely space-efficient. It applies one of three novel estimators to the compressed state of the Flajolet-Martin-85 coupon collection process. In an apples-to-apples empirical comparison against compressed HyperLogLog sketches, the new algorithm simultaneously wins on all three dimensions of the time/space/accuracy tradeoff. Our prototype uses the zstd compression library, and produces sketches that are smaller than the entropy of HLL, so no possible implementation of compressed HLL can match its space efficiency. The paper's technical contributions include analyses and simulations of the three new estimators, accurate values for the entropies of FM85 and HLL, and a non-trivial method for estimating a double asymptotic limit via simulation.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "compressed HLL",
        "simulations",
        "HLL",
        "accurate values",
        "compressed HyperLogLog sketches",
        "FM85",
        "non-trivial method",
        "sketches",
        "new cardinality estimation algorithm",
        "double asymptotic limit",
        "space efficiency",
        "Flajolet-Martin-85 coupon collection process",
        "new algorithm",
        "Flajolet",
        "time/space/accuracy tradeoff"
      ]
    },
    "org": {
      "title": "Semi-supervised anomaly detection \u2013 towards model-independent searches of new physics",
      "url": "https://www.semanticscholar.org/paper/88111309efc6b7e90195a6f55dccdc4214bcda7b",
      "abstract": "Most classification algorithms used in high energy physics fall under the category of supervised machine learning. Such methods require a training set containing both signal and background events and are prone to classification errors should this training data be systematically inaccurate for example due to the assumed MC model. To complement such model-dependent searches, we propose an algorithm based on semi-supervised anomaly detection techniques, which does not require a MC training sample for the signal data. We first model the background using a multivariate Gaussian mixture model. We then search for deviations from this model by fitting to the observations a mixture of the background model and a number of additional Gaussians. This allows us to perform pattern recognition of any anomalous excess over the background. We show by a comparison to neural network classifiers that such an approach is a lot more robust against misspecification of the signal MC than supervised classification. In cases where there is an unexpected signal, a neural network might fail to correctly identify it, while anomaly detection does not suffer from such a limitation. On the other hand, when there are no systematic errors in the training data, both methods perform comparably.",
      "fieldsOfStudy": [
        "Physics",
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "supervised classification",
        "additional Gaussians",
        "supervised machine learning",
        "semi-supervised anomaly detection techniques",
        "classification errors",
        "Gaussians",
        "MC",
        "Most classification algorithms",
        "anomaly detection",
        "assumed MC model",
        "multivariate Gaussian mixture model",
        "high energy physics",
        "background model",
        "MC training sample",
        "neural network classifiers",
        "model-dependent searches"
      ]
    }
  },
  null,
  {
    "sim": 1,
    "gen": {
      "title": "Triple State QuickSort, A replacement for the C/C++ library qsort",
      "url": "https://www.semanticscholar.org/paper/7234c8c8ea752e9d4bbd2384903a6af49f18c22d",
      "abstract": "An industrial grade Quicksort function along with its new algorithm is presented. Compared to 4 other well known implementations of Quicksort, the new algorithm reduces both the number of comparisons and swaps in most cases while staying close to the best of the 4 in worst cases. We trade space for performance, at the price of n/2 temporary extra spaces in the worst case. Run time tests reveal an overall improvement of at least 15.8% compared to the overall best of the other 4 functions. Furthermore, our function scores a 32.7% run time improvement against Yaroslavskiy's new Dual Pivot Quicksort. Our function is pointer based, which is meant as a replacement for the C/C++ library qsort(). But we also provide an array based function of the same algorithm for easy porting to different programming languages.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "cases",
        "Dual Pivot Quicksort",
        "different programming languages",
        "worst case",
        "Quicksort",
        "n/2 temporary extra spaces",
        "Yaroslavskiys new Dual Pivot Quicksort",
        "easy porting",
        "An industrial grade Quicksort function",
        "swaps",
        "comparisons",
        "new algorithm",
        "new algorithm",
        "Run time tests",
        "qsort",
        "quicksort"
      ]
    },
    "org": {
      "title": "Triple State QuickSort, A replacement for the C/C++ library qsort",
      "url": "https://www.semanticscholar.org/paper/7234c8c8ea752e9d4bbd2384903a6af49f18c22d",
      "abstract": "An industrial grade Quicksort function along with its new algorithm is presented. Compared to 4 other well known implementations of Quicksort, the new algorithm reduces both the number of comparisons and swaps in most cases while staying close to the best of the 4 in worst cases. We trade space for performance, at the price of n/2 temporary extra spaces in the worst case. Run time tests reveal an overall improvement of at least 15.8% compared to the overall best of the other 4 functions. Furthermore, our function scores a 32.7% run time improvement against Yaroslavskiy's new Dual Pivot Quicksort. Our function is pointer based, which is meant as a replacement for the C/C++ library qsort(). But we also provide an array based function of the same algorithm for easy porting to different programming languages.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "cases",
        "Dual Pivot Quicksort",
        "different programming languages",
        "worst case",
        "Quicksort",
        "n/2 temporary extra spaces",
        "Yaroslavskiys new Dual Pivot Quicksort",
        "easy porting",
        "An industrial grade Quicksort function",
        "swaps",
        "comparisons",
        "new algorithm",
        "new algorithm",
        "Run time tests",
        "qsort",
        "quicksort"
      ]
    }
  },
  {
    "sim": 0.6465231851234805,
    "gen": {
      "title": "The Power of Choice in Priority Scheduling",
      "url": "https://www.semanticscholar.org/paper/98bd1ddddb3f63e81c8e75574b1d3ea656db9037",
      "abstract": "Consider the following random process: we are given n queues, into which elements of increasing labels are inserted uniformly at random. To remove an element, we pick two queues at random, and remove the element of lower label (higher priority) among the two. The cost of a removal is the rank of the label removed, among labels still present in any of the queues, that is, the distance from the optimal choice at each step. Variants of this strategy are prevalent in state-of-the-art concurrent priority queue implementations. Nonetheless, it is not known whether such implementations provide any rank guarantees, even in a sequential model. We answer this question, showing that this strategy provides surprisingly strong guarantees: Although the single-choice process, where we always insert and remove from a single randomly chosen queue, has degrading cost, going to infinity as we increase the number of steps, in the two choice process, the expected rank of a removed element is O(n) while the expected worst-case cost is O(n log n). These bounds are tight, and hold irrespective of the number of steps for which we run the process. The argument is based on a new technical connection between \"heavily loaded\" balls-into-bins processes and priority scheduling. Our analytic results inspire a new concurrent priority queue implementation, which improves upon the state of the art in terms of practical performance.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "queues",
        "priority scheduling",
        "increasing labels",
        "higher priority",
        "lower label",
        "new concurrent priority queue implementation",
        "elements",
        "labels",
        "degrading cost",
        "practical performance",
        "steps",
        "implementations",
        "following random process",
        "single-choice process",
        "infinity",
        "O(n log n",
        "O(n",
        "removed element"
      ]
    },
    "org": {
      "title": "Distributed maximal matching: greedy is optimal",
      "url": "https://www.semanticscholar.org/paper/5018d1f39afea88cb59d40f830110aa42e097a49",
      "abstract": "We study distributed algorithms that find a maximal matching in an anonymous, edge-coloured graph. If the edges are properly coloured with k colours, there is a trivial greedy algorithm that finds a maximal matching in k-1 synchronous communication rounds. The present work shows that the greedy algorithm is optimal in the general case: if A is a deterministic distributed algorithm that finds a maximal matching in anonymous, k-edge-coloured graphs, then there is a worst-case input in which the running time of A is at least k1 rounds.\n If we focus on graphs of maximum degree \u0394, it is known that a maximal matching can be found in O(\u0394+ log* k) rounds, and prior work implies a lower bound of \u03a9(polylog(\u0394) + log* k) rounds. Our work closes the gap between upper and lower bounds: the complexity is \u0398(\u0394+ log* k) rounds. To our knowledge, this is the first linear-in-\u0394 lower bound for the distributed complexity of a classical graph problem.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "synchronous communication rounds",
        "prior work",
        "k colours",
        "graphs",
        "algorithms",
        "\u03a9(polylog(\u0394",
        "upper and lower bounds",
        "O(\u0394+ log",
        "trivial greedy algorithm",
        "deterministic distributed algorithm",
        "maximal matching",
        "maximum degree",
        "lower bound",
        "rounds",
        "k-1 synchronous communication rounds",
        "distributed algorithms",
        "\u0398(\u0394+ log* k",
        "\u03a9(polylog(\u0394) + log* k) rounds"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.2844993341181914,
    "gen": {
      "title": "Accurate Face Alignment using Shape Constrained Markov Network",
      "url": "https://www.semanticscholar.org/paper/8b748b1c02a4be636703600ed490d78882d38117",
      "abstract": "In this paper, we present a shape constrained Markov network for accurate face alignment. The global face shape is defined as a set of weighted shape samples which are integrated into the Markov network optimization. These weighted samples provide structural constraints to make the Markov network more robust to local image noise. We propose a hierarchical Condensation algorithm to draw the shape samples efficiently. Specifically, a proposal density incorporating the local face shape is designed to generate more samples close to the image features for accurate alignment, based on a local Markov network search. A constrained regularization algorithm is also developed to weigh favorably those points that are already accurately aligned. Extensive experiments demonstrate the accuracy and effectiveness of our proposed approach.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "local image noise",
        "accurate alignment",
        "Markov",
        "local Markov network search",
        "samples",
        "samples",
        "Markov network optimization",
        "Markov network",
        "structural constraints",
        "The global face shape",
        "shape samples",
        "shape constrained Markov network",
        "image features"
      ]
    },
    "org": {
      "title": "Where are my followers? Understanding the Locality Effect in Twitter",
      "url": "https://www.semanticscholar.org/paper/84e1c283b8c3dafa6e98b1933c6bb6826f93ca3b",
      "abstract": "Twitter is one of the most used applications in the current Internet with more than 200M accounts created so far. As other large-scale systems Twitter can obtain benefit by exploiting the Locality effect existing among its users. In th is paper we perform the first comprehensive study of the Locality effect of Twitter. For this purpose we have collected the geographical location of around 1M Twitter users and 16M of their followers. Our results demonstrate that language and cultural characteristics determine the level of Locali ty expected for different countries. Those countries with a di fferent language than English such as Brazil typically show a high intra-country Locality whereas those others where English is official or co-official language suffer from an exter nal Locality effect. This is, their users have a larger numbe r of followers in US than within their same country. This is produced by two reasons: first, US is the dominant country in Twitter counting with around half of the users, and second, these countries share a common language and cultural characteristics with US.",
      "fieldsOfStudy": [
        "Computer Science",
        "Physics"
      ],
      "topics": [
        "different countries",
        "official language",
        "Twitter",
        "high intra-country Locality",
        "cultural characteristics",
        "English",
        "Locali ty",
        "country",
        "dominant country",
        "exter nal Locality effect",
        "followers",
        "language and cultural characteristics",
        "Those countries",
        "official or co-official language",
        "di fferent language",
        "common language",
        "countries"
      ]
    }
  },
  null,
  {
    "sim": 0.30015482874699295,
    "gen": {
      "title": "Numerical homogenization of time-dependent Maxwell's equations with dispersion effects",
      "url": "https://www.semanticscholar.org/paper/0cfe942f21409c24221a47579939af93cc57868a",
      "abstract": "This thesis studies the propagation of electromagnetic waves in heterogeneous structures such as metamaterials. The governing equations for this problem are Maxwell's equations with highly oscillatory parameters. We use an analytic homogenization result which yields an effective Maxwell system that involves a convolution integral. This convolution represents dispersive effects that result from the interaction of the wave with the (locally) periodic microscopic structure. \n \nWe discretize in space using the Finite Element Heterogeneous Multiscale Method (FE-HMM) and provide a semi-discrete error estimate. The rigorous error analysis in space is supplemented by a rather standard time discretization at the end of which an efficient, fully discrete method is proposed. This method uses a recursive approximation of the convolution that relies on the assumption that the convolution kernel is an exponential function. Eventually, we present numerical experiments both for the microscopic and the macroscopic scale.",
      "fieldsOfStudy": [
        "Physics"
      ],
      "topics": [
        "metamaterials",
        "heterogeneous structures",
        "semi-discrete error estimate",
        "electromagnetic waves",
        "dispersive effects",
        "Maxwell",
        "space",
        "Finite Element Heterogeneous Multiscale Method",
        "convolution kernel",
        "exponential function",
        "effective Maxwell system",
        "numerical experiments",
        "The rigorous error analysis",
        "macroscopic scale",
        "Maxwells equations",
        "convolution integral"
      ]
    },
    "org": {
      "title": "Learning Probably Approximately Correct Maximin Strategies in Simulation-Based Games with Infinite Strategy Spaces",
      "url": "https://www.semanticscholar.org/paper/5346d7ddb97f849ff645b2e9c99666383394db38",
      "abstract": "We tackle the problem of learning equilibria in simulation-based games. In such games, the players' utility functions cannot be described analytically, as they are given through a black-box simulator that can be queried to obtain noisy estimates of the utilities. This is the case in many real-world games in which a complete description of the elements involved is not available upfront, such as complex military settings and online auctions. In these situations, one usually needs to run costly simulation processes to get an accurate estimate of the game outcome. As a result, solving these games begets the challenge of designing learning algorithms that can find (approximate) equilibria with high confidence, using as few simulator queries as possible. Moreover, since running the simulator during the game is unfeasible, the algorithms must first perform a pure exploration learning phase and, then, use the (approximate) equilibrium learned this way to play the game. In this work, we focus on two-player zero-sum games with infinite strategy spaces. Drawing from the best arm identification literature, we design two algorithms with theoretical guarantees to learn maximin strategies in these games. The first one works in the fixed-confidence setting, guaranteeing the desired confidence level while minimizing the number of queries. Instead, the second algorithm fits the fixed-budget setting, maximizing the confidence without exceeding the given maximum number of queries. First, we formally prove {\\delta}-PAC theoretical guarantees for our algorithms under some regularity assumptions, which are encoded by letting the utility functions be drawn from a Gaussian process. Then, we experimentally evaluate our techniques on a testbed made of randomly generated games and instances representing simple real-world security settings.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "games",
        "designing learning algorithms",
        "complex military settings",
        "queries",
        "noisy estimates",
        "high confidence",
        "infinite strategy spaces",
        "online auctions",
        "costly simulation processes",
        "real-world games",
        "simulation-based games",
        "game outcome",
        "available upfront",
        "maximin strategies",
        "equilibria",
        "learning algorithms",
        "simple real-world security settings"
      ]
    }
  },
  {
    "sim": 0.7083743270170546,
    "gen": {
      "title": "Dynamic modularity approach to adaptive inner/outer loop control of robotic systems",
      "url": "https://www.semanticscholar.org/paper/b95746092748e8e2c5abe88e904aa821315ba94f",
      "abstract": "Modern applications of robotics typically involve a robot control system with an inner PI (proportional-integral) or PID (proportional-integral-derivative) control loop and an outer user-specified control loop. The existing outer loop controllers, however, do not take into consideration the dynamic effects of robots and their effectiveness relies on the ad hoc assumption that the inner PI or PID control loop is fast enough, and other torque-based control algorithms cannot be implemented in robotics with closed architecture (i.e., the torque control loop is closed). In this paper, we propose a dynamic modularity approach to resolve this issue, and a class of adaptive outer loop control schemes is proposed for robotic systems with an inner/outer loop structure and their role is to generate joint velocity and position commands for the low-level joint servoing loop. Without relying on the ad hoc assumption that the joint servoing is fast enough or the modification of the low-level joint controller structure, we rigorously show that the proposed outer loop controllers can ensure the stability and convergence of the closed-loop robotic system. We also propose the outer loop version of the standard Slotine and Li adaptive controller in joint space, and a promising conclusion may be that most torque-based adaptive controllers for robots can be redesigned to fit the inner/outer loop structure, by using the adaptively scaled dynamic compensation and the new definition of the joint velocity command. Simulation results are provided to show the performance of the proposed adaptive outer loop controllers, using a three-DOF (degree-of-freedom) manipulator.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Engineering"
      ],
      "topics": [
        "adaptive outer loop control schemes",
        "joint velocity",
        "joint space",
        "proposed outer loop controllers",
        "The existing outer loop controllers",
        "robotic systems",
        "outer loop version",
        "torque-based adaptive controllers",
        "outer user-specified control loop",
        "torque-based control algorithms",
        "position commands",
        "inner PI or PID control loop",
        "low-level joint servoing loop",
        "inner/outer loop structure",
        "torque control loop"
      ]
    },
    "org": {
      "title": "Projection based whole body motion planning for legged robots",
      "url": "https://www.semanticscholar.org/paper/dbedee9a5532e83bd5e0b3a366a4ac34292aa8c0",
      "abstract": "In this paper we present a new approach for dynamic motion planning for legged robots. We formulate a trajectory optimization problem based on a compact form of the robot dynamics. Such a form is obtained by projecting the rigid body dynamics onto the null space of the Constraint Jacobian. As consequence of the projection, contact forces are removed from the model but their effects are still taken into account. This approach permits to solve the optimal control problem of a floating base constrained multibody system while avoiding the use of an explicit contact model. We use direct transcription to numerically solve the optimization. As the contact forces are not part of the decision variables the size of the resultant discrete mathematical program is reduced and therefore solutions can be obtained in a tractable time. Using a predefined sequence of contact configurations (phases), our approach solves motions where contact switches occur. Transitions between phases are automatically resolved without using a model for switching dynamics. We present results on a hydraulic quadruped robot (HyQ), including single phase (standing, crouching) as well as multiple phase (rearing, diagonal leg balancing and stepping) dynamic motions.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "single phase",
        "legged robots",
        "dynamics",
        "phases",
        "contact switches",
        "contact forces",
        "contact configurations",
        "motions",
        "account",
        "multibody system",
        "robot dynamics",
        "explicit contact model",
        "Constraint Jacobian",
        "rigid body dynamics",
        "HyQ",
        "dynamic motion planning",
        "switching dynamics",
        "solutions"
      ]
    }
  },
  null,
  {
    "sim": 0.4791176028578863,
    "gen": {
      "title": "Mapping between Compositional Semantic Representations and Lexical Semantic Resources: Towards Accurate Deep Semantic Parsing",
      "url": "https://www.semanticscholar.org/paper/8d2b776aef44e6ddec954728befbffb9399ae94c",
      "abstract": "This paper introduces a machine learning method based on bayesian networks which is applied to the mapping between deep semantic representations and lexical semantic resources. A probabilistic model comprising Minimal Recursion Semantics (MRS) structures and lexicalist oriented semantic features is acquired. Lexical semantic roles enriching the MRS structures are inferred, which are useful to improve the accuracy of deep semantic parsing. Verb classes inference was also investigated, which, together with lexical semantic information provided by VerbNet and PropBank resources, can be substantially beneficial to the parse disambiguation task.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "deep semantic parsing",
        "deep semantic representations",
        "lexical semantic information",
        "Lexical semantic roles",
        "lexicalist oriented semantic features",
        "parse disambiguation task",
        "bayesian networks",
        "Minimal Recursion Semantics",
        "PropBank",
        "VerbNet and PropBank resources",
        "VerbNet",
        "bayesian",
        "Verb classes inference",
        "MRS structures",
        "disambiguation",
        "MRS",
        "machine learning method"
      ]
    },
    "org": {
      "title": "Neural Text Generation: A Practical Guide",
      "url": "https://www.semanticscholar.org/paper/55d87169355378ab5bded7488c899dc0069219dd",
      "abstract": "Deep learning methods have recently achieved great empirical success on machine translation, dialogue response generation, summarization, and other text generation tasks. At a high level, the technique has been to train end-to-end neural network models consisting of an encoder model to produce a hidden representation of the source text, followed by a decoder model to generate the target. While such models have significantly fewer pieces than earlier systems, significant tuning is still required to achieve good performance. For text generation models in particular, the decoder can behave in undesired ways, such as by generating truncated or repetitive outputs, outputting bland and generic responses, or in some cases producing ungrammatical gibberish. This paper is intended as a practical guide for resolving such undesired behavior in text generation models, with the aim of helping enable real-world applications.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "text generation models",
        "text generation tasks",
        "dialogue response generation",
        "models",
        "ungrammatical gibberish",
        "undesired behavior",
        "good performance",
        "undesired ways",
        "great empirical success",
        "significant tuning",
        "machine translation",
        "earlier systems",
        "outputting bland and generic responses",
        "decoder model",
        "summarization",
        "bland and generic responses",
        "real-world applications"
      ]
    }
  },
  null,
  null,
  null,
  null,
  {
    "sim": 0.5280906321167009,
    "gen": {
      "title": "The New Combined Closed-Solution for 3D Reconstruction of Environment Based on Iterative Closest Point Algorithm",
      "url": "https://www.semanticscholar.org/paper/d14796244216c02178d6cc2670e8c6d770e907dd",
      "abstract": "This The scientific problem at solving which the present project is directed consists in the development of accurate methods for reconstruction of a three-dimensional map of the accessible of environment with requied accuracy of reconstruction. The problem of consistent aligning of 3D point data is known registration task. The most popular registration algorithm is the Iterative Closest Point algorithm. Three basic problems are characteristic for the ICP algorithm: first, the convergence of the algorithm depends strongly on the choice of the initial approximation; second, the algorithm does not take into account the local shape of the surface around each point; and, third, the search for the nearest points is of high computational complexity. In this paper a new close solutions to 3D total variation regularization will be obtained and effective algorithms for restoring 3D data will be designed. The proposed approach improves the accuracy and convergence of reconstruction methods for complex and large-scale scenes. The performance and computational complexity of the proposed RGB-D Mapping algorithm in real indoor environments is discussed. Keywords\u2014simultaneous localization and mapping; a threedimensional map; iterative closest point algorithm; orthogonal transformations; variational problem of the point-to-point",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "effective algorithms",
        "3D point data",
        "reconstruction methods",
        "point",
        "real indoor environments",
        "reconstruction",
        "requied accuracy",
        "computational complexity",
        "3D data",
        "accurate methods",
        "Iterative Closest Point algorithm",
        "environment",
        "variational problem",
        "known registration task",
        "3D total variation regularization"
      ]
    },
    "org": {
      "title": "Large-Margin Metric Learning for Partitioning Problems",
      "url": "https://www.semanticscholar.org/paper/1cf8579f1079fa44424e3ab55f528bf6651f5f98",
      "abstract": "In this paper, we consider unsupervised partitioning problems, such as clustering, image segmentation, video segmentation and other change-point detection problems. We focus on partitioning problems based explicitly or implicitly on the minimization of Euclidean distortions, which include mean-based change-point detection, K-means, spectral clustering and normalized cuts. Our main goal is to learn a Mahalanobis metric for these unsupervised problems, leading to feature weighting and/or selection. This is done in a supervised way by assuming the availability of several potentially partially labelled datasets that share the same metric. We cast the metric learning problem as a large-margin structured prediction problem, with proper definition of regularizers and losses, leading to a convex optimization problem which can be solved efficiently with iterative techniques. We provide experiments where we show how learning the metric may significantly improve the partitioning performance in synthetic examples, bioinformatics, video segmentation and image segmentation problems.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "partitioning problems",
        "unsupervised partitioning problems",
        "video segmentation",
        "image segmentation",
        "change-point detection problems",
        "iterative techniques",
        "convex optimization problem",
        "selection",
        "proper definition",
        "feature weighting",
        "Euclidean distortions",
        "metric learning problem",
        "unsupervised problems",
        "synthetic examples",
        "video segmentation and image segmentation problems",
        "normalized cuts",
        "spectral clustering",
        "clustering"
      ]
    }
  },
  {
    "sim": 0.589605956558619,
    "gen": {
      "title": "Visual Object Tracking for Unmanned Aerial Vehicles: A Benchmark and New Motion Models",
      "url": "https://www.semanticscholar.org/paper/6ebc40a061433c24a3ea1f305bb6533b8f3dd5f4",
      "abstract": "\n \n Despite recent advances in the visual tracking community, most studies so far have focused on the observation model. As another important component in the tracking system, the motion model is much less well-explored especially for some extreme scenarios. In this paper, we consider one such scenario in which the camera is mounted on an unmanned aerial vehicle (UAV) or drone. We build a benchmark dataset of high diversity, consisting of 70 videos captured by drone cameras. To address the challenging issue of severe camera motion, we devise simple baselines to model the camera motion by geometric transformation based on background feature points. An extensive comparison of recent state-of-the-art trackers and their motion model variants on our drone tracking dataset validates both the necessity of the dataset and the effectiveness of the proposed methods. Our aim for this work is to lay the foundation for further research in the UAV tracking area.\n \n",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "drone cameras",
        "drone",
        "background feature points",
        "drone tracking dataset",
        "UAV",
        "geometric transformation",
        "simple baselines",
        "motion model variants",
        "UAV tracking area",
        "camera motion",
        "studies",
        "motion model",
        "high diversity",
        "unmanned aerial vehicle"
      ]
    },
    "org": {
      "title": "Toward unsupervised, multi-object discovery in large-scale image collections",
      "url": "https://www.semanticscholar.org/paper/1ac9e9d1f861f47b4b92d2fef343f574d3236661",
      "abstract": null,
      "fieldsOfStudy": [
        "Computer Science"
      ]
    }
  },
  null,
  null,
  {
    "sim": 0.36748491828382146,
    "gen": {
      "title": "Refined Dynamic Event-Triggering Cluster Consensus of Multiagent Systems With Fixed/Switching Topology.",
      "url": "https://www.semanticscholar.org/paper/c2f7412c3a7a75f2ae33201c176ebc8eb2966c38",
      "abstract": "This article is concerned with cluster consensus control of multiagent systems (MASs) with the fixed/switching topology under a dynamic event-trigger (DET) mechanism. A refined sampled-data-based DET scheme is proposed by introducing two dynamically adjusting threshold parameters to distinguish the different transmission requirements for neighboring agents intra and outer cluster. Faced with the difficulties of acquiring full state information among spatially distributed agents, output feedback is employed to construct cooperative control protocols. Both fixed and switching topologies are considered to execute the designed DET-based cooperative cluster consensus control protocols. By constructing appropriate Lyapunov-Krasovskii functionals (LKFs), some sufficient criteria in terms of matrix inequalities for the cluster consensus of MASs are derived, which can ensure that the error system with the proposed DET-based control strategy is asymptotically stable. Facing the nonconvex issue induced by output feedback, a particle swarm optimization (PSO)-based control design algorithm is novelly developed to calculate the control gains and event-triggering parameters jointly based on the derived stability criteria. The elements of the matrix variables are valued stochastically in certain ranges and the fitness function is designed as the accumulation of the weighting value of each matrix inequality. Finally, an application of multiple satellites formation flying is applied to numerically illustrate the effectiveness of the cluster consensus control strategy with the designed DET mechanism.",
      "fieldsOfStudy": [
        "Medicine"
      ],
      "topics": [
        "cooperative control protocols",
        "outer cluster",
        "PSO)-based control design algorithm",
        "matrix inequalities",
        "cluster consensus control strategy",
        "designed DET-based cooperative cluster consensus control protocols",
        "multiagent systems",
        "threshold parameters",
        "proposed DET-based control strategy",
        "MASs",
        "designed DET mechanism",
        "cluster consensus",
        "output feedback",
        "control gains",
        "DET",
        "neighboring agents",
        "intra and outer cluster"
      ]
    },
    "org": {
      "title": "Stochastic Low-Rank Kernel Learning for Regression",
      "url": "https://www.semanticscholar.org/paper/9418769c65a3bb863adbec060cfafabd71a1a009",
      "abstract": "We present a novel approach to learn a kernel-based regression function. It is based on the use of conical combinations of data-based parameterized kernels and on a new stochastic convex optimization procedure of which we establish convergence guarantees. The overall learning procedure has the nice properties that a) the learned conical combination is automatically designed to perform the regression task at hand and b) the updates implicated by the optimization procedure are quite inexpensive. In order to shed light on the appositeness of our learning strategy, we present empirical results from experiments conducted on various benchmark datasets.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "convergence guarantees",
        "benchmark datasets",
        "conical combinations",
        "new stochastic convex optimization procedure",
        "empirical results",
        "hand",
        "data-based parameterized kernels",
        "optimization procedure",
        "learned conical combination",
        "The overall learning procedure",
        "experiments",
        "kernel-based regression function",
        "regression task",
        "nice properties",
        "light"
      ]
    }
  },
  {
    "sim": 0.3783722766468932,
    "gen": {
      "title": "Regularization of Neural Networks using DropConnect",
      "url": "https://www.semanticscholar.org/paper/38f35dd624cd1cf827416e31ac5e0e0454028eca",
      "abstract": "We introduce DropConnect, a generalization of Dropout (Hinton et al., 2012), for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recognition benchmarks by aggregating multiple DropConnect-trained models.",
      "fieldsOfStudy": [
        "Mathematics",
        "Computer Science"
      ],
      "topics": [
        "neural networks",
        "image recognition benchmarks",
        "DropConnect",
        "Dropout",
        "multiple DropConnect-trained models",
        "Dropout (Hinton et al.",
        "network",
        "previous layer",
        "weights",
        "al",
        "units",
        "activations",
        "large fully-connected layers",
        "Hinton",
        "datasets",
        "random subset"
      ]
    },
    "org": {
      "title": "Head-Driven Phrase Structure Grammar Parsing on Penn Treebank",
      "url": "https://www.semanticscholar.org/paper/72c0e5b7365ae4981db13cfa15ca808a8eb3a8a1",
      "abstract": "Head-driven phrase structure grammar (HPSG) enjoys a uniform formalism representing rich contextual syntactic and even semantic meanings. This paper makes the first attempt to formulate a simplified HPSG by integrating constituent and dependency formal representations into head-driven phrase structure. Then two parsing algorithms are respectively proposed for two converted tree representations, division span and joint span. As HPSG encodes both constituent and dependency structure information, the proposed HPSG parsers may be regarded as a sort of joint decoder for both types of structures and thus are evaluated in terms of extracted or converted constituent and dependency parsing trees. Our parser achieves new state-of-the-art performance for both parsing tasks on Penn Treebank (PTB) and Chinese Penn Treebank, verifying the effectiveness of joint learning constituent and dependency structures. In details, we report 95.84 F1 of constituent parsing and 97.00% UAS of dependency parsing on PTB.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "joint span",
        "dependency parsing",
        "joint decoder",
        "constituent parsing",
        "Chinese Penn Treebank",
        "joint learning constituent and dependency structures",
        "division span",
        "structures",
        "dependency",
        "Penn Treebank",
        "constituent",
        "formal representations",
        "PTB",
        "head-driven phrase structure",
        "constituent and dependency formal representations",
        "HPSG",
        "extracted or converted constituent and dependency parsing trees",
        "constituent and dependency structure information"
      ]
    }
  },
  {
    "sim": 0.5564913092758603,
    "gen": {
      "title": "A comparative study of Generative Adversarial Networks for Text-to-Image synthesis",
      "url": "https://www.semanticscholar.org/paper/765f7fb79a71fe306a3270643a025ba2be4c1e30",
      "abstract": "Text-to-picture alludes to the conversion of a textual description into a semantically similar image.The automatic synthesis of top-quality pictures from text portrayals is both exciting and useful at the same time.Current AI systems have shown significant advances in the field,but the work is still far from complete. Recent advances in the field of Deep Learning have resulted in the introduction of generative models that are capable of generating realistic images when trained appropriately.In this paper,authors will review the advancements in architectures for solving the problem of image synthesis using a text description.They begin by studying the concepts of the standard GAN, how the DCGAN has been used for the task at hand is followed by the StackGAN with uses a stack of two GANs to generate an image through iterative refinement & StackGAN++ which uses multiple GANs in a tree-like structure making the task of generating images from the text more generalized. They look at the AttnGAN which uses an attentional model to generate sub-regions of an image based on the description.",
      "fieldsOfStudy": null,
      "topics": [
        "image synthesis",
        "generating images",
        "realistic images",
        "text portrayals",
        "multiple GANs",
        "iterative refinement",
        "generative models",
        "image",
        "StackGAN++",
        "semantically similar image",
        "significant advances",
        "textual description",
        "picture",
        "Deep Learning",
        "images",
        "Text",
        "StackGAN"
      ]
    },
    "org": {
      "title": "Adaptive Explainable Neural Networks (Axnns)",
      "url": "https://www.semanticscholar.org/paper/68e6d209c3ed883d6261f031f03ecca6b5a7ecaf",
      "abstract": "While machine learning techniques have been successfully applied in several fields, the black-box nature of the models presents challenges for interpreting and explaining the results. We develop a new framework called Adaptive Explainable Neural Networks (AxNN) for achieving the dual goals of good predictive performance and model interpretability. For predictive performance, we build a structured neural network made up of ensembles of generalized additive model networks and additive index models (through explainable neural networks) using a two-stage process. This can be done using either a boosting or a stacking ensemble. For interpretability, we show how to decompose the results of AxNN into main effects and higher-order interaction effects. The computations are inherited from Google's open source tool AdaNet and can be efficiently accelerated by training with distributed computing. The results are illustrated on simulated and real datasets.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "main effects",
        "generalized additive model networks",
        "additive index models",
        "higher-order interaction effects",
        "model interpretability",
        "distributed computing",
        "ensembles",
        "predictive performance",
        "Adaptive Explainable Neural Networks",
        "AxNN",
        "structured neural network",
        "interpreting",
        "fields",
        "challenges"
      ]
    }
  },
  {
    "sim": 0.6287347601496033,
    "gen": {
      "title": "Are we ready for autonomous driving? The KITTI vision benchmark suite",
      "url": "https://www.semanticscholar.org/paper/de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42",
      "abstract": "Today, visual recognition systems are still rarely employed in robotics applications. Perhaps one of the main reasons for this is the lack of demanding benchmarks that mimic such scenarios. In this paper, we take advantage of our autonomous driving platform to develop novel challenging benchmarks for the tasks of stereo, optical flow, visual odometry/SLAM and 3D object detection. Our recording platform is equipped with four high resolution video cameras, a Velodyne laser scanner and a state-of-the-art localization system. Our benchmarks comprise 389 stereo and optical flow image pairs, stereo visual odometry sequences of 39.2 km length, and more than 200k 3D object annotations captured in cluttered scenarios (up to 15 cars and 30 pedestrians are visible per image). Results from state-of-the-art algorithms reveal that methods ranking high on established datasets such as Middlebury perform below average when being moved outside the laboratory to the real world. Our goal is to reduce this bias by providing challenging benchmarks with novel difficulties to the computer vision community. Our benchmarks are available online at: www.cvlibs.net/datasets/kitti.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "stereo visual odometry sequences",
        "optical flow image pairs",
        "3D object detection",
        "visual recognition systems",
        "image",
        "robotics applications",
        "cluttered scenarios",
        "scenarios",
        "challenging benchmarks",
        "3D",
        "200k 3D object annotations",
        "Middlebury perform",
        "optical flow",
        "demanding benchmarks",
        "established datasets",
        "389 stereo and optical flow image pairs",
        "novel difficulties",
        "visual odometry/SLAM"
      ]
    },
    "org": {
      "title": "RePr: Improved Training of Convolutional Filters",
      "url": "https://www.semanticscholar.org/paper/37eaca9f4319c0f20ca9ccadf2389d1fed0cf772",
      "abstract": "A well-trained Convolutional Neural Network can easily be pruned without significant loss of performance. This is because of unnecessary overlap in the features captured by the network\u2019s filters. Innovations in network architecture such as skip/dense connections and inception units have mitigated this problem to some extent, but these improvements come with increased computation and memory requirements at run-time. We attempt to address this problem from another angle - not by changing the network structure but by altering the training method. We show that by temporarily pruning and then restoring a subset of the model\u2019s filters, and repeating this process cyclically, overlap in the learned features is reduced, producing improved generalization. We show that the existing model-pruning criteria are not optimal for selecting filters to prune in this context, and introduce inter-filter orthogonality as the ranking criteria to determine under-expressive filters. Our method is applicable both to vanilla convolutional networks and more complex modern architectures, and improves the performance across a variety of tasks, especially when applied to smaller networks.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "network architecture",
        "smaller networks",
        "vanilla convolutional networks",
        "filters",
        "inter-filter orthogonality",
        "improved generalization",
        "performance",
        "inception units",
        "tasks",
        "network structure",
        "complex modern architectures",
        "increased computation and memory requirements",
        "significant loss",
        "network\u2019s filters",
        "skip/dense connections",
        "unnecessary overlap",
        "overlap"
      ]
    }
  },
  {
    "sim": 0.674061321716637,
    "gen": {
      "title": "Robust Optimization over Multiple Domains",
      "url": "https://www.semanticscholar.org/paper/12a17d5dfd222abfa47e121b734c93ae988d05b4",
      "abstract": "In this work, we study the problem of learning a single model for multiple domains. Unlike the conventional machine learning scenario where each domain can have the corresponding model, multiple domains (i.e., applications/users) may share the same machine learning model due to maintenance loads in cloud computing services. For example, a digit-recognition model should be applicable to hand-written digits, house numbers, car plates, etc. Therefore, an ideal model for cloud computing has to perform well at each applicable domain. To address this new challenge from cloud computing, we develop a framework of robust optimization over multiple domains. In lieu of minimizing the empirical risk, we aim to learn a model optimized to the adversarial distribution over multiple domains. Hence, we propose to learn the model and the adversarial distribution simultaneously with the stochastic algorithm for efficiency. Theoretically, we analyze the convergence rate for convex and non-convex models. To our best knowledge, we first study the convergence rate of learning a robust non-convex model with a practical algorithm. Furthermore, we demonstrate that the robustness of the framework and the convergence rate can be further enhanced by appropriate regularizers over the adversarial distribution. The empirical study on real-world fine-grained visual categorization and digits recognition tasks verifies the effectiveness and efficiency of the proposed framework.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "multiple domains",
        "non-convex models",
        "efficiency",
        "machine learning model",
        "cloud computing services",
        "robust non-convex model",
        "car plates",
        "robust optimization",
        "applicable domain",
        "cloud computing",
        "corresponding model",
        "maintenance loads",
        "house numbers",
        "single model",
        "ideal model",
        "convex and non-convex models"
      ]
    },
    "org": {
      "title": "Complete Dictionary Learning via \ud835\udcc14-Norm Maximization over the Orthogonal Group",
      "url": "https://www.semanticscholar.org/paper/f9d7dbb8372d563b29065cb30cb624a366f0e461",
      "abstract": "This paper considers the fundamental problem of learning a complete (orthogonal) dictionary from samples of sparsely generated signals. Most existing methods solve the dictionary (and sparse representations) based on heuristic algorithms, usually without theoretical guarantees for either optimality or complexity. The recent $\\ell^1$-minimization based methods do provide such guarantees but the associated algorithms recover the dictionary one column at a time. In this work, we propose a new formulation that maximizes the $\\ell^4$-norm over the orthogonal group, to learn the entire dictionary. We prove that under a random data model, with nearly minimum sample complexity, the global optima of the $\\ell^4$ norm are very close to signed permutations of the ground truth. Inspired by this observation, we give a conceptually simple and yet effective algorithm based on `matching, stretching, and projection' (MSP). The algorithm provably converges locally at a superlinear (cubic) rate and cost per iteration is merely an SVD. In addition to strong theoretical guarantees, experiments show that the new algorithm is significantly more efficient and effective than existing methods, including KSVD and $\\ell^1$-based methods. Preliminary experimental results on real images clearly demonstrate advantages of so learned dictionary over classic PCA bases.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics",
        "Engineering"
      ],
      "topics": [
        "heuristic algorithms",
        "Most existing methods",
        "classic PCA bases",
        "signed permutations",
        "guarantees",
        "strong theoretical guarantees",
        "sparse representations",
        "complexity",
        "MSP",
        "SVD",
        "samples",
        "ground truth",
        "PCA",
        "learned dictionary",
        "entire dictionary"
      ]
    }
  },
  {
    "sim": 0.5398751530439877,
    "gen": {
      "title": "Entropy Minimization In Emergent Languages",
      "url": "https://www.semanticscholar.org/paper/313860ca6c4427cd6a0eff9a87997a840b632651",
      "abstract": "There is growing interest in studying the languages that emerge when neural agents are jointly trained to solve tasks requiring communication through a discrete channel. We investigate here the information-theoretic complexity of such languages, focusing on the basic two-agent, one-exchange setup. We find that, under common training procedures, the emergent languages are subject to an entropy minimization pressure that has also been detected in human language, whereby the mutual information between the communicating agent's inputs and the messages is minimized, within the range afforded by the need for successful communication. That is, emergent languages are (nearly) as simple as the task they are developed for allow them to be. This pressure is amplified as we increase communication channel discreteness. Further, we observe that stronger discrete-channel-driven entropy minimization leads to representations with increased robustness to overfitting and adversarial attacks. We conclude by discussing the implications of our findings for the study of natural and artificial communication systems.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "communication channel discreteness",
        "successful communication",
        "communication",
        "human language",
        "increased robustness",
        "languages",
        "emergent languages",
        "neural agents",
        "natural and artificial communication systems",
        "stronger discrete-channel-driven entropy minimization",
        "representations",
        "tasks",
        "overfitting and adversarial attacks",
        "discrete channel",
        "entropy minimization pressure"
      ]
    },
    "org": {
      "title": "Cross Scene Prediction via Modeling Dynamic Correlation using Latent Space Shared Auto-Encoders",
      "url": "https://www.semanticscholar.org/paper/094dcd70c61cb33e7ba8b0916feb181d110f9a62",
      "abstract": "This work addresses on the following problem: given a set of unsynchronized history observations of two scenes that are correlative on their dynamic changes, the purpose is to learn a cross-scene predictor, so that with the observation of one scene, a robot can onlinely predict the dynamic state of the other. A method is proposed to solve the problem via modeling dynamic correlation using latent space shared auto-encoders. Assuming that the inherent correlation of scene dynamics can be represented by shared latent space, where a common latent state is reached if the observations of both scenes are at an approximate time. A learning model is developed by connecting two auto-encoders through the latent space, and a prediction model is built by concatenating the encoder of the input scene with the decoder of the target one. Simulation datasets are generated imitating the dynamic flows at two adjacent gates of a campus, where the dynamic changes are triggered by a common working and teaching schedule. Similar scenarios can also be found at successive intersections on a single road, gates of a subway station, etc. Accuracy of cross-scene prediction is examined at various conditions of scene correlation and pairwise observations. Potentials of the proposed method are demonstrated by comparing with conventional end-to-end methods and linear predictions.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "scene correlation",
        "scene dynamics",
        "dynamic correlation",
        "shared latent space",
        "pairwise observations",
        "cross-scene prediction",
        "unsynchronized history observations",
        "latent space",
        "linear predictions",
        "conditions",
        "input scene",
        "gates",
        "common latent state",
        "dynamic state",
        "dynamic changes",
        "encoders"
      ]
    }
  },
  {
    "sim": 0.28719609100396903,
    "gen": {
      "title": "Unsupervised representation learning of structured radio communication signals",
      "url": "https://www.semanticscholar.org/paper/14189330ef6b7abfcc32191f7c1afd34f6dac371",
      "abstract": "We explore unsupervised representation learning of radio communication signals in raw sampled time series representation. We demonstrate that we can learn modulation basis functions using convolutional autoencoders and visually recognize their relationship to the analytic bases used in digital communications. We also propose and evaluate quantitative metrics for quality of encoding using domain relevant performance metrics.",
      "fieldsOfStudy": [
        "Computer Science"
      ],
      "topics": [
        "raw sampled time series representation",
        "radio communication signals",
        "unsupervised representation learning",
        "digital communications",
        "domain relevant performance metrics",
        "quantitative metrics",
        "modulation basis functions",
        "convolutional autoencoders",
        "encoding",
        "quality",
        "analytic bases",
        "relationship"
      ]
    },
    "org": {
      "title": "Enumeration of Distinct Support Vectors for Interactive Decision Making",
      "url": "https://www.semanticscholar.org/paper/4a0f926f892f4f19c05b8235e4d0cbba42b1aebd",
      "abstract": "In conventional prediction tasks, a machine learning algorithm outputs a single best model that globally optimizes its objective function, which typically is accuracy. Therefore, users cannot access the other models explicitly. In contrast to this, multiple model enumeration attracts increasing interests in non-standard machine learning applications where other criteria, e.g., interpretability or fairness, than accuracy are main concern and a user may want to access more than one non-optimal, but suitable models. In this paper, we propose a K-best model enumeration algorithm for Support Vector Machines (SVM) that given a dataset S and an integer K>0, enumerates the K-best models on S with distinct support vectors in the descending order of the objective function values in the dual SVM problem. Based on analysis of the lattice structure of support vectors, our algorithm efficiently finds the next best model with small latency. This is useful in supporting users's interactive examination of their requirements on enumerated models. By experiments on real datasets, we evaluated the efficiency and usefulness of our algorithm.",
      "fieldsOfStudy": [
        "Computer Science",
        "Mathematics"
      ],
      "topics": [
        "enumerated models",
        "multiple model enumeration",
        "non-standard machine learning applications",
        "distinct support vectors",
        "best model",
        "Support Vector Machines",
        "single best model",
        "support vectors",
        "main concern",
        "small latency",
        "K-best model enumeration algorithm",
        "accuracy",
        "models",
        "increasing interests",
        "users",
        "SVM"
      ]
    }
  },
  null
]